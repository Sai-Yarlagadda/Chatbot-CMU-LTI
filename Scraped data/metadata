faculty_name: Yonatan Bisk
faculty_authorid: 3312309
paper_id: 376f494126d1ea4f571ea0263c43ac2b6331800a
paper_title: SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs
publication_link: http://arxiv.org/pdf/2306.17842 
year_published: 2023 
abstract_paper:In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos. SPAE converts between raw pixels and interpretable lexical tokens (or words) extracted from the LLM's vocabulary. The resulting tokens capture both the semantic meaning and the fine-grained details needed for visual reconstruction, effectively translating the visual content into a language comprehensible to the LLM, and empowering it to perform a wide array of multimodal tasks. Our approach is validated through in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set of image understanding and generation tasks. Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.
isOpenAccess: True
TL\DR: This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.
================================
faculty_name: Yonatan Bisk
faculty_authorid: 3312309
paper_id: 3b0c02955e88f5862e61b560c7f70ba8cf235b1d
paper_title: HomeRobot: Open-Vocabulary Mobile Manipulation
publication_link: http://arxiv.org/pdf/2306.11565 
year_published: 2023 
abstract_paper:HomeRobot (noun): An affordable compliant robot that navigates homes and manipulates a wide range of objects in order to complete everyday tasks. Open-Vocabulary Mobile Manipulation (OVMM) is the problem of picking any object in any unseen environment, and placing it in a commanded location. This is a foundational challenge for robots to be useful assistants in human environments, because it involves tackling sub-problems from across robotics: perception, language understanding, navigation, and manipulation are all essential to OVMM. In addition, integration of the solutions to these sub-problems poses its own substantial challenges. To drive research in this area, we introduce the HomeRobot OVMM benchmark, where an agent navigates household environments to grasp novel objects and place them on target receptacles. HomeRobot has two components: a simulation component, which uses a large and diverse curated object set in new, high-quality multi-room home environments; and a real-world component, providing a software stack for the low-cost Hello Robot Stretch to encourage replication of real-world experiments across labs. We implement both reinforcement learning and heuristic (model-based) baselines and show evidence of sim-to-real transfer. Our baselines achieve a 20% success rate in the real world; our experiments identify ways future research work improve performance. See videos on our website: https://ovmm.github.io/.
isOpenAccess: True
TL\DR: The HomeRobot OVMM benchmark is introduced, where an agent navigates household environments to grasp novel objects and place them on target receptacles, and baselines achieve a 20% success rate in the real world; the experiments identify ways future research work improve performance.
================================
faculty_name: Yonatan Bisk
faculty_authorid: 3312309
paper_id: 5ce2f1dff23a5620f77f9b11f1e534422ab8ff3f
paper_title: Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents
publication_link: http://arxiv.org/pdf/2305.02412 
year_published: 2023 
abstract_paper:Pre-trained large language models (LLMs) capture procedural knowledge about the world. Recent work has leveraged LLM's ability to generate abstract plans to simplify challenging control tasks, either by action scoring, or action modeling (fine-tuning). However, the transformer architecture inherits several constraints that make it difficult for the LLM to directly serve as the agent: e.g. limited input lengths, fine-tuning inefficiency, bias from pre-training, and incompatibility with non-text environments. To maintain compatibility with a low-level trainable actor, we propose to instead use the knowledge in LLMs to simplify the control problem, rather than solving it. We propose the Plan, Eliminate, and Track (PET) framework. The Plan module translates a task description into a list of high-level sub-tasks. The Eliminate module masks out irrelevant objects and receptacles from the observation for the current sub-task. Finally, the Track module determines whether the agent has accomplished each sub-task. On the AlfWorld instruction following benchmark, the PET framework leads to a significant 15% improvement over SOTA for generalization to human goal specifications.
isOpenAccess: True
TL\DR: A framework to use the knowledge in LLMs to simplify the control problem, rather than solving it is proposed, which leads to a significant 15% improvement over SOTA for generalization to human goal specifications.
================================
faculty_name: Yonatan Bisk
faculty_authorid: 3312309
paper_id: 69b8cd15966c4c9c3e44e71769e557f1c87fb3f9
paper_title: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception
publication_link: https://arxiv.org/pdf/2309.08508 
year_published: 2023 
abstract_paper:A holistic understanding of object properties across diverse sensory modalities (e.g., visual, audio, and haptic) is essential for tasks ranging from object categorization to complex manipulation. Drawing inspiration from cognitive science studies that emphasize the significance of multi-sensory integration in human perception, we introduce MOSAIC (Multimodal Object property learning with Self-Attention and Interactive Comprehension), a novel framework designed to facilitate the learning of unified multi-sensory object property representations. While it is undeniable that visual information plays a prominent role, we acknowledge that many fundamental object properties extend beyond the visual domain to encompass attributes like texture, mass distribution, or sounds, which significantly influence how we interact with objects. In MOSAIC, we leverage this profound insight by distilling knowledge from multimodal foundation models and aligning these representations not only across vision but also haptic and auditory sensory modalities. Through extensive experiments on a dataset where a humanoid robot interacts with 100 objects across 10 exploratory behaviors, we demonstrate the versatility of MOSAIC in two task families: object categorization and object-fetching tasks. Our results underscore the efficacy of MOSAIC's unified representations, showing competitive performance in category recognition through a simple linear probe setup and excelling in the fetch object task under zero-shot transfer conditions. This work pioneers the application of sensory grounding in foundation models for robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems. We have released the code, datasets, and additional results: https://github.com/gtatiya/MOSAIC.
isOpenAccess: True
TL\DR: This work pioneers the application of sensory grounding in foundation models for robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems.
================================
faculty_name: Yonatan Bisk
faculty_authorid: 3312309
paper_id: 8035a247980cb18abf2bb7b9d96e7d4c63622ef2
paper_title: Reasoning about the Unseen for Efficient Outdoor Object Navigation
publication_link: https://arxiv.org/pdf/2309.10103 
year_published: 2023 
abstract_paper:Robots should exist anywhere humans do: indoors, outdoors, and even unmapped environments. In contrast, the focus of recent advancements in Object Goal Navigation(OGN) has targeted navigating in indoor environments by leveraging spatial and semantic cues that do not generalize outdoors. While these contributions provide valuable insights into indoor scenarios, the broader spectrum of real-world robotic applications often extends to outdoor settings. As we transition to the vast and complex terrains of outdoor environments, new challenges emerge. Unlike the structured layouts found indoors, outdoor environments lack clear spatial delineations and are riddled with inherent semantic ambiguities. Despite this, humans navigate with ease because we can reason about the unseen. We introduce a new task OUTDOOR, a new mechanism for Large Language Models (LLMs) to accurately hallucinate possible futures, and a new computationally aware success metric for pushing research forward in this more complex domain. Additionally, we show impressive results on both a simulated drone and physical quadruped in outdoor environments. Our agent has no premapping and our formalism outperforms naive LLM-based approaches
isOpenAccess: True
TL\DR: A new task OUTDOOR is introduced, a new mechanism for Large Language Models (LLMs) to accurately hallucinate possible futures, and a new computationally aware success metric for pushing research forward in this more complex domain are introduced.
================================
faculty_name: Yonatan Bisk
faculty_authorid: 3312309
paper_id: b777aa86b5a1d49ce8eababc5c2ee56d3562801e
paper_title: The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment
publication_link: http://arxiv.org/pdf/2302.06117 
year_published: 2023 
abstract_paper:Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.
isOpenAccess: True
TL\DR: This work examines the effects of model design decisions, framework paradigms, and hardware platforms on total model latency through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency.
================================
faculty_name: Yonatan Bisk
faculty_authorid: 3312309
paper_id: e41482f4ee984f17382f6cdd900df094d928be06
paper_title: WebArena: A Realistic Web Environment for Building Autonomous Agents
publication_link: https://arxiv.org/pdf/2307.13854 
year_published: 2023 
abstract_paper:With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41%, significantly lower than the human performance of 78.24%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.
isOpenAccess: True
TL\DR: This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.
================================
faculty_name: Yonatan Bisk
faculty_authorid: 3312309
paper_id: e7b3b692b0816821aafc0d354749bc3802cbf6ac
paper_title: Computational Language Acquisition with Theory of Mind
publication_link: http://arxiv.org/pdf/2303.01502 
year_published: 2023 
abstract_paper:Unlike current state-of-the-art language models, young children actively acquire language through interactions with their surrounding environment and caretakers. One mechanism that has been argued to be critical to language learning is the ability to infer the mental states of other agents in social environments, coined Theory of Mind (ToM) by Premack&Woodruff (1978). Drawing inspiration from the modern operationalized versions of ToM implemented in Rabinowitz et al. (2018) and Zhu et al. (2021), we build language-learning agents equipped with ToM, and measure its effects on the learning process. We model ToM by giving the speaker agent an internal listener model that is trained alongside the speaker and used to rerank potential utterances. We experiment with varying task difficulty, hypothesizing that models will acquire more complex language to adapt to stronger environmental pressures. We find that training speakers with a highly weighted ToM listener component leads to performance gains in our image referential game setting. We also find some evidence that increasing task difficulty in the training process results in more fluent and precise utterances in evaluation. This suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.
isOpenAccess: True
TL\DR: It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.
================================
faculty_name: Jamie Callan
faculty_authorid: 144987107
paper_id: 197d5fbc3764ff18186275545d0764d5b1c7659b
paper_title: Conversational Search with Random Walks over Entity Graphs
publication_link: https://dl.acm.org/doi/pdf/10.1145/3578337.3605125 
year_published: 2023 
abstract_paper:The entities that emerge during a conversation can be used to model topics, but not all entities are equally useful for this task. Modeling the conversation with entity graphs and predicting each entity's centrality in the conversation provides additional information that improves the retrieval of answer passages for the current question. Experiments show that using random walks to estimate entity centrality on conversation entity graphs improves top precision answer passage ranking over competitive transformer-based baselines.
isOpenAccess: True
TL\DR: Experiments show that using random walks to estimate entity centrality on conversation entity graphs improves top precision answer passage ranking over competitive transformer-based baselines.
================================
faculty_name: Jamie Callan
faculty_authorid: 144987107
paper_id: 1e0a4ff0c5d2d850ff5907e310ffcedc9cad9718
paper_title: KALE: Using a K-Sparse Projector for Lexical Expansion
publication_link: https://dl.acm.org/doi/pdf/10.1145/3578337.3605131 
year_published: 2023 
abstract_paper:Recent research has proposed retrieval approaches based on sparse representations and inverted indexes, with terms produced by neural language models and leveraging the advantages from both neural retrieval and lexical matching. This paper proposes KALE, a new lightweight method of this family that uses a small model with a k-sparse projector to convert dense representations into a sparse set of entries from a latent vocabulary. The KALE vocabulary captures semantic concepts than perform well when used in isolation, and perform better when extending the original lexical vocabulary, this way improving first-stage retrieval accuracy. Experiments with the MSMARCOv1 passage retrieval dataset, the TREC Deep Learning dataset, and BEIR datasets, examined the effectiveness of KALE under varying conditions. Results show that the KALE terms can replace the original lexical vocabulary, with gains in accuracy and efficiency. Combining KALE with the original lexical vocabulary, or with other learned terms, can further improve retrieval accuracy with only a modest increase in computational cost.
isOpenAccess: True
TL\DR: KALE is a new lightweight method that uses a small model with a k-sparse projector to convert dense representations into a sparse set of entries from a latent vocabulary, which can replace the original lexical vocabulary with gains in accuracy and efficiency.
================================
faculty_name: Jamie Callan
faculty_authorid: 144987107
paper_id: 6b7eefa15c0a461afeab4fa13cf862c5340fdc2a
paper_title: CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms
publication_link: https://dl.acm.org/doi/pdf/10.1145/3578337.3605126 
year_published: 2023 
abstract_paper:Lexical exact-match systems perform text retrieval efficiently with sparse matching signals and fast retrieval through inverted lists, but naturally suffer from the mismatch between lexical surface form and implicit term semantics. This paper proposes to directly bridge the surface form space and the term semantics space in lexical exact-match retrieval via contextualized surface forms (CSF). Each CSF pairs a lexical surface form with a context source, and is represented by a lexical form weight and a contextualized semantic vector representation. This framework is able to perform sparse lexicon-based retrieval by learning to represent each query and document as a "bag-of-CSFs", simultaneously addressing two key factors in sparse retrieval: vocabulary expansion of surface form and semantic representation of term meaning. At retrieval time, it efficiently matches CSFs through exact-match of learned surface forms, and effectively scores each CSF pair via contextual semantic representations, leading to joint improvement in both term match and term scoring. Multiple experiments show that this approach successfully resolves the main mismatch issues in lexical exact-match retrieval and outperforms state-of-the-art lexical exact-match systems, reaching comparable accuracy as lexical all-to-all soft match systems as an efficient exact-match-based system.
isOpenAccess: True
TL\DR: This paper proposes to directly bridge the surface form space and the term semantics space in lexical exact-match retrieval via contextualized surface forms (CSF), reaching comparable accuracy as lexical all-to-all soft match systems as an efficient exact- match-based system.
================================
faculty_name: Jamie Callan
faculty_authorid: 144987107
paper_id: 88884b8806262a4095036041e3567d450dba39f7
paper_title: Active Retrieval Augmented Generation
publication_link: http://arxiv.org/pdf/2305.06983 
year_published: 2023 
abstract_paper:Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. Code and datasets are available at https://github.com/jzbjyb/FLARE.
isOpenAccess: True
TL\DR: This work proposes Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.
================================
faculty_name: Jamie Callan
faculty_authorid: 144987107
paper_id: ac9ee72a5cd611e9143e385f668af662583721ee
paper_title: Multi-Objective Improvement of Android Applications
publication_link: https://arxiv.org/pdf/2308.11387 
year_published: 2023 
abstract_paper:Non-functional properties, such as runtime or memory use, are important to mobile app users and developers, as they affect user experience. Previous work on automated improvement of non-functional properties in mobile apps failed to address the inherent trade-offs between such properties. We propose a practical approach and the first open-source tool, GIDroid (2023), for multi-objective automated improvement of Android apps. In particular, we use Genetic improvement, a search-based technique that navigates the space of software variants to find improved software. We use a simulation-based testing framework to greatly improve the speed of search. GIDroid contains three state-of-the-art multi-objective algorithms, and two new mutation operators, which cache the results of method calls. Genetic improvement relies on testing to validate patches. Previous work showed that tests in open-source Android applications are scarce. We thus wrote tests for 21 versions of 7 Android apps, creating a new benchmark for performance improvements. We used GIDroid to improve versions of mobile apps where developers had previously found improvements to runtime, memory, and bandwidth use. Our technique automatically re-discovers 64% of existing improvements. We then applied our approach to current versions of software in which there were no known improvements. We were able to improve execution time by up to 35%, and memory use by up to 33% in these apps.
isOpenAccess: True
TL\DR: This work proposes a practical approach and the first open-source tool, GIDroid, for multi-objective automated improvement of Android apps, and uses Genetic improvement, a search-based technique that navigates the space of software variants to find improved software.
================================
faculty_name: Justine Cassell
faculty_authorid: 145431806
paper_id: 24bff26f19051b1413d1e343322c1ae4bba05428
paper_title: When to generate hedges in peer-tutoring interactions
publication_link: https://arxiv.org/pdf/2307.15582 
year_published: 2023 
abstract_paper:This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model’s performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.
isOpenAccess: True
TL\DR: The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model’s performance and provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation.
================================
faculty_name: Justine Cassell
faculty_authorid: 145431806
paper_id: 74fedee9d809ec766a2089a89435fa7dd1346693
paper_title: How About Kind of Generating Hedges using End-to-End Neural Models?
publication_link: http://arxiv.org/pdf/2306.14696 
year_published: 2023 
abstract_paper:Hedging is a strategy for softening the impact of a statement in conversation. In reducing the strength of an expression, it may help to avoid embarrassment (more technically, “face threat”) to one’s listener. For this reason, it is often found in contexts of instruction, such as tutoring. In this work, we develop a model of hedge generation based on i) fine-tuning state-of-the-art language models trained on human-human tutoring data, followed by ii) reranking to select the candidate that best matches the expected hedging strategy within a candidate pool using a hedge classifier. We apply this method to a natural peer-tutoring corpus containing a significant number of disfluencies, repetitions, and repairs. The results show that generation in this noisy environment is feasible with reranking. By conducting an error analysis for both approaches, we reveal the challenges faced by systems attempting to accomplish both social and task-oriented goals in conversation.
isOpenAccess: True
TL\DR: This work develops a model of hedge generation based on fine-tuning state-of-the-art language models trained on human-human tutoring data, followed by reranking to select the candidate that best matches the expected hedging strategy within a candidate pool using a hedge classifier.
================================
faculty_name: Justine Cassell
faculty_authorid: 145431806
paper_id: a82f56482b9e63714ea0d1948ac3aa6edb092001
paper_title: Beyond Single-Mindedness: A Figure-Ground Reversal for the Cognitive Sciences
publication_link: https://repository.ubn.ru.nl/bitstream/handle/2066/291926/1/291926.pdf 
year_published: 2023 
abstract_paper:A fundamental fact about human minds is that they are never truly alone: all minds are steeped in situated interaction. That social interaction matters is recognized by any experimentalist who seeks to exclude its influence by studying individuals in isolation. On this view, interaction complicates cognition. Here, we explore the more radical stance that interaction co-constitutes cognition: that we benefit from looking beyond single minds toward cognition as a process involving interacting minds. All around the cognitive sciences, there are approaches that put interaction center stage. Their diverse and pluralistic origins may obscure the fact that collectively, they harbor insights and methods that can respecify foundational assumptions and fuel novel interdisciplinary work. What might the cognitive sciences gain from stronger interactional foundations? This represents, we believe, one of the key questions for the future. Writing as a transdisciplinary collective assembled from across the classic cognitive science hexagon and beyond, we highlight the opportunity for a figure-ground reversal that puts interaction at the heart of cognition. The interactive stance is a way of seeing that deserves to be a key part of the conceptual toolkit of cognitive scientists.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Justine Cassell
faculty_authorid: 145431806
paper_id: b3efaa75beada858414a5ba2346dec317203633c
paper_title: "You might think about slightly revising the title”: Identifying Hedges in Peer-tutoring Interactions
publication_link: https://aclanthology.org/2022.acl-long.153.pdf 
year_published: 2023 
abstract_paper:Hedges have an important role in the management of rapport. In peer-tutoring, they are notably used by tutors in dyads experiencing low rapport to tone down the impact of instructions and negative feedback.Pursuing the objective of building a tutoring agent that manages rapport with teenagers in order to improve learning, we used a multimodal peer-tutoring dataset to construct a computational framework for identifying hedges. We compared approaches relying on pre-trained resources with others that integrate insights from the social science literature. Our best performance involved a hybrid approach that outperforms the existing baseline while being easier to interpret. We employ a model explainability tool to explore the features that characterize hedges in peer-tutoring conversations, and we identify some novel features, and the benefits of a such a hybrid model approach.
isOpenAccess: True
TL\DR: A model explainability tool is employed to explore the features that characterize hedges in peer-tutoring conversations, and some novel features, and the benefits of a such a hybrid model approach are identified.
================================
faculty_name: Mona Diab
faculty_authorid: 2138579860
paper_id: 0a94fbb5e1c93513523f00e75d672ef4553861f9
paper_title: Can Large Language Models Infer Causation from Correlation?
publication_link: http://arxiv.org/pdf/2306.05836 
year_published: 2023 
abstract_paper:Causal inference is one of the hallmarks of human intelligence. While the field of CausalNLP has attracted much interest in the recent years, existing causal inference datasets in NLP primarily rely on discovering causality from empirical knowledge (e.g., commonsense knowledge). In this work, we propose the first benchmark dataset to test the pure causal inference skills of large language models (LLMs). Specifically, we formulate a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables. We curate a large-scale dataset of more than 200K samples, on which we evaluate seventeen existing LLMs. Through our experiments, we identify a key shortcoming of LLMs in terms of their causal inference skills, and show that these models achieve almost close to random performance on the task. This shortcoming is somewhat mitigated when we try to re-purpose LLMs for this skill via finetuning, but we find that these models still fail to generalize -- they can only perform causal inference in in-distribution settings when variable names and textual expressions used in the queries are similar to those in the training set, but fail in out-of-distribution settings generated by perturbing these queries. Corr2Cause is a challenging task for LLMs, and would be helpful in guiding future research on improving LLMs' pure reasoning skills and generalizability. Our data is at https://huggingface.co/datasets/causalnlp/corr2cause. Our code is at https://github.com/causalNLP/corr2cause.
isOpenAccess: True
TL\DR: This work proposes the first benchmark dataset to test the pure causal inference skills of large language models (LLMs), and formulates a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables.
================================
faculty_name: Mona Diab
faculty_authorid: 2138579860
paper_id: 4286d07449447f3bfffc1eeb2ee0de9b00dfadfd
paper_title: ALERT: Adapt Language Models to Reasoning Tasks
publication_link: https://aclanthology.org/2023.acl-long.60.pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: The extensive empirical analysis shows that language models learn more reasoning skills such as textual entailment, abductive reasoning, and analogical reasoning during the finetuning stage compared to pretraining stage, but also finds that when language models are finetuned they tend to overfit to the prompt template, which hurts the robustness of models causing generalization problems.
================================
faculty_name: Mona Diab
faculty_authorid: 2138579860
paper_id: 5e2f8088647e357bb6440d271ed1fcc4d5ed7e7c
paper_title: Care4Lang at MEDIQA-Chat 2023: Fine-tuning Language Models for Classifying and Summarizing Clinical Dialogues
publication_link: https://aclanthology.org/2023.clinicalnlp-1.55.pdf 
year_published: 2023 
abstract_paper:Summarizing medical conversations is one of the tasks proposed by MEDIQA-Chat to promote research on automatic clinical note generation from doctor-patient conversations. In this paper, we present our submission to this task using fine-tuned language models, including T5, BART and BioGPT models. The fine-tuned models are evaluated using ensemble metrics including ROUGE, BERTScore andBLEURT. Among the fine-tuned models, Flan-T5 achieved the highest aggregated score for dialogue summarization.
isOpenAccess: True
TL\DR: This paper presents their submission to this task using fine-tuned language models, including T5, BART and BioGPT models, and finds Flan-T5 achieved the highest aggregated score for dialogue summarization.
================================
faculty_name: Mona Diab
faculty_authorid: 2138579860
paper_id: 99bfe503743c5ec8e16e50ab8438159cdb533a89
paper_title: The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations
publication_link: https://arxiv.org/pdf/2310.04988 
year_published: 2023 
abstract_paper:The recent advancements in Large Language Models (LLMs) have garnered widespread acclaim for their remarkable emerging capabilities. However, the issue of hallucination has parallelly emerged as a by-product, posing significant concerns. While some recent endeavors have been made to identify and mitigate different types of hallucination, there has been a limited emphasis on the nuanced categorization of hallucination and associated mitigation methods. To address this gap, we offer a fine-grained discourse on profiling hallucination based on its degree, orientation, and category, along with offering strategies for alleviation. As such, we define two overarching orientations of hallucination: (i) factual mirage (FM) and (ii) silver lining (SL). To provide a more comprehensive understanding, both orientations are further sub-categorized into intrinsic and extrinsic, with three degrees of severity - (i) mild, (ii) moderate, and (iii) alarming. We also meticulously categorize hallucination into six types: (i) acronym ambiguity, (ii) numeric nuisance, (iii) generated golem, (iv) virtual voice, (v) geographic erratum, and (vi) time wrap. Furthermore, we curate HallucInation eLiciTation (HILT), a publicly available dataset comprising of 75,000 samples generated using 15 contemporary LLMs along with human annotations for the aforementioned categories. Finally, to establish a method for quantifying and to offer a comparative spectrum that allows us to evaluate and rank LLMs based on their vulnerability to producing hallucinations, we propose Hallucination Vulnerability Index (HVI). We firmly believe that HVI holds significant value as a tool for the wider NLP community, with the potential to serve as a rubric in AI-related policy-making. In conclusion, we propose two solution strategies for mitigating hallucinations.
isOpenAccess: True
TL\DR: This work defines two overarching orientations of hallucination and proposes two solution strategies for mitigating hallucinations, and firmly believes that HVI holds significant value as a tool for the wider NLP community, with the potential to serve as a rubric in AI-related policy-making.
================================
faculty_name: Mona Diab
faculty_authorid: 2138579860
paper_id: c218cd1772999517b137bbbc9872c4f67e540b7f
paper_title: OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models
publication_link: https://aclanthology.org/2023.nlrse-1.10.pdf 
year_published: 2023 
abstract_paper:We conduct a thorough investigation into the reasoning capabilities of Large Language Models (LLMs), focusing specifically on the Open Pretrained Transformers (OPT) models as a representative of such models. Our study entails finetuning three different sizes of OPT on a carefully curated reasoning corpus, resulting in two sets of finetuned models: OPT-R, finetuned without explanations, and OPT-RE, finetuned with explanations. We then evaluate all models on 57 out-of-domain tasks drawn from the Super-NaturalInstructions benchmark, covering 26 distinct reasoning skills, utilizing three prompting techniques. Through a comprehensive grid of 27 configurations and 6,156 test evaluations, we investigate the dimensions of finetuning, prompting, and scale to understand the role of explanations on different reasoning skills. Our findings reveal that having explanations in the fewshot exemplar has no significant impact on the model’s performance when the model is finetuned, while positively affecting the non-finetuned counterpart. Moreover, we observe a slight yet consistent increase in classification accuracy as we incorporate explanations during prompting and finetuning, respectively. Finally, we offer insights on which reasoning skills benefit the most from incorporating explanations during finetuning and prompting, such as Numerical (+20.4%) and Analogical (+13.9%) reasoning, as well as skills that exhibit negligible or negative effects.
isOpenAccess: True
TL\DR: It is revealed that having explanations in the fewshot exemplar has no significant impact on the model’s performance when the model is finetuned, while positively affecting the non-finetuned counterpart, and a slight yet consistent increase in classification accuracy as the authors incorporate explanations during prompting and finetuning.
================================
faculty_name: Mona Diab
faculty_authorid: 2138579860
paper_id: f727f928e7e179307d8d4a1da2387393f2bd7915
paper_title: Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models
publication_link: https://aclanthology.org/2023.eacl-main.199.pdf 
year_published: 2023 
abstract_paper:Language models can memorize a considerable amount of factual information during pretraining that can be elicited through prompting or finetuning models on tasks like question answering. In this paper, we discuss approaches to measuring model factual beliefs, updating incorrect factual beliefs in models, and visualizing graphical relationships between factual beliefs. Our main contributions include: (1) new metrics for evaluating belief-updating methods focusing on the logical consistency of beliefs, (2) a training objective for Sequential, Local, and Generalizing updates (SLAG) that improves the performance of existing hypernetwork approaches, and (3) the introduction of the belief graph, a new form of visualization for language models that shows relationships between stored model beliefs. Our experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency. Although off-the-shelf optimizers are surprisingly strong belief-updating baselines, our learned optimizers can outperform them in more difficult settings than have been considered in past work.
isOpenAccess: True
TL\DR: The experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency, and off-the-shelf optimizers can outperform them in more difficult settings than have been considered in past work.
================================
faculty_name: Mona Diab
faculty_authorid: 1400553531
paper_id: 27b69c63d3ca627e64da78b8e5ef0c49b2840ea6
paper_title: Comparison of the structures and topologies of plasma extracted circulating nuclear and mitochondrial cell-free DNA
publication_link: https://www.frontiersin.org/articles/10.3389/fgene.2023.1104732/pdf 
year_published: 2023 
abstract_paper:Introduction: The function, origin and structural features of circulating nuclear DNA (cir-nDNA) and mitochondrial DNA (cir-mtDNA) are poorly known, even though they have been investigated in numerous clinical studies, and are involved in a number of routine clinical applications. Based on our previous report disproving the conventional plasma isolation used for cirDNA analysis, this work enables a direct topological comparison of the circulating structures associated with nuclear DNA and mitochondrial cell-free DNA. Materials and methods: We used a Q-PCR and low-pass whole genome sequencing (LP-WGS) combination approach of cir-nDNA and cir-mtDNA, extracted using a procedure that eliminates platelet activation during the plasma isolation process to prevent mitochondria release in the extracellular milieu. Various physical procedures, such as filtration and differential centrifugation, were employed to infer their circulating structures. Results: DSP-S cir-mtDNA mean size profiles distributed on a slightly shorter range than SSP-S. SSP-S detected 40-fold more low-sized cir-mtDNA fragments (<90 bp/nt) and three-fold less long-sized fragments (>200 bp/nt) than DSP-S. The ratio of the fragment number below 90 bp over the fragment number above 200 bp was very homogenous among both DSP-S and SSP-S profiles, being 134-fold lower with DSP-S than with SSP-S. Cir-mtDNA and cir-nDNA DSP-S and SSP-S mean size profiles of healthy individuals ranged in different intervals with periodic sub-peaks only detectable with cir-nDNA. The very low amount of cir-mtDNA fragments of short size observed suggested that most of the cir-mtDNA is poorly fragmented and appearing longer than ∼1,000 bp, the readout limit of this LP-WGS method. Data suggested that cir-nDNA is, among DNA extracted in plasma, associated with ∼8.6% of large structures (apoptotic bodies, large extracellular vesicles (EVs), cell debris…), ∼27.7% in chromatin and small EVs and ∼63.7% mainly in oligo- and mono-nucleosomes. By contrast, cir-mtDNA appeared to be preponderantly (75.7%) associated with extracellular mitochondria, either in its free form or with large EVs; to a lesser extent, it was also associated with other structures: small EVs (∼18.4%), and exosomes or protein complexes (∼5.9%). Conclusion: This is the first study to directly compare the structural features of cir-nDNA and cir-mtDNA. The significant differences revealed between both are due to the DNA topological structure contained in the nucleus (chromatin) and in the mitochondria (plasmid) that determine their biological stability in blood. Although cir-nDNA and cir-mtDNA are principally associated with mono-nucleosomes and cell-free mitochondria, our study highlights the diversity of the circulating structures associated with cell-free DNA. They consequently have different pharmacokinetics as well as physiological functions. Thus, any accurate evaluation of their biological or diagnostic individual properties must relies on appropriate pre-analytics, and optimally on the isolation or enrichment of one category of their cirDNA associated structures.
isOpenAccess: True
TL\DR: This is the first study to directly compare the structural features of cir-nDNA and cir-mtDNA, and highlights the diversity of the circulating structures associated with cell-free DNA.
================================
faculty_name: Mona Diab
faculty_authorid: 1400553531
paper_id: 3503a4c6163197136bbd880c9db514e8c01b6936
paper_title: Cytomegalovirus at the crossroads of immunosenescence and oncogenesis
publication_link: https://www.explorationpub.com/uploads/Article/A100386/100386.pdf 
year_published: 2023 
abstract_paper:Human cytomegalovirus (HCMV), whose genome is around 235 kb, is a ubiquitous human herpesvirus that infects between 40% and 95% of the population. Though HCMV infection is commonly asymptomatic and leads to subtle clinical symptoms, it can promote robust immune responses and establish lifelong latency. In addition, in immunocompromised hosts, including individuals with acquired immunodeficiency syndrome (AIDS), transplant recipients, and developing fetuses it can lead to severe diseases. Immunosenescence, well-defined as the alterations in the immune system, is linked mainly to aging and has been recently gathering considerable attention. Senescence was characterized by an elevated inflammation and hence considered a powerful contributor to “inflammaging” that is measured mainly by tumor necrosis factor-α (TNF-α), interleukin-6 (IL-6), and C-reactive protein (CRP) levels as well as latent viral infections, for instance, cytomegalovirus (CMV). Inflammaging resulted in a senescence-associated secretory phenotype (SASP). HCMV is markedly associated with accelerated aging of the immune system as well as several age-associated diseases that accumulate and subsequently deteriorate the immune responses, thus have been linked to mortality, declined vaccine efficacy, serious diseases, and tumors in the elderly. HCMV triggers or exacerbates immunosenescence; on the other hand, the weakened immune responses and inflammaging favor viral reactivation and highlight the role of HCMV in aging as well as viral-associated tumors. HCMV reactivation resulting in sequential lytic and latent viral cycles could contribute to HCMV genomic variability. Besides the oncomodulatory role and transforming capacities of HCMV, the immune-privileged tumor microenvironment has been considered the main element in tumor progression and aggressiveness. Therefore, the interplay between HCMV, immunosenescence, and cancer will aid in discovering new therapeutic approaches that target HCMV and act as immune response boosters mainly to fight cancers of poor prognosis, particularly in the elderly population.
isOpenAccess: True
TL\DR: The interplay between HCMV, immunosenescence, and cancer will aid in discovering new therapeutic approaches that target H CMV and act as immune response boosters mainly to fight cancers of poor prognosis, particularly in the elderly population.
================================
faculty_name: Mona Diab
faculty_authorid: 1400553531
paper_id: 4bb86a709eb9f47242f8b7f93e9a9c24bdb74870
paper_title: Aspalathus linearis (Rooibos) Targets Adipocytes and Obesity-Associated Inflammation
publication_link: https://www.mdpi.com/2072-6643/15/7/1751/pdf?version=1680572571 
year_published: 2023 
abstract_paper:Excess weight and obesity are the fifth leading cause of death globally, and sustained efforts from health professionals and researchers are required to mitigate this pandemic-scale problem. Polyphenols and flavonoids found in Aspalathus linearis—a plant widely consumed as Rooibos tea—are increasingly being investigated for their positive effects on various health issues including inflammation. The aim of our study was to examine the effect of Rooibos extract on obesity and the associated low-grade chronic inflammatory state by testing antioxidant activity, cytokine secretions, macrophage polarization and the differentiation of human adipocytes through the development of adipospheroids. Rooibos extract significantly decreased ROS production and the secretion of pro-inflammatory cytokines (IFN-γ, IL-12, IL-2 and IL-17a) in human leukocytes. Additionally, Rooibos extract down-regulated LPS-induced macrophage M1 polarization, shown by a significant decrease in the expression of pro-inflammatory cytokines: TNFα, IL-8, IL-6, IL-1β and CXCL10. In addition, Rooibos inhibited intracellular lipid accumulation and reduced adipogenesis by decreasing the expression of PPARγ, Ap2 and HSL in adipospheroids. A significant decrease in leptin expression was noted and this, more interestingly, was accompanied by a significant increase in adiponectin expression. Using a co-culture system between macrophages and adipocytes, Rooibos extract significantly decreased the expression of all studied pro-inflammatory cytokines and particularly leptin, and increased adiponectin expression. Thus, adding Rooibos tea to the daily diet is likely to prevent the development of obesity associated with chronic low-level inflammation.
isOpenAccess: True
TL\DR: Rooibos extract significantly decreased the expression of all studied pro-inflammatory cytokines and particularly leptin, and increased adiponectin expression, likely to prevent the development of obesity associated with chronic low-level inflammation.
================================
faculty_name: Mona Diab
faculty_authorid: 1400553531
paper_id: 81513416b80f753166e224b34b599e9385980a97
paper_title: Emerging Therapeutic Approaches to Target the Dark Side of Senescent Cells: New Hopes to Treat Aging as a Disease and to Delay Age-Related Pathologies
publication_link: https://www.mdpi.com/2073-4409/12/6/915/pdf?version=1678958147 
year_published: 2023 
abstract_paper:Life expectancy has drastically increased over the last few decades worldwide, with important social and medical burdens and costs. To stay healthy longer and to avoid chronic disease have become essential issues. Organismal aging is a complex process that involves progressive destruction of tissue functionality and loss of regenerative capacity. One of the most important aging hallmarks is cellular senescence, which is a stable state of cell cycle arrest that occurs in response to cumulated cell stresses and damages. Cellular senescence is a physiological mechanism that has both beneficial and detrimental consequences. Senescence limits tumorigenesis, lifelong tissue damage, and is involved in different biological processes, such as morphogenesis, regeneration, and wound healing. However, in the elderly, senescent cells increasingly accumulate in several organs and secrete a combination of senescence associated factors, contributing to the development of various age-related diseases, including cancer. Several studies have revealed major molecular pathways controlling the senescent phenotype, as well as the ones regulating its interactions with the immune system. Attenuating the senescence-associated secretory phenotype (SASP) or eliminating senescent cells have emerged as attractive strategies aiming to reverse or delay the onset of aging diseases. Here, we review current senotherapies designed to suppress the deleterious effect of SASP by senomorphics or to selectively kill senescent cells by “senolytics” or by immune system-based approaches. These recent investigations are promising as radical new controls of aging pathologies and associated multimorbidities.
isOpenAccess: True
TL\DR: Current senotherapies designed to suppress the deleterious effect of SASP by senomorphics or to selectively kill senescent cells by “senolytics” or by immune system-based approaches are reviewed.
================================
faculty_name: Mona Diab
faculty_authorid: 1400553531
paper_id: bcfbcbbe128ee74e39cb8698e5dfd6047b690487
paper_title: Crosstalk of Inflammatory Cytokines within the Breast Tumor Microenvironment
publication_link: https://www.mdpi.com/1422-0067/24/4/4002/pdf?version=1676767442 
year_published: 2023 
abstract_paper:Several immune and immunocompetent cells, including dendritic cells, macrophages, adipocytes, natural killer cells, T cells, and B cells, are significantly correlated with the complex discipline of oncology. Cytotoxic innate and adaptive immune cells can block tumor proliferation, and others can prevent the immune system from rejecting malignant cells and provide a favorable environment for tumor progression. These cells communicate with the microenvironment through cytokines, a chemical messenger, in an endocrine, paracrine, or autocrine manner. These cytokines play an important role in health and disease, particularly in host immune responses to infection and inflammation. They include chemokines, interleukins (ILs), adipokines, interferons, colony-stimulating factors (CSFs), and tumor necrosis factor (TNF), which are produced by a wide range of cells, including immune cells, such as macrophages, B-cells, T-cells, and mast cells, as well as endothelial cells, fibroblasts, a variety of stromal cells, and some cancer cells. Cytokines play a crucial role in cancer and cancer-related inflammation, with direct and indirect effects on tumor antagonistic or tumor promoting functions. They have been extensively researched as immunostimulatory mediators to promote the generation, migration and recruitment of immune cells that contribute to an effective antitumor immune response or pro-tumor microenvironment. Thus, in many cancers such as breast cancer, cytokines including leptin, IL-1B, IL-6, IL-8, IL-23, IL-17, and IL-10 stimulate while others including IL-2, IL-12, and IFN-γ, inhibit cancer proliferation and/or invasion and enhance the body’s anti-tumor defense. Indeed, the multifactorial functions of cytokines in tumorigenesis will advance our understanding of cytokine crosstalk pathways in the tumor microenvironment, such as JAK/STAT, PI3K, AKT, Rac, MAPK, NF-κB, JunB, cFos, and mTOR, which are involved in angiogenesis, cancer proliferation and metastasis. Accordingly, targeting and blocking tumor-promoting cytokines or activating and amplifying tumor-inhibiting cytokines are considered cancer-directed therapies. Here, we focus on the role of the inflammatory cytokine system in pro- and anti-tumor immune responses, discuss cytokine pathways involved in immune responses to cancer and some anti-cancer therapeutic applications.
isOpenAccess: True
TL\DR: The role of the inflammatory cytokine system in pro- and anti-tumor immune responses is focused on, and cytokine pathways involved in immune responses to cancer and some anti-cancer therapeutic applications are discussed.
================================
faculty_name: Mona Diab
faculty_authorid: 1700007
paper_id: 45f7ab2dd1bd86703f3fc0f713d35851ae15b038
paper_title: Author Correction: Arabic natural language processing for Qur’anic research: a systematic review
publication_link: https://link.springer.com/content/pdf/10.1007/s10462-023-10390-x.pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Mona Diab
faculty_authorid: 1700007
paper_id: c5849f406e8263806a84e1a407ec0e0fe131bd5c
paper_title: Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology
publication_link: https://aclanthology.org/2023.iwslt-1.2.pdf 
year_published: 2023 
abstract_paper:We present the ACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages. This dataset enables further research into multilingual speech translation under realistic recording conditions with unsegmented audio and domain-specific terminology, applying NLP tools to text and speech in the technical domain, and evaluating and improving model robustness to diverse speaker demographics.
isOpenAccess: True
TL\DR: This dataset enables further research into multilingual speech translation under realistic recording conditions with unsegmented audio and domain-specific terminology, applying NLP tools to text and speech in the technical domain, and evaluating and improving model robustness to diverse speaker demographics.
================================
faculty_name: Mona Diab
faculty_authorid: 2006800765
paper_id: 11ff985b42649154d87015b8a4c2cf07abf82fef
paper_title: A bleeding bite: crotalinae snake envonamation
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Mona Diab
faculty_authorid: 6897753
paper_id: 4674d83e0c54a9a7b6833121cc2f40cd21f2579c
paper_title: PAMR1 negatively impacts cell proliferation and migration of Human Colon Cancer HT29 Cell Line
publication_link: https://www.biorxiv.org/content/biorxiv/early/2022/09/08/2022.09.07.506931.full.pdf 
year_published: 2023 
abstract_paper:Colorectal cancer (CRC) is becoming one of the most prevalent cancers worldwide. Among cancers, it ranks the third place in terms of incidence and the second in terms of mortality. Even though immunological test allows fast and easy diagnostic method, there is no specific and reliable methods for early detection of CRC. Despite different treatments, high risk of re-occurrence is associated with advanced and metastatic CRC stages. An exhaustive knowledge on specific biomarkers or molecular actors involved in CRC could help to eradicate tumors or limit cancer recurrence. In this study, we focused on PAMR1 (Peptidase Domain Containing Associated with Muscle Regeneration 1), which is already considered as a tumor suppressor in breast and cervical cancers. In silico analysis of RNASeq data showed that PAMR1 was significantly downregulated in CRC tissues compared to their adjacent normal ones, as well as in cervical cancer. Our analysis showed that this downregulation, probably due to promoter hypermethylation, such as in breast cancer tissues, appeared in the four cancer stages as early as the first stage. In consistency with in silico analyses, the expression of PAMR1 was found to be lower at the transcript and protein levels in CRC tissue samples compared to normal ones, as well as in different CRC cell lines (HCT116, HT29, and SW620) compared to normal colon cell line (CCD841CoN). To understand the role of PAMR1 in CRC cancer, recombinant purified PAMR1 or concentrated secretome from CHO overexpressing PAMR1 were used to exogenously treat CRC cell lines with a focus on HT-29 cells as well as Hela cervical cancer cell line known to be sensitive to PAMR1. Transient or stable transfections were also performed to determine the impact of PAMR1 overexpression in HT29 and/or HeLa cells. In this study, we finally showed that presence of PAMR1 could reduce both cell proliferation and cell migration with a positive correlation between these biological effects and PAMR1’s quantity. This implies that PAMR1 expresses anti-proliferative and anti-migrative effects in CRC. Further studies to be done in order to confirm the tumor suppressive role of PAMR1 in CRC.
isOpenAccess: True
TL\DR: It is shown that presence of PAMR1 could reduce both cell proliferation and cell migration with a positive correlation between these biological effects and PAMr1’s quantity, which implies that PamR1 expresses anti-proliferative and anti-migrative effects in CRC.
================================
faculty_name: Mona Diab
faculty_authorid: 2267988266
paper_id: e818b74b7415fb43deeb80c1a33ffd5be76abed4
paper_title: A Combination of Ruthenium Complexes and Photosensitizers to Treat Colorectal Cancer
publication_link: https://www.preprints.org/manuscript/202309.1909/v1/download 
year_published: 2023 
abstract_paper:Treatment regimens are regularly evolving alongside novel therapies and drugs. Such evolution is necessary to circumvent resistance mechanisms and to give patients the best possible health care. When dealing with cancer, most regimens involve multiple treatments (surgery, radiation therapy, chemotherapy, immunotherapy, etc.). The purpose of this study was to associate in a single compound metal-based drugs and photosensitizers to combine chemotherapy and photodynamic therapy. Two arene–ruthenium tetrapyridylporphyrin compounds (2H-TPyP-arene-Ru and Zn-TPyP-arene-Ru) have been synthesized and evaluated on two colorectal cancer cell lines (HCT116 and HT-29). Their cytotoxicity and phototoxicity have been evaluated. In addition, the anticancer mechanism and the cell death process mediated by the two compounds were studied. The results showed that the two arene–ruthenium photosensitizer-containing complexes have a strong phototoxic effect after photoactivation. The 2H-TPyP-arene-Ru complex induced outstanding cytotoxicity when compared to the Zn-TPyP-arene-Ru analogue. Moreover, under light, these two arene–ruthenium photosensitizers induce an apoptotic process in human colorectal cancer cell lines.
isOpenAccess: True
TL\DR: It is shown that presence of PAMR1 could reduce both cell proliferation and cell migration with a positive correlation between these biological effects and PAMr1’s quantity, which implies that PamR1 expresses anti-proliferative and anti-migrative effects in CRC.
================================
faculty_name: Fernando Diaz
faculty_authorid: 2171780039
paper_id: e59a99c198ee4012e34fd79d7cb33be75d0a120d
paper_title: Amplification-free, highly sensitive electrochemical DNA-based sensor for simultaneous detection of stx1 and stx2 genes of Shiga toxin-producing E. coli (STEC)
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Fernando Diaz
faculty_authorid: 1435898066
paper_id: 442b8568036949fc51734ef47f41313d9afef6db
paper_title: Discordance Between Social Vulnerability and Cancer-Related Mortality in Border Counties - A Letter to the Editor Regarding “Local Social Vulnerability as a Predictor for Cancer-Related Mortality Among US Counties”
publication_link: https://academic.oup.com/oncolo/advance-article-pdf/doi/10.1093/oncolo/oyad271/51791454/oyad271.pdf 
year_published: 2023 
abstract_paper:This letter to the editor remarks on results of a recently published study and highlights the need for multinational and interinstitutional registries so health departments in the US and Latin American countries can accurately capture cancer incidence and mortality data.
isOpenAccess: True
TL\DR: None
================================
faculty_name: Fernando Diaz
faculty_authorid: 1435898066
paper_id: 70753c30b5eef5fd9bf8673cee4b586105f47c20
paper_title: Cross-border utilization of cancer care by patients in the US and Mexico – a survey of Mexican oncologists
publication_link: https://globalizationandhealth.biomedcentral.com/counter/pdf/10.1186/s12992-023-00983-0 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: The type of care sought, as well as the reasons for seeking it, differ between US and Mexico-based patients, highlighting unmet needs for patients with cancer in both countries and calling for policy changes to improve outcomes in border regions.
================================
faculty_name: Fernando Diaz
faculty_authorid: 146699947
paper_id: cda03f3d8b1eff888174c0dc4262e1dc73be2d49
paper_title: Population well-being and the COVID-19 vaccination program in Chile: evidence from Google Trends
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: It is found that mental well-being responds positively to the percentage of inoculated people, and this phenomenon appears to be permanent and affected by socioeconomic status, with the wealthier population experiencing greater improvements than the less wealthy.
================================
faculty_name: Fernando Diaz
faculty_authorid: 2200736391
paper_id: 574fe6378d43b1f1f2e8467bda1574292d6c586d
paper_title: Females translate male mRNA transferred during mating
publication_link: Not given 
year_published: 2023 
abstract_paper:Although RNA is found in the seminal fluid of diverse organisms, it is unknown whether this RNA is functional within females. Here, we develop an experimental proteomic method called VESPA (Variant Enabled SILAC Proteomic Analysis) to test the hypothesis that Drosophila male seminal fluid RNA is translated by females. We find strong evidence for 67 male-derived, female-translated proteins (mdFTPs) in female lower reproductive tracts at six hours postmating, many with predicted functions relevant to reproduction. Gene knockout experiments indicate that genes coding for mdFTPs play diverse roles in postmating interactions, with effects on fertilization efficiency, and the formation and persistence of the insemination reaction mass, a trait hypothesized to be involved in sexual conflict. These findings advance our understanding of reproduction by revealing a novel mechanism of postmating molecular interactions between the sexes that strengthens and extends male influences on reproductive outcomes in previously unrecognized ways. Given the diverse species known to carry RNA in seminal fluid, this discovery has broad significance for understanding molecular mechanisms of cooperation and conflict during reproduction.
isOpenAccess: True
TL\DR: It is found that mental well-being responds positively to the percentage of inoculated people, and this phenomenon appears to be permanent and affected by socioeconomic status, with the wealthier population experiencing greater improvements than the less wealthy.
================================
faculty_name: Fernando Diaz
faculty_authorid: 2200736391
paper_id: cda71255a5e02e0d3a5fe99e711caea09417bf3f
paper_title: Transcriptional Misexpression in Hybrids between Species Linked by Gene Flow Is Associated With Patterns of Sequence Divergence
publication_link: https://academic.oup.com/gbe/article-pdf/15/5/evad071/50385144/evad071.pdf 
year_published: 2023 
abstract_paper:Abstract The extent to which hybridization disrupts a gene's pattern of expression likely governs its propensity for introgression, whereas its extent of molecular divergence can itself underlie such disruption. Together, these phenomena shape the landscape of sequence and transcriptional divergence across the genome as species diverge. To understand this process, we characterize gene expression inheritance, regulatory divergence, and molecular divergence in the reproductive transcriptomes of species linked by gene flow: the fruit flies Anastrepha fraterculus and A. obliqua, which show evidence of gene flow despite clear evolutionary divergence. We find that their transcriptional patterns are a mosaic between those typically observed within and between allopatric species. Transcripts showing transgressive expression in hybrids or cis-regulatory divergence between species are associated with greater sequence divergence. This may reflect pleiotropic constraints that make them resistant to gene flow or they may be more likely to experience divergent selection. Although these more divergent gene classes are likely to be important contributors to species differences, they are relatively rare. Instead, most differentially regulated transcripts, including those linked to reproduction, show high degrees of dominance in hybrids and trans-regulated divergence between species, suggesting widespread genetic compatibility that potentially allowed for introgression. These findings provide insights into how postzygotic isolating mechanisms might evolve in the presence of gene flow: regions showing cis-regulatory divergence or transgressive expression contribute to reproductive isolation, whereas regions with dominant expression and trans-regulatory divergence allow for introgression. These patterns create a genomic mosaic of transcriptional regulation that is tied to sequence divergence.
isOpenAccess: True
TL\DR: Analysis of reproductive transcriptomes of fruit flies linked by gene flow provides insights into how postzygotic isolating mechanisms might evolve in the presence of gene flow: regions showing cis-regulatory divergence or transgressive expression contribute to reproductive isolation, whereas regions with dominant expression and trans-regulations allow for introgression.
================================
faculty_name: Fernando Diaz
faculty_authorid: 145472321
paper_id: a76e7e394112a26116446a2920467a2702de5f56
paper_title: Pre-vaccination CD56 dimCD16 +NK cell abundance and T h1/T h17 ratio predict responsiveness to conjugated pneumococcal vaccine in older adults
publication_link: https://journals.aai.org/jimmunol/article-pdf/210/1_Supplement/252.03/1632514/252_03.pdf 
year_published: 2023 
abstract_paper:
 Older adults are at high risk of morbidity and mortality from Streptococcus pneumoniae (pneumococcus) infections. There are two available vaccines for pneumococcus: T-cell-independent capsular polysaccharide Pneumovax and T-cell-dependent conjugated Prevnar. However, how older adults respond to these vaccines at the cellular level and whether there are baseline predictors for responsiveness, is not known. To address this, we recruited older adults (60+ yrs), who are vaccinated with Prevnar (n=19) or Pneumovax (n=20). Vaccine responsiveness was quantified using opsonophagocytic assays, which revealed that both vaccines induce strong responses. Interestingly, sex was associated with Prevnar responses, where women mounted stronger responses than men. Pre-vaccination flow cytometry data showed that Th1 cells positively, Th17 cells negatively correlated with Prevnar responses. Furthermore, bulk RNA-seq data from PBMCs showed that baseline expression levels of cytotoxic genes (NCAM1, GNLY, PRF1) are negatively associated with Prevnar responses. scRNA-seq data from top and bottom responders showed that this cytotoxicity signature stems from CD56 dimCD16 +NK cells, where having more of these cells are detrimental to responses. Interestingly, women had significantly higher Th1, lower Th17 and lower CD16+ NK cells compared to men, which explains their stronger Prevnar responses. This is the first study to uncover older adults’ responses to two pneumococcal vaccines; we uncovered an activated immune phenotype of Th and NK cell subsets that impedes responses to Prevnar. Interestingly, this phenotype only affected adjuvanted vaccine responses, providing an opportunity for precision vaccinology for pneumococcus disease.
 Supported by grants from National Institute of Health (R35 GM124922, R01 AG052608) and JAX cancer center (JAX-CC).
isOpenAccess: True
TL\DR: This is the first study to uncover older adults’ responses to two pneumococcal vaccines; an activated immune phenotype of Th and NK cell subsets that impedes responses to Prevnar is uncovered.
================================
faculty_name: Fernando Diaz
faculty_authorid: 145472333
paper_id: 55704caaf3d31e1795a1ca0c3bed9e77ae3a3c95
paper_title: Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision
publication_link: http://arxiv.org/pdf/2306.07908 
year_published: 2023 
abstract_paper:Across a variety of ranking tasks, researchers use reciprocal rank to measure the effectiveness for users interested in exactly one relevant item. Despite its widespread use, evidence suggests that reciprocal rank is brittle when discriminating between systems. This brittleness, in turn, is compounded in modern evaluation settings where current, high-precision systems may be difficult to distinguish. We address the lack of sensitivity of reciprocal rank by introducing and connecting it to the concept of best-case retrieval, an evaluation method focusing on assessing the quality of a ranking for the most satisfied possible user across possible recall requirements. This perspective allows us to generalize reciprocal rank and define a new preference-based evaluation we call lexicographic precision or lexiprecision. By mathematical construction, we ensure that lexiprecision preserves differences detected by reciprocal rank, while empirically improving sensitivity and robustness across a broad set of retrieval and recommendation tasks.
isOpenAccess: True
TL\DR: This work addresses the lack of sensitivity of reciprocal rank by introducing and connecting it to the concept of best-case retrieval, an evaluation method focusing on assessing the quality of a ranking for the most satisfied possible user across possible recall requirements.
================================
faculty_name: Fernando Diaz
faculty_authorid: 145472333
paper_id: 567f6bc975deb3d728feec9bfcf7d4036ceabb12
paper_title: Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery
publication_link: https://arxiv.org/pdf/2308.14601 
year_published: 2023 
abstract_paper:As online music platforms grow, music recommender systems play a vital role in helping users navigate and discover content within their vast musical databases. At odds with this larger goal, is the presence of popularity bias, which causes algorithmic systems to favor mainstream content over, potentially more relevant, but niche items. In this work we explore the intrinsic relationship between music discovery and popularity bias. To mitigate this issue we propose a domain-aware, individual fairness-based approach which addresses popularity bias in graph neural network (GNNs) based recommender systems. Our approach uses individual fairness to reflect a ground truth listening experience, i.e., if two songs sound similar, this similarity should be reflected in their representations. In doing so, we facilitate meaningful music discovery that is robust to popularity bias and grounded in the music domain. We apply our BOOST methodology to two discovery based tasks, performing recommendations at both the playlist level and user level. Then, we ground our evaluation in the cold start setting, showing that our approach outperforms existing fairness benchmarks in both performance and recommendation of lesser-known content. Finally, our analysis explains why our proposed methodology is a novel and promising approach to mitigating popularity bias and improving the discovery of new and niche content in music recommender systems.
isOpenAccess: True
TL\DR: This work proposes a domain-aware, individual fairness-based approach which addresses popularity bias in graph neural network (GNNs) based recommender systems and applies the BOOST methodology to two discovery based tasks, performing recommendations at both the playlist level and user level.
================================
faculty_name: Fernando Diaz
faculty_authorid: 145472333
paper_id: 5e1ba2d4416333dd6f6a31a4ff4221b40dfb74b1
paper_title: Overview of the TREC 2021 Fair Ranking Track
publication_link: http://arxiv.org/pdf/2302.10856 
year_published: 2023 
abstract_paper:The TREC Fair Ranking Track aims to provide a platform for participants to develop and evaluate novel retrieval algorithms that can provide a fair exposure to a mixture of demographics or attributes, such as ethnicity, that are represented by relevant documents in response to a search query. For example, particular demographics or attributes can be represented by the documents' topical content or authors. The 2021 Fair Ranking Track adopted a resource allocation task. The task focused on supporting Wikipedia editors who are looking to improve the encyclopedia's coverage of topics under the purview of a WikiProject. WikiProject coordinators and/or Wikipedia editors search for Wikipedia documents that are in need of editing to improve the quality of the article. The 2021 Fair Ranking track aimed to ensure that documents that are about, or somehow represent, certain protected characteristics receive a fair exposure to the Wikipedia editors, so that the documents have an fair opportunity of being improved and, therefore, be well-represented in Wikipedia. The under-representation of particular protected characteristics in Wikipedia can result in systematic biases that can have a negative human, social, and economic impact, particularly for disadvantaged or protected societal groups.
isOpenAccess: True
TL\DR: The 2021 Fair Ranking track aimed to ensure that documents that are about, or somehow represent, certain protected characteristics receive a fair exposure to the Wikipedia editors, so that the documents have an fair opportunity of being improved and, therefore, be well-represented in Wikipedia.
================================
faculty_name: Fernando Diaz
faculty_authorid: 144776673
paper_id: 023ea96250244e082b961657a95545638d9f8329
paper_title: Cost analysis of three-dimensional radiation therapy versus intensity-modulated chemoradiotherapy for locally advanced cervical cancer in Peruvian citizens
publication_link: https://ecancer.org/en/journal/article/1531-cost-analysis-of-three-dimensional-radiation-therapy-versus-intensitymodulated-chemoradiotherapy-for-locally-advanced-cervical-cancer-in-peruvian-citizens/pdf 
year_published: 2023 
abstract_paper:Background and objectives The standard treatment for locally advanced cervical cancer (CC) is chemoradiotherapy (CTRT) followed by high-dose-rate brachytherapy (HDRBT). The ideal scenario would be under novel intensity-modulated radiation therapy (IMRT) volumetric-modulated arc therapy (VMAT) radiation techniques over three-dimensional (3D) radiation therapy. However, radiotherapy (RT) centres in low- and middle-income countries have limited equipment for teletherapy services like HDRBT. This is why the 3D modality is still in use. The objective of this study was to analyse costs in a comparison of 3D versus IMRT versus VMAT based on clinical staging. Materials and methods From 02/01/2022 to 05/01/2023 a prospective registry of the costs for oncological management was carried out for patients with locally advanced CC who received CTRT ± HDRBT. This included the administration of radiation with chemotherapy. The cost associated with patient and family transfers and hours in the hospital was also identified. These expenses were used to project the direct and indirect costs of 3D versus IMRT versus VMAT. Results The treatment regimens for stage IIIC2, including 3D and novel techniques, are those with the highest costs. The administration of 3D RT for IIIC2 and novel IMRT or VMAT techniques, is $3,881.69, $3,374.76, and $2,862.80, respectively. The indirect cost from stage IIB to IIIC1 in descending order is IMRT, 3D and VMAT, but in IIIC2 the novel technique regimens reduce by up to 33.99% compared to 3D. Conclusion In RT centres with an available supply of RT equipment, VMAT should be preferred over IMRT/3D since it reduces costs and toxicity. However, in RT centres where demand exceeds supply in the VMAT technique planning systems, the use of 3D teletherapy over IMRT/VMAT could continue to be used in patients with stage IIB to IIIC1.
isOpenAccess: True
TL\DR: In RT centres with an available supply of RT equipment, VMAT should be preferred over IMRT/3D since it reduces costs and toxicity and in RT centres where demand exceeds supply in the VMAT technique planning systems, the use of 3D teletherapy over IM RT/VMAT could continue to be used in patients with stage IIB to IIIC1.
================================
faculty_name: Fernando Diaz
faculty_authorid: 144776673
paper_id: 217fce1552139ca00ac113b2124a36365fa579ca
paper_title: Impact of outpatient radiotherapy on direct non-medical cost in patients in the Central Macro Region of Peru 2021
publication_link: https://ecancer.org/en/journal/article/1580-impact-of-outpatient-radiotherapy-on-direct-non-medical-cost-in-patients-in-the-central-macro-region-of-peru-2021/pdf 
year_published: 2023 
abstract_paper:Background Financial toxicity arises in cancer patients due to the objective financial burden of the disease or treatment, being associated with worse clinical outcomes. Direct non-medical spending on cancer patients undergoing radiotherapy in Peru under its publicly funded health system has not been described. Objective To know the expenses related to the transfer of the radiotherapy outpatient. Methodology For patients who started radiation therapy in 2021, treatment demographics and expenses related to transporting the patient from home to the radiation therapy center were prospectively collected. Association and connection tests were used, such as the Mann–Whitney/Kruskal–Wallis U-test and Spearman’s Rho. A value of p < 0.05 is considered statistically significant. Results 398 patients were collected, with average weekly expenses for transportation, lodging and food of $17.04, $6.69 and $45.91, respectively. Confirmation was positive between weekly spending and remoteness, likewise it was negative between effective teletherapy and remoteness, both analyses being statistically significant. Conclusion The expense associated with transfer for radiotherapy is high, exceeding the average monthly income of the patient, as a consequence they have a worse therapeutic result, and may cause financial toxicity in cancer patients.
isOpenAccess: True
TL\DR: The expense associated with transfer for radiotherapy is high, exceeding the average monthly income of the patient, as a consequence they have a worse therapeutic result, and may cause financial toxicity in cancer patients.
================================
faculty_name: Fernando Diaz
faculty_authorid: 2046821992
paper_id: 414fc2423dbd9bcfd7870ea856485f51a4fc3e62
paper_title: Comparative Efficacy of First and Second Generation long-acting injectable antipsychotic upon schizophrenic patients: a systematic review and network meta-analysis
publication_link: https://archivosdeneurociencias.org/index.php/ADN/article/download/432/787 
year_published: 2023 
abstract_paper:Introduction: Long-acting injectable antipsychotics (LAIA) can lead the course of treatment with the potential to increase adherence in schizophrenia treatment. The objective of this systematic review and network meta-analysis is to find the efficacy of SG-LAIAs, FG-LAIAs compared to each other for schizophrenia. 
Methods: This systematic review and network meta-analysis was designed following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA), with registration in Prospero (ID CRD42019128700). A database in MEDLINE, EMBASE, Web of Science, and Scopus, until June 17, 2020, with an actualization from June 2020 to September 14, 2021.  
Results: The SMDs for the four (80%) antipsychotics that significantly reduced PANSS score compared with placebo ranged between –0·72 (95% CrI –0·99 to –0·46) for haloperidol to –0·45 (–0·54 to –0·37) for paliperidone. 8 studies reported usable results for negative symptoms and positive symptoms (Four antipsychotics compared). The SMDs for the three (75%) antipsychotics that significantly reduced negative symptoms compared with placebo ranged between –0·40 (95% CrI –0·53 to –0·26) for aripiprazole to –0·32 (–0·44 to –0·19) for risperidone. The SMDs for the three (100%) drugs that significantly reduced positive symptoms compared with placebo ranged between –0·50 (95% CrI –0·63 to –0·37) for aripiprazole to –0·19 (–0·57 to 0·20) for zuclopenthixol. 
Discussion: We found evidence suggesting that all long-acting injectable antipsychotics, except for zuclopenthixol, are equally efficient in reducing symptoms in schizophrenia, 
Conclusions: Most LAIAs are equally efficient at reducing overall symptoms, and differences between individual LAIAs are non-significant.
isOpenAccess: True
TL\DR: The expense associated with transfer for radiotherapy is high, exceeding the average monthly income of the patient, as a consequence they have a worse therapeutic result, and may cause financial toxicity in cancer patients.
================================
faculty_name: Fernando Diaz
faculty_authorid: 2212324259
paper_id: 11c44e8f63b8fb6e726cbf9c1fcd56b21053df44
paper_title: PLATFORM BASED ON DATA ANALYTICS AND STATISTICS TO PREDICT AND MONITOR THE INTEGRATED AND INTELLIGENT ENERGY MANAGEMENT OF ENERGY-INTENSIVE BUILDINGS
publication_link: http://www.dyna-energia.com/Reports/ArticulosMasDescargados.aspx 
year_published: 2023 
abstract_paper:ABSTRACT: 
Currently, large buildings are often equipped with building management systems (BMS), but either because of the type of control or the difficulty of interacting with them, they do not allow optimization policies to be implemented. As far as energy efficiency is concerned, optimization strategies often result from the analysis of monitored data by a specialist, which slows down both decision making and implementation. 
Aware of this problem, this project arises, in which a complementary platform to the BMS systems is developed to provide them with greater intelligence. For its design, the Puerta del Hierro Hospital in Madrid has been taken as a pilot case, from the data captured by its own BMS and using the 6 SIGMA methodology, algorithms have been developed capable of optimizing the production systems themselves, thus helping to make up for the weaknesses in the operation of the systems and reducing energy consumption, minimizing the environmental impact and allowing to obtain the maximum performance of its assets. 
The platform uses the information gathered by the BMS and weather forecasts to predict a building's energy demand and, based on this, optimize energy production at any given moment.
Keywords: Commissioning, Energy efficiency, Smart building, Degree-days, BMS, 6 SIGMA.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Fernando Diaz
faculty_authorid: 65852910
paper_id: b79041565cbd9da52daf97f73c4097eed0afd723
paper_title: Concomitant inhibition of PPARγ and mTORC1 induces the differentiation of human monocytes into highly immunogenic dendritic cells.
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Fernando Diaz
faculty_authorid: 65852910
paper_id: cbe6b6d58254ee2434d091ed7b8466e444ef892a
paper_title: Clusterin protects mature dendritic cells from reactive oxygen species mediated cell death
publication_link: https://www.tandfonline.com/doi/pdf/10.1080/2162402X.2023.2294564?needAccess=true 
year_published: 2023 
abstract_paper:ABSTRACT Dendritic cells (DCs) play a key role in the induction of the adaptive immune response. They capture antigens in peripheral tissues and prime naïve T lymphocytes, triggering the adaptive immune response. In the course of inflammatory processes DCs face stressful conditions including hypoxia, low pH and high concentrations of reactive oxygen species (ROS), among others. How DCs survive under these adverse conditions remain poorly understood. Clusterin is a protein highly expressed by tumors and usually associated with bad prognosis. It promotes cancer cell survival by different mechanisms such as apoptosis inhibition and promotion of autophagy. Here, we show that, upon maturation, human monocyte-derived DCs (MoDCs) up-regulate clusterin expression. Clusterin protects MoDCs from ROS-mediated toxicity, enhancing DC survival and promoting their ability to induce T cell activation. In line with these results, we found that clusterin is expressed by a population of mature LAMP3+ DCs, called mregDCs, but not by immature DCs in human cancer. The expression of clusterin by intratumoral DCs was shown to be associated with a transcriptomic profile indicative of cellular response to stress. These results uncover an important role for clusterin in DC physiology.
isOpenAccess: True
TL\DR: It is found that clusterin is expressed by a population of mature LAMP3+ DCs, called mregDCs, but not by immature DCs in human cancer, and this results uncover an important role for clusterin in DC physiology.
================================
faculty_name: Fernando Diaz
faculty_authorid: 2193360464
paper_id: edde6245557416c5911a5e29c5ea93bf2deabf1f
paper_title: A Bibliometric Analysis on Cooperatives in Circular Economy and Eco-Innovation Studies
publication_link: https://www.mdpi.com/2071-1050/15/21/15595/pdf?version=1699005682 
year_published: 2023 
abstract_paper:Cooperatives address societal challenges embracing values beyond mere profit-oriented production. Considering the ongoing shift to achieve efficient use of resources and increased circularity, cooperatives should be better equipped to incorporate circular economy (CE) and eco-innovation (EI) into their strategies (compared to regular enterprises). This paper reviews the scholarly literature focusing on the application of CE and EI within cooperative studies with the aim to understand the relationships between these topics, identify the existing scholarly communities, and to observe salient research themes. This study refined the method of van den Hoven and Rubalcaba (2016) to conduct a two-step bibliographic review of documents: a thematic analysis of citation data from Scopus (including a manual review of 16 papers) was followed by a bibliometric analysis of 101 documents from Web of Science (using R-Studio’s Biblioshiny). Our results identified three intellectual clusters of cooperative studies focusing on the downstream of CE: (1) industrial ecology; (2) recycling; and (3) waste management. Our study also revealed an emerging scholarly field focused on cooperatives and CE, and with little attention to EI. These findings aim at catalyzing the integration of cooperatives more effectively into scholarly discussions, suggesting that environmental sustainability should be recognized as an additional principle of the cooperative identity—providing a wider perspective that enhances interest in the research of these topics and their interconnections.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Fernando Diaz
faculty_authorid: 1456699200
paper_id: 53e57edca377b168c010cfed423f1b90f56007a4
paper_title: Understanding of the Effect of the Adsorption of Atom and Cluster Silver on Chitosan: An In Silico Analysis
publication_link: https://www.mdpi.com/1420-3049/28/15/5809/pdf?version=1690899554 
year_published: 2023 
abstract_paper:In this work, the structural, electronic, and optical stability properties of the chitosan monomer (M-Ch) and atomic silver complex are reported, as well as a unitary cell of a silver cluster in the gas phase and acetic acid. The generalized gradient approximation HSEh1PBE/def2-TZVPP50 results established the structures’ anionic charge (Q = −1|e|) and the doublet state (M = 2). The high cohesive energy indicates structural stability, and the quantum-mechanical descriptors show a high polarity and low chemical reactivity. Also, the quantum-mechanical descriptors present a low work function that shows the structures are suitable for applications in light-emitting diodes. Finally, the electronic behavior observed by the |HOMO-LUMO| gap energy changes depending on the atomic silver incorporated into the complex.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Scott Fahlman
faculty_authorid: 1758714
paper_id: 13922d438c437cea443b6c4747c54a29a8bdd742
paper_title: Score: A Rule Engine for the Scone Knowledge Base System
publication_link: http://arxiv.org/pdf/2305.04154 
year_published: 2023 
abstract_paper:We present Score, a rule engine designed and implemented for the Scone knowledge base system. Scone is a knowledge base system designed for storing and manipulating rich representations of general knowledge in symbolic form. It represents knowledge in the form of nodes and links in a network structure, and it can perform basic inference about the relationships between different elements efficiently. On its own, Scone acts as a sort of"smart memory"that can interface with other software systems. One area of improvement for Scone is how useful it can be in supplying knowledge to an intelligent agent that can use the knowledge to perform actions and update the knowledge base with its observations. We augment the Scone system with a production rule engine that automatically performs simple inference based on existing and newly-added structures in Scone's knowledge base, potentially improving the capabilities of any planning systems built on top of Scone. Production rule systems consist of"if-then"production rules that try to match their predicates to existing knowledge and fire their actions when their predicates are satisfied. We propose two kinds of production rules, if-added and if-needed rules, that differ in how they are checked and fired to cover multiple use cases. We then implement methods to efficiently check and fire these rules in a large knowledge base. The new rule engine is not meant to be a complex stand-alone planner, so we discuss how it fits into the context of Scone and future work on planning systems.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Robert Frederking
faculty_authorid: 108366693
paper_id: 42f711ca3491d4bf33b35683944d9b8f5bc1c558
paper_title: Reconstructing ice force-displacement development in structural assessments of freshwater, polycrystalline ice impacts
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Daniel Fried
faculty_authorid: 48582444
paper_id: 0524230fb6da632043c714523b409431dc08edc9
paper_title: Analysis of the transparent surface layer formed at the surfaces of arrested enamel caries lesions with tomographic imaging methods
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Daniel Fried
faculty_authorid: 48582444
paper_id: 3dc7c209b772baaf3cca527ac3c5deca330f7b2e
paper_title: Exploratory Analysis of Objective Outcome Measures for the Clinical Assessment of Erosive Tooth Wear
publication_link: https://www.mdpi.com/2075-4418/13/15/2568/pdf?version=1690945777 
year_published: 2023 
abstract_paper:This study proposed using enamel surface texture and thickness for the objective detection and monitoring of erosive tooth wear (ETW), comparing them to the standard subjective Basic Erosive Wear Evaluation (BEWE). Thirty-two subjects (n = 597 teeth) were enrolled in this longitudinal observational clinical study. Enamel thickness (by cross-polarization optical coherence tomography, CP-OCT) and 3D dental microwear parameters, i.e., area-scale fractal complexity (Asfc), anisotropy (Str), and roughness (Sa) (by white-light scanning confocal profilometry), were obtained from buccal surfaces. Buccal, occlusal, and lingual surfaces were scored for BEWE and the maximum score per tooth (BEWEMax) was determined at baseline and 12 months (M12). Data outcome relationships were evaluated (alpha = 0.05). Enamel thickness decreased (p < 0.001), BEWE scores, Sa, and Str increased (p < 0.001), while Asfc did not change at M12. Baseline BEWEBuccal correlated strongly with BEWEMax (r = 0.86, p < 0.001) and moderately with BEWELingual (r = 0.42, p < 0.001), but not with enamel thickness (r = 0.03, p = 0.43). Change (Δ) in surface texture outcomes correlated poorly but significantly with ΔBEWEBuccal (r = −0.15–0.16, p < 0.001) and did not correlate with Δenamel thickness (r = 0.02–0.09, p > 0.06). Teeth with BEWE progression revealed a greater increase in ΔSa and ΔStr. These findings suggest that enamel surface roughness can potentially determine ETW severity, and CP-OCT may be relevant for clinically monitoring enamel thickness.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Daniel Fried
faculty_authorid: 48582444
paper_id: 4a48291d52be0ef4e399270eb029fe03ca2ed831
paper_title: Assessment of the activity of secondary caries lesions with short-wavelength infrared, thermal, and optical coherence tomographic imaging
publication_link: https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-28/issue-9/094801/Assessment-of-the-activity-of-secondary-caries-lesions-with-short/10.1117/1.JBO.28.9.094801.pdf 
year_published: 2023 
abstract_paper:Abstract. Significance: Leakage in the interfaces between restorative materials and tooth structure allows for fluid and bacterial acid infiltration, causing restoration failure due to secondary caries. Dentists spend more time replacing composite restorations than placing new ones. Previous in vitro and in vivo studies on enamel and root surfaces using shortwave-infrared (SWIR) and thermal imaging during dehydration with forced air have been promising for assessing lesion activity. Aim: We hypothesized that SWIR reflectance and thermal imaging methods can be used to monitor the activity of secondary caries lesions around composite restorations. The objective of this study was to employ these methods to measure the rate of fluid loss from lesions during dehydration with forced air to assess lesion activity. Approach: Sixty-three extracted human teeth with total of 109 suspected secondary lesions were examined using SWIR and thermal imaging during dehydration. The thickness of the highly mineralized transparent surface layer (TSL) at lesion interfaces indicative of lesion activity was measured by optical coherence tomography (OCT). Micro-computed tomography (MicroCT) was used to further confirm lesion severity and structure. OCT and MicroCT measurements of lesion structure, depth, and severity were correlated with fluid loss rates measured with SWIR reflectance and thermal imaging. Results: TSL thickness measured with OCT correlated with both SWIR reflectance and thermal measurements of rates of fluid loss (p  <  0.05). Increasing TSL thickness led to decreased permeability of lesions, potentially indicating full lesion arrest at TSL  ≥  70  μm. SWIR performed better than thermal imaging for secondary lesion activity assessment, although both methods performed best on smooth surface lesions. Conclusions: Nondestructive SWIR reflectance and OCT imaging methods are promising for clinically monitoring the activity of secondary caries lesions.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Daniel Fried
faculty_authorid: 48582444
paper_id: 52b9ab94b9a4be203031bbc1fa61251513b1d5f7
paper_title: Monitoring lesion activity on primary teeth with CP‐OCT and SWIR reflectance imaging
publication_link: https://escholarship.org/content/qt24z290zt/qt24z290zt.pdf?t=rvf4ji 
year_published: 2023 
abstract_paper:The purpose of this study was to use cross polarization optical coherence tomography (CP‐OCT) and short wavelength infrared imaging (SWIR) reflectance imaging to monitor changes in the structure and activity of early occlusal caries on primary teeth over a period of 6 months during intervention with fluoride.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Daniel Fried
faculty_authorid: 48582444
paper_id: 6aedce6dc4e6c9a218bbc95fc4ae4d4de8d424ac
paper_title: Active Surveillance of Root Caries in Vivo with CP-OCT
publication_link: https://www.mdpi.com/2075-4418/13/3/465/pdf?version=1674821027 
year_published: 2023 
abstract_paper:The active surveillance of root caries lesions to monitor potential remineralization or decay progression is challenging for the clinician, due to unreliable diagnostic information. The conventional visual and tactile methods for assessing the lesion activity are not reliable, and the clinician is often unable to determine if the lesion is progressing or has been arrested. An important marker of an arrested lesion is a highly mineralized transparent surface zone (TSL) that forms when the mineral is deposited in the outer layer of the lesion. The purpose of this study was to determine if cross-polarization optical coherence tomography (CP-OCT) could be used to detect changes in the lesion severity and activity during active monitoring. In total, 18 subjects with 22 suspected active root caries lesions were evaluated using CP-OCT at the baseline, 3 months, and 6 months. All subjects were instructed to use a high fluoride dentifrice at the baseline. The results showed that CP-OCT was able to discriminate the active from the arrested lesions by identifying the presence of a TSL on arrested lesions. The results also indicated that the mean TSL thickness increased significantly (p < 0.05) for the nine lesion areas. In addition, CP-OCT was able to show the progression of demineralization, erosion, and changes in gingival contours in scanned areas. CP-OCT was valuable for monitoring the activity and severity of root caries lesions in vivo. CP-OCT can be used to assess the activity of root caries lesions at a single time point by detecting the presence of a TSL at the lesion surface indicative of the lesion arrest.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Daniel Fried
faculty_authorid: 48582444
paper_id: aa705ba5294ed9d06978fe6a08ab2f2b5dd08e1e
paper_title: Time‐resolved SWIR imaging for the assessment of the activity of occlusal caries lesions
publication_link: Not given 
year_published: 2023 
abstract_paper:The aim of this study was to develop a clinical SWIR reflectance handpiece to assess the activity of lesions on the occlusal surfaces. The time‐resolved reflectivity of 10 active and 10 arrested occlusal caries lesions on extracted teeth was monitored at 1470 nm using a benchtop system and a modified clinical prototype during forced air drying. The presence of a highly mineralized surface layer measured with microcomputed tomography (microCT) was used to indicate lesion activity. Multiple kinetic parameters were extracted from the acquired SWIR time versus intensity dehydration curves and used to assess lesion activity. Three parameters: delay, %Ifin, and rate calculated from the SWIR dehydration curves were significantly different (p < 0.05) between active and arrested lesions. The modified clinical probe was able to completely dehydrate all the active lesion areas in the occlusal pits and fissures in less than 30 s.
isOpenAccess: True
TL\DR: A clinical SWIR reflectance handpiece to assess the activity of lesions on the occlusal surfaces was developed and was able to completely dehydrate all the active lesion areas in the Occlusal pits and fissures in less than 30 s.
================================
faculty_name: Daniel Fried
faculty_authorid: 48582444
paper_id: bebca5d54374c83a7489638d3b45d2b006d559f0
paper_title: Diagnostic Performance of Multispectral SWIR Transillumination and Reflectance Imaging for Caries Detection
publication_link: https://www.mdpi.com/2075-4418/13/17/2824/pdf?version=1693538243 
year_published: 2023 
abstract_paper:The aim of this clinical study was to compare the diagnostic performance of dual short wavelength infrared (SWIR) occlusal transillumination and reflectance multispectral imaging with conventional visual assessment and radiography for caries detection on premolars scheduled for extraction for orthodontics reasons. Polarized light microscopy (PLM) and micro-computed tomography (microCT) performed after tooth extraction were used as gold standards. The custom-fabricated imaging probe was 3D-printed and the imaging system employed a SWIR camera and fiber-optic light sources emitting light at 1300 nm for occlusal transillumination and 1600 nm for reflectance measurements. Teeth (n = 135) on 40 test subjects were imaged in vivo using the SWIR imaging prototype in the study and teeth were extracted after imaging. Our study demonstrates for the first time that near-simultaneous real-time transillumination and reflectance video can be successfully acquired for caries detection. Both SWIR imaging modalities had markedly higher sensitivity for lesions on proximal and occlusal surfaces compared to conventional methods (visual and radiographic). Reflectance imaging at 1600 nm had higher sensitivity and specificity than transillumination at 1300 nm. The combined SWIR methods yielded higher specificity but the combined sensitivity was lower than for each individual method.
isOpenAccess: True
TL\DR: A clinical SWIR reflectance handpiece to assess the activity of lesions on the occlusal surfaces was developed and was able to completely dehydrate all the active lesion areas in the Occlusal pits and fissures in less than 30 s.
================================
faculty_name: Daniel Fried
faculty_authorid: 47070750
paper_id: 19f59c14b3d79e3203c696128a135d33eb35e468
paper_title: Pragmatic Inference with a CLIP Listener for Contrastive Captioning
publication_link: http://arxiv.org/pdf/2306.08818 
year_published: 2023 
abstract_paper:We propose a simple yet effective and robust method for contrastive captioning: generating discriminative captions that distinguish target images from very similar alternative distractor images. Our approach is built on a pragmatic inference procedure that formulates captioning as a reference game between a speaker, which produces possible captions describing the target, and a listener, which selects the target given the caption. Unlike previous methods that derive both speaker and listener distributions from a single captioning model, we leverage an off-the-shelf CLIP model to parameterize the listener. Compared with captioner-only pragmatic models, our method benefits from rich vision language alignment representations from CLIP when reasoning over distractors. Like previous methods for discriminative captioning, our method uses a hyperparameter to control the tradeoff between the informativity (how likely captions are to allow a human listener to discriminate the target image) and the fluency of the captions. However, we find that our method is substantially more robust to the value of this hyperparameter than past methods, which allows us to automatically optimize the captions for informativity - outperforming past methods for discriminative captioning by 11% to 15% accuracy in human evaluations
isOpenAccess: True
TL\DR: This work proposes a simple yet effective and robust method for contrastive captioning: generating discriminative captions that distinguish target images from very similar alternative distractor images by leveraging an off-the-shelf CLIP model to parameterize the listener.
================================
faculty_name: Daniel Fried
faculty_authorid: 47070750
paper_id: 1bf21dabbdfc81fd4f9e92b1201ecce744cabb6a
paper_title: SantaCoder: don't reach for the stars!
publication_link: http://arxiv.org/pdf/2301.03988 
year_published: 2023 
abstract_paper:The BigCode project is an open-scientific collaboration working on the responsible development of large language models for code. This tech report describes the progress of the collaboration until December 2022, outlining the current state of the Personally Identifiable Information (PII) redaction pipeline, the experiments conducted to de-risk the model architecture, and the experiments investigating better preprocessing methods for the training data. We train 1.1B parameter models on the Java, JavaScript, and Python subsets of The Stack and evaluate them on the MultiPL-E text-to-code benchmark. We find that more aggressive filtering of near-duplicates can further boost performance and, surprisingly, that selecting files from repositories with 5+ GitHub stars deteriorates performance significantly. Our best model outperforms previous open-source multilingual code generation models (InCoder-6.7B and CodeGen-Multi-2.7B) in both left-to-right generation and infilling on the Java, JavaScript, and Python portions of MultiPL-E, despite being a substantially smaller model. All models are released under an OpenRAIL license at https://hf.co/bigcode.
isOpenAccess: True
TL\DR: This work proposes a simple yet effective and robust method for contrastive captioning: generating discriminative captions that distinguish target images from very similar alternative distractor images by leveraging an off-the-shelf CLIP model to parameterize the listener.
================================
faculty_name: Daniel Fried
faculty_authorid: 47070750
paper_id: 2b2d9ee18507aa89a7f1ecba0bf68844c7d9aa75
paper_title: Grounding Language Models to Images for Multimodal Generation
publication_link: http://arxiv.org/pdf/2301.13823 
year_published: 2023 
abstract_paper:We propose an efﬁcient method to ground pre-trained text-only language models to the visual domain, enabling them to process and generate arbitrarily interleaved image-and-text data. Our method leverages the abilities of language models learnt from large scale text-only pretraining, such as in-context learning and free-form text generation. We keep the language model frozen, and ﬁnetune input and output linear layers to enable cross-modality interactions. This allows our model to process arbitrarily interleaved image-and-text inputs, and generate free-form text interleaved with retrieved images. We achieve strong zero-shot performance on grounded tasks such as contextual image retrieval and multimodal dialogue, and showcase compelling interactive abilities. Our approach works with any off-the-shelf language model and paves the way towards an ef-fective, general solution for leveraging pretrained language models in visually grounded settings.
isOpenAccess: True
TL\DR: This work proposes a simple yet effective and robust method for contrastive captioning: generating discriminative captions that distinguish target images from very similar alternative distractor images by leveraging an off-the-shelf CLIP model to parameterize the listener.
================================
faculty_name: Daniel Fried
faculty_authorid: 47070750
paper_id: 3e4085e5869f1b7959707a1e1d7d273b6057eb4e
paper_title: StarCoder: may the source be with you!
publication_link: http://arxiv.org/pdf/2305.06161 
year_published: 2023 
abstract_paper:The BigCode community, an open-scientific collaboration working on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder and StarCoderBase: 15.5B parameter models with 8K context length, infilling capabilities and fast large-batch inference enabled by multi-query attention. StarCoderBase is trained on 1 trillion tokens sourced from The Stack, a large collection of permissively licensed GitHub repositories with inspection tools and an opt-out process. We fine-tuned StarCoderBase on 35B Python tokens, resulting in the creation of StarCoder. We perform the most comprehensive evaluation of Code LLMs to date and show that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model. Furthermore, StarCoder outperforms every model that is fine-tuned on Python, can be prompted to achieve 40\% pass@1 on HumanEval, and still retains its performance on other programming languages. We take several important steps towards a safe open-access model release, including an improved PII redaction pipeline and a novel attribution tracing tool, and make the StarCoder models publicly available under a more commercially viable version of the Open Responsible AI Model license.
isOpenAccess: True
TL\DR: This work performs the most comprehensive evaluation of Code LLMs to date and shows that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model.
================================
faculty_name: Daniel Fried
faculty_authorid: 47070750
paper_id: 6fb5c0eff3696ef252aca9638e10176ecce7cecb
paper_title: Generating Images with Multimodal Language Models
publication_link: https://arxiv.org/pdf/2305.17216 
year_published: 2023 
abstract_paper:We propose a method to fuse frozen text-only large language models (LLMs) with pre-trained image encoder and decoder models, by mapping between their embedding spaces. Our model demonstrates a wide suite of multimodal capabilities: image retrieval, novel image generation, and multimodal dialogue. Ours is the first approach capable of conditioning on arbitrarily interleaved image and text inputs to generate coherent image (and text) outputs. To achieve strong performance on image generation, we propose an efficient mapping network to ground the LLM to an off-the-shelf text-to-image generation model. This mapping network translates hidden representations of text into the embedding space of the visual models, enabling us to leverage the strong text representations of the LLM for visual outputs. Our approach outperforms baseline generation models on tasks with longer and more complex language. In addition to novel image generation, our model is also capable of image retrieval from a prespecified dataset, and decides whether to retrieve or generate at inference time. This is done with a learnt decision module which conditions on the hidden representations of the LLM. Our model exhibits a wider range of capabilities compared to prior multimodal language models. It can process image-and-text inputs, and produce retrieved images, generated images, and generated text -- outperforming non-LLM based generation models across several text-to-image tasks that measure context dependence.
isOpenAccess: True
TL\DR: This work performs the most comprehensive evaluation of Code LLMs to date and shows that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model.
================================
faculty_name: Daniel Fried
faculty_authorid: 47070750
paper_id: e41482f4ee984f17382f6cdd900df094d928be06
paper_title: WebArena: A Realistic Web Environment for Building Autonomous Agents
publication_link: https://arxiv.org/pdf/2307.13854 
year_published: 2023 
abstract_paper:With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41%, significantly lower than the human performance of 78.24%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.
isOpenAccess: True
TL\DR: This work performs the most comprehensive evaluation of Code LLMs to date and shows that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model.
================================
faculty_name: Daniel Fried
faculty_authorid: 2238210389
paper_id: 5016766c87982f5c62ef6580e120939ab155d776
paper_title: Amortizing Pragmatic Program Synthesis with Rankings
publication_link: https://arxiv.org/pdf/2309.03225 
year_published: 2023 
abstract_paper:In program synthesis, an intelligent system takes in a set of user-generated examples and returns a program that is logically consistent with these examples. The usage of Rational Speech Acts (RSA) framework has been successful in building \emph{pragmatic} program synthesizers that return programs which -- in addition to being logically consistent -- account for the fact that a user chooses their examples informatively. However, the computational burden of running the RSA algorithm has restricted the application of pragmatic program synthesis to domains with a small number of possible programs. This work presents a novel method of amortizing the RSA algorithm by leveraging a \emph{global pragmatic ranking} -- a single, total ordering of all the hypotheses. We prove that for a pragmatic synthesizer that uses a single demonstration, our global ranking method exactly replicates RSA's ranked responses. We further empirically show that global rankings effectively approximate the full pragmatic synthesizer in an online, multi-demonstration setting. Experiments on two program synthesis domains using our pragmatic ranking method resulted in orders of magnitudes of speed ups compared to the RSA synthesizer, while outperforming the standard, non-pragmatic synthesizer.
isOpenAccess: True
TL\DR: This work presents a novel method of amortizing the RSA algorithm by leveraging a single, total ordering of all the hypotheses, and proves that for a pragmatic synthesizer that uses a single demonstration, the global ranking method exactly replicates RSA's ranked responses.
================================
faculty_name: Daniel Fried
faculty_authorid: 2237920336
paper_id: eafc0e6504514650753207108f15e62e09008950
paper_title: Longitudinal assessment of dental erosion-abrasion by cross-polarization optical coherence tomography in vitro.
publication_link: https://www.scielo.br/j/bor/a/J8Zw4RyWJFHJxhwCjntTzdK/?lang=en&format=pdf 
year_published: 2023 
abstract_paper:This study tested a novel in vitro dental erosion-abrasion model and the performance of cross-polarization optical coherence tomography (CP-OCT) in longitudinally monitoring the simulated lesions. Thirty human enamel specimens were prepared and randomized to receive three dental erosion-abrasion (EA) protocols: severe (s-EA, lemon juice/pH:2.5/4.25%w/v citric acid), moderate (m-EA, grapefruit juice/pH:3.5/1.03%w/v citric acid) and no-EA (water, control). EA challenge was performed by exposing the specimens to acidic solutions 4x/day and to brushing 2x/day with 1:3 fluoridated toothpaste slurry, for 14 days. Enamel thickness measurements were obtained using CP-OCT at baseline (D0), 7 (D7) and 14 days (D14) and micro-computed tomography (micro-CT) at D14. Enamel surface loss was measured with both CP-OCT and optical profilometry at D0, D7 and D14. Data was analyzed with repeated-measures ANOVA and Pearson's correlation (r) (α = 0.05). CP-OCT enamel thickness decreased over time in the s-EA group (D0 >D7 > D14, p < 0.001) and m-EA group (D0 > D14, p = 0.019) but did not change in the no-EA group (p = 0.30). Overall, CP-OCT and micro-CT results at D14 correlated moderately (r = 0.73). CP-OCT surface loss was highest for s-EA (p <0.001) but did not differ between moderate and no-EA (p = 0.25). Enamel surface loss with profilometry increased with severity (no-EA>m-EA>s-EA, p < 0.001). D14 surface loss was higher than D7 for both methods except for the no-EA group with profilometry. CP-OCT and profilometry had moderate overall correlation (r = 0.70). Our results revealed that the currently proposed in vitro dental erosion-abrasion model is valid and could simulate lesions of different severities over time. CP-OCT was a suitable method for monitoring the EA lesions.
isOpenAccess: True
TL\DR: This work presents a novel method of amortizing the RSA algorithm by leveraging a single, total ordering of all the hypotheses, and proves that for a pragmatic synthesizer that uses a single demonstration, the global ranking method exactly replicates RSA's ranked responses.
================================
faculty_name: Daniel Fried
faculty_authorid: 2273683165
paper_id: f983cf75e368dcd07dd3a762721c095678514e56
paper_title: AutoReply: Detecting Nonsense in Dialogue with Discriminative Replies
publication_link: https://aclanthology.org/2023.findings-emnlp.23.pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Alexander Hauptmann
faculty_authorid: 7661726
paper_id: 72cce47fd053bf916314d89a8174726c58c05e02
paper_title: Towards Open-Domain Twitter User Profile Inference
publication_link: https://aclanthology.org/2023.findings-acl.198.pdf 
year_published: 2023 
abstract_paper:,
isOpenAccess: True
TL\DR: None
================================
faculty_name: Alexander Hauptmann
faculty_authorid: 145788702
paper_id: 2107b867cb8f8afa30a9a940288d7c8b657f8aa5
paper_title: Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation
publication_link: https://aclanthology.org/2023.acl-short.127.pdf 
year_published: 2023 
abstract_paper:Zero-shot and few-shot stance detection identify the polarity of text with regard to a certain target when we have only limited or no training resources for the target. Previous work generally formulates the problem into a classification setting, ignoring the potential use of label text. In this paper, we instead utilize a conditional generation framework and formulate the problem as denoising from partially-filled templates, which can better utilize the semantics among input, label, and target texts. We further propose to jointly train an auxiliary task, target prediction, and to incorporate manually constructed incorrect samples with unlikelihood training to improve the representations for both target and label texts. We also verify the effectiveness of target-related Wikipedia knowledge with the generation framework. Experiments show that our proposed method significantly outperforms several strong baselines on VAST, and achieves new state-of-the-art performance.
isOpenAccess: True
TL\DR: This paper utilizes a conditional generation framework and formulates the zero-shot and few-shot stance detection problem as denoising from partially-filled templates, which can better utilize the semantics among input, label, and target texts.
================================
faculty_name: Alexander Hauptmann
faculty_authorid: 145788702
paper_id: 376f494126d1ea4f571ea0263c43ac2b6331800a
paper_title: SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs
publication_link: http://arxiv.org/pdf/2306.17842 
year_published: 2023 
abstract_paper:In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos. SPAE converts between raw pixels and interpretable lexical tokens (or words) extracted from the LLM's vocabulary. The resulting tokens capture both the semantic meaning and the fine-grained details needed for visual reconstruction, effectively translating the visual content into a language comprehensible to the LLM, and empowering it to perform a wide array of multimodal tasks. Our approach is validated through in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set of image understanding and generation tasks. Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.
isOpenAccess: True
TL\DR: This paper utilizes a conditional generation framework and formulates the zero-shot and few-shot stance detection problem as denoising from partially-filled templates, which can better utilize the semantics among input, label, and target texts.
================================
faculty_name: Alexander Hauptmann
faculty_authorid: 145788702
paper_id: 405e3910e06c9efe7e660b8697bcb4bab4e92f48
paper_title: STMT: A Spatial-Temporal Mesh Transformer for MoCap-Based Action Recognition
publication_link: https://arxiv.org/pdf/2303.18177 
year_published: 2023 
abstract_paper:We study the problem of human action recognition using motion capture (MoCap) sequences. Unlike existing techniques that take multiple manual steps to derive standard-ized skeleton representations as model input, we propose a novel Spatial-Temporal Mesh Transformer (STMT) to directly model the mesh sequences. The model uses a hierarchical transformer with intra-frame off-set attention and inter-frame self-attention. The attention mechanism allows the model to freely attend between any two vertex patches to learn nonlocal relationships in the spatial-temporal domain. Masked vertex modeling and future frame prediction are used as two self-supervised tasks to fully activate the bi-directional and auto-regressive attention in our hierarchical transformer. The proposed method achieves state-of-the-art performance compared to skeleton-based and point-cloud-based models on common MoCap benchmarks. Code is available at https://github.com/zgzxy001/STMT.
isOpenAccess: True
TL\DR: This paper utilizes a conditional generation framework and formulates the zero-shot and few-shot stance detection problem as denoising from partially-filled templates, which can better utilize the semantics among input, label, and target texts.
================================
faculty_name: Alexander Hauptmann
faculty_authorid: 145788702
paper_id: 8ccda6de0223bcd897d5dc0efc8f33222a899d0d
paper_title: DocumentNet: Bridging the Data Gap in Document Pre-training
publication_link: https://aclanthology.org/2023.emnlp-industry.66.pdf 
year_published: 2023 
abstract_paper:Document understanding tasks, in particular, Visually-rich Document Entity Retrieval (VDER), have gained significant attention in recent years thanks to their broad applications in enterprise AI. However, publicly available data have been scarce for these tasks due to strict privacy constraints and high annotation costs. To make things worse, the non-overlapping entity spaces from different datasets hinder the knowledge transfer between document types. In this paper, we propose a method to collect massive-scale and weakly labeled data from the web to benefit the training of VDER models. The collected dataset, named DocumentNet, does not depend on specific document types or entity sets, making it universally applicable to all VDER tasks. The current DocumentNet consists of 30M documents spanning nearly 400 document types organized in a four-level ontology. Experiments on a set of broadly adopted VDER tasks show significant improvements when DocumentNet is incorporated into the pre-training for both classic and few-shot learning settings. With the recent emergence of large language models (LLMs), DocumentNet provides a large data source to extend their multi-modal capabilities for VDER.
isOpenAccess: True
TL\DR: This paper utilizes a conditional generation framework and formulates the zero-shot and few-shot stance detection problem as denoising from partially-filled templates, which can better utilize the semantics among input, label, and target texts.
================================
faculty_name: Alexander Hauptmann
faculty_authorid: 2257000091
paper_id: 985f0c89c5a607742ec43c1fdc2cbfe54541cbad
paper_title: Language Model Beats Diffusion - Tokenizer is Key to Visual Generation
publication_link: https://arxiv.org/pdf/2310.05737 
year_published: 2023 
abstract_paper:While Large Language Models (LLMs) are the dominant models for generative tasks in language, they do not perform as well as diffusion models on image and video generation. To effectively use LLMs for visual generation, one crucial component is the visual tokenizer that maps pixel-space inputs to discrete tokens appropriate for LLM learning. In this paper, we introduce MAGVIT-v2, a video tokenizer designed to generate concise and expressive tokens for both videos and images using a common token vocabulary. Equipped with this new tokenizer, we show that LLMs outperform diffusion models on standard image and video generation benchmarks including ImageNet and Kinetics. In addition, we demonstrate that our tokenizer surpasses the previously top-performing video tokenizer on two more tasks: (1) video compression comparable to the next-generation video codec (VCC) according to human evaluations, and (2) learning effective representations for action recognition tasks.
isOpenAccess: True
TL\DR: This paper utilizes a conditional generation framework and formulates the zero-shot and few-shot stance detection problem as denoising from partially-filled templates, which can better utilize the semantics among input, label, and target texts.
================================
faculty_name: Alexander Hauptmann
faculty_authorid: 2243236696
paper_id: e371d10dd65c8bb25375f3c09d1c0cac777cca65
paper_title: Hyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin
publication_link: https://arxiv.org/pdf/2309.10013 
year_published: 2023 
abstract_paper:Recent research in representation learning has shown that hierarchical data lends itself to low-dimensional and highly informative representations in hyperbolic space. However, even if hyperbolic embeddings have gathered attention in image recognition, their optimization is prone to numerical hurdles. Further, it remains unclear which applications stand to benefit the most from the implicit bias imposed by hyperbolicity, when compared to traditional Euclidean features. In this paper, we focus on prototypical hyperbolic neural networks. In particular, the tendency of hyperbolic embeddings to converge to the boundary of the Poincar\'e ball in high dimensions and the effect this has on few-shot classification. We show that the best few-shot results are attained for hyperbolic embeddings at a common hyperbolic radius. In contrast to prior benchmark results, we demonstrate that better performance can be achieved by a fixed-radius encoder equipped with the Euclidean metric, regardless of the embedding dimension.
isOpenAccess: True
TL\DR: This paper utilizes a conditional generation framework and formulates the zero-shot and few-shot stance detection problem as denoising from partially-filled templates, which can better utilize the semantics among input, label, and target texts.
================================
faculty_name: Daphne Ippolito
faculty_authorid: 7975935
paper_id: 03fb535de5cfcf435705a079334ac60f501226ab
paper_title: Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System
publication_link: https://arxiv.org/pdf/2309.04858 
year_published: 2023 
abstract_paper:Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model’s predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).
isOpenAccess: True
TL\DR: Methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling) are presented, which has implications for detecting generated text.
================================
faculty_name: Daphne Ippolito
faculty_authorid: 7975935
paper_id: 1567bcac0ab09269c9d0ff33c9a406132417fab9
paper_title: A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity
publication_link: http://arxiv.org/pdf/2305.13169 
year_published: 2023 
abstract_paper:Pretraining is the preliminary and fundamental step in developing capable language models (LM). Despite this, pretraining data design is critically under-documented and often guided by empirically unsupported intuitions. To address this, we pretrain 28 1.5B parameter decoder-only models, training on data curated (1) at different times, (2) with varying toxicity and quality filters, and (3) with different domain compositions. First, we quantify the effect of pretraining data age. A temporal shift between evaluation data and pretraining data leads to performance degradation, which is not overcome by finetuning. Second, we explore the effect of quality and toxicity filters, showing a trade-off between performance on standard benchmarks and risk of toxic generations. Our findings indicate there does not exist a one-size-fits-all solution to filtering training data. We also find that the effects of different types of filtering are not predictable from text domain characteristics. Lastly, we empirically validate that the inclusion of heterogeneous data sources, like books and web, is broadly beneficial and warrants greater prioritization. These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which we hope will help support more informed data-centric decisions in LM development.
isOpenAccess: True
TL\DR: These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which are hoped to help support more informed data-centric decisions in LM development.
================================
faculty_name: Daphne Ippolito
faculty_authorid: 7975935
paper_id: 2e965b5d97c2d6fb4af284307735be39283792ba
paper_title: Extracting Training Data from Diffusion Models
publication_link: http://arxiv.org/pdf/2301.13188 
year_published: 2023 
abstract_paper:Image diffusion models such as DALL-E 2, Imagen, and Stable Diffusion have attracted significant attention due to their ability to generate high-quality synthetic images. In this work, we show that diffusion models memorize individual images from their training data and emit them at generation time. With a generate-and-filter pipeline, we extract over a thousand training examples from state-of-the-art models, ranging from photographs of individual people to trademarked company logos. We also train hundreds of diffusion models in various settings to analyze how different modeling and data decisions affect privacy. Overall, our results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.
isOpenAccess: True
TL\DR: The results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.
================================
faculty_name: Daphne Ippolito
faculty_authorid: 7975935
paper_id: 8724579d3f126e753a0451d98ff57b165f722e72
paper_title: Are aligned neural networks adversarially aligned?
publication_link: http://arxiv.org/pdf/2306.15447 
year_published: 2023 
abstract_paper:Large language models are now tuned to align with the goals of their creators, namely to be"helpful and harmless."These models should respond helpfully to user questions, but refuse to answer requests that could cause harm. However, adversarial users can construct inputs which circumvent attempts at alignment. In this work, we study to what extent these models remain aligned, even when interacting with an adversarial user who constructs worst-case inputs (adversarial examples). These inputs are designed to cause the model to emit harmful content that would otherwise be prohibited. We show that existing NLP-based optimization attacks are insufficiently powerful to reliably attack aligned text models: even when current NLP-based attacks fail, we can find adversarial inputs with brute force. As a result, the failure of current attacks should not be seen as proof that aligned text models remain aligned under adversarial inputs. However the recent trend in large-scale ML models is multimodal models that allow users to provide images that influence the text that is generated. We show these models can be easily attacked, i.e., induced to perform arbitrary un-aligned behavior through adversarial perturbation of the input image. We conjecture that improved NLP attacks may demonstrate this same level of adversarial control over text-only models.
isOpenAccess: True
TL\DR: It is shown that existing NLP-based optimization attacks are insufficiently powerful to reliably attack aligned text models, and conjecture that improved NLP attacks may demonstrate this same level of adversarial control over text-only models.
================================
faculty_name: Lori Levin
faculty_authorid: 145585627
paper_id: 659be1ff350634f50cc066d258ee6a45e697e552
paper_title: SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing
publication_link: https://aclanthology.org/2023.sigmorphon-1.22.pdf 
year_published: 2023 
abstract_paper:In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.
isOpenAccess: True
TL\DR: It is shown that existing NLP-based optimization attacks are insufficiently powerful to reliably attack aligned text models, and conjecture that improved NLP attacks may demonstrate this same level of adversarial control over text-only models.
================================
faculty_name: Lori Levin
faculty_authorid: 145585627
paper_id: 7a08051aac75a809737096e39820bf836908d4e1
paper_title: Construction Grammar Provides Unique Insight into Neural Language Models
publication_link: http://arxiv.org/pdf/2302.02178 
year_published: 2023 
abstract_paper:Construction Grammar (CxG) has recently been used as the basis for probing studies that have investigated the performance of large pretrained language models (PLMs) with respect to the structure and meaning of constructions. In this position paper, we make suggestions for the continuation and augmentation of this line of research. We look at probing methodology that was not designed with CxG in mind, as well as probing methodology that was designed for specific constructions. We analyse selected previous work in detail, and provide our view of the most important challenges and research questions that this promising new field faces.
isOpenAccess: True
TL\DR: The view of the most important challenges and research questions that this promising new field of research faces is provided, and an analysis of selected previous work in detail is provided.
================================
faculty_name: Lori Levin
faculty_authorid: 145585627
paper_id: bf42c0462d1415cdde877c90d58da11545407b8a
paper_title: Generalized Glossing Guidelines: An Explicit, Human- and Machine-Readable, Item-and-Process Convention for Morphological Annotation
publication_link: https://aclanthology.org/2023.sigmorphon-1.7.pdf 
year_published: 2023 
abstract_paper:Interlinear glossing provides a vital type of morphosyntactic annotation, both for linguists and language revitalists, and numerous conventions exist for representing it formally and computationally. Some of these formats are human readable; others are machine readable. Some are easy to edit with general-purpose tools. Few represent non-concatentative processes like infixation, reduplication, mutation, truncation, and tonal overwriting in a consistent and formally rigorous way (on par with affixation). We propose an annotation conventionâ€”Generalized Glossing Guidelines (GGG) that combines all of these positive properties using an Item-and-Process (IP) framework. We describe the format, demonstrate its linguistic adequacy, and compare it with two other interlinear glossed text annotation schemes.
isOpenAccess: True
TL\DR: The view of the most important challenges and research questions that this promising new field of research faces is provided, and an analysis of selected previous work in detail is provided.
================================
faculty_name: Lori Levin
faculty_authorid: 145585627
paper_id: c5207241406586f4263b235667e004b71ea68953
paper_title: Syntax and Semantics Meet in the “Middle”: Probing the Syntax-Semantics Interface of LMs Through Agentivity
publication_link: https://arxiv.org/pdf/2305.18185 
year_published: 2023 
abstract_paper:Recent advances in large language models have prompted researchers to examine their abilities across a variety of linguistic tasks, but little has been done to investigate how models handle the interactions in meaning across words and larger syntactic forms—i.e. phenomena at the intersection of syntax and semantics. We present the semantic notion of agentivity as a case study for probing such interactions. We created a novel evaluation dataset by utilitizing the unique linguistic properties of a subset of optionally transitive English verbs. This dataset was used to prompt varying sizes of three model classes to see if they are sensitive to agentivity at the lexical level, and if they can appropriately employ these word-level priors given a specific syntactic context. Overall, GPT-3 text-davinci-003 performs extremely well across all experiments, outperforming all other models tested by far. In fact, the results are even better correlated with human judgements than both syntactic and semantic corpus statistics. This suggests that LMs may potentially serve as more useful tools for linguistic annotation, theory testing, and discovery than select corpora for certain tasks.
isOpenAccess: True
TL\DR: The view of the most important challenges and research questions that this promising new field of research faces is provided, and an analysis of selected previous work in detail is provided.
================================
faculty_name: Lori Levin
faculty_authorid: 1686960
paper_id: 2cdc646a6b70418e7cbd7fbdb8bb113176c4659f
paper_title: Somatosensory and motor representations following bilateral transplants of the hands: A 6-year longitudinal case report on the first pediatric bilateral hand transplant patient
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: The view of the most important challenges and research questions that this promising new field of research faces is provided, and an analysis of selected previous work in detail is provided.
================================
faculty_name: Lori Levin
faculty_authorid: 1686960
paper_id: 2f540bab03c2672715539ecf17ff4872ea521605
paper_title: Identifying Health-Related Quality of Life Domains after Upper Extremity Transplantation.
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: The view of the most important challenges and research questions that this promising new field of research faces is provided, and an analysis of selected previous work in detail is provided.
================================
faculty_name: Lori Levin
faculty_authorid: 1686960
paper_id: 52a97ad16605c18e23c9750a388a26a9cdf12200
paper_title: Assessment of quality of life after upper extremity transplantation: Framework for patient-reported outcome scale domains
publication_link: https://www.frontiersin.org/articles/10.3389/fpsyg.2022.989593/pdf 
year_published: 2023 
abstract_paper:Upper extremity transplantation offers the promise of restored function and regained quality of life (QOL) for individuals who have sustained hand or arm amputation. However, a major challenge for this procedure becoming an accessible treatment option for patients is the lack of standard measures to document benefits to QOL. Patient-reported outcomes (PRO) measures are well-suited for this kind of intervention, where the perspective of the patient is central to defining treatment success. To date, qualitative work with experts, clinicians, and patients has been used to identify the most important domains of QOL for PRO item development. Specifically, our group’s qualitative work has identified several domains of QOL that are unique to individuals who have received upper extremity transplants, which are distinct from topics covered by existing PRO measures. These include emotional and social aspects of upper extremity transplant, such as Expectations and Perceived Outcomes, Integration and Assimilation of Transplant, Fitting in, and Post-Surgical Challenges and Complications. The broad topic of Satisfaction with Transplant was subdivided into three subtopics: Function, Sensation, and Aesthetics. Satisfaction with Sensation was also identified as a unique domain not evaluated by existing PRO measures. This report operationalizes these eight QOL domains by presenting scoping definitions. This manuscript describes the work that has been completed for domain characterization as an early step toward developing standardized PRO measures to evaluate these important outcomes specific to upper extremity transplantation.
isOpenAccess: True
TL\DR: Qualitative work with experts, clinicians, and patients has identified several domains of QOL that are unique to individuals who have received upper extremity transplants, which are distinct from topics covered by existing PRO measures.
================================
faculty_name: Lei Li
faculty_authorid: 2151533650
paper_id: de54ffba68e0a65b7d9070538e2e84a7d58ced36
paper_title: Establishment of a N1-methyladenosine-related risk signature for breast carcinoma by bioinformatics analysis and experimental validation
publication_link: https://link.springer.com/content/pdf/10.1007/s12282-023-01458-1.pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: A m^1A RNA methylation regulator-related prognostic model was constructed, and a nomogram based on the prognostic model was constructed to provide a theoretical reference for individual counseling and clinical preventive intervention in BRCA.
================================
faculty_name: Lei Li
faculty_authorid: 2066703771
paper_id: 81a0ff93d7a3678330c0fb362fab427217bf2483
paper_title: Population pharmacokinetic analysis and dosing regimen optimization of teicoplanin in critically ill patients with sepsis
publication_link: https://www.frontiersin.org/articles/10.3389/fphar.2023.1132367/pdf 
year_published: 2023 
abstract_paper:Objectives: Teicoplanin has been extensively used in the treatment for infections caused by gram-positive bacteria including methicillin-resistant Staphylococcus aureus (MRSA). However, current teicoplanin treatment is challenging due to relatively low and variable concentrations under standard dosage regimens. This study aimed to investigate the population pharmacokinetics (PPK) characteristics of teicoplanin in adult sepsis patients and provide recommendations for optimal teicoplanin dosing regimens. Methods: A total of 249 serum concentration samples from 59 septic patients were prospectively collected in the intensive care unit (ICU). Teicoplanin concentrations were detected, and patients’ clinical data were recorded. PPK analysis was performed using a non-linear, mixed-effect modeling approach. Monte Carlo simulations were performed to evaluate currently recommended dosing and other dosage regimens. The optimal dosing regimens were defined and compared by different pharmacokinetic/pharmacodynamic parameters, including trough concentration (Cmin), the ratio of 24-h area under the concentration-time curve to the minimum inhibitory concentration (AUC0-24/MIC), as well as the probability of target attainment (PTA) and the cumulative fraction of response (CFR) against MRSA. Results: A two-compartment model adequately described the data. The final model parameter estimates for clearance, central compartment volume of distribution, intercompartmental clearance and peripheral compartment volume were 1.03 L/h, 20.1 L, 3.12 L/h and 101 L, respectively. Glomerular filtration rate (GFR) was the only covariate that significantly affected teicoplanin clearance. Model-based simulations revealed that 3 or 5 loading doses of 12/15 mg/kg every 12 h followed by a maintenance dose of 12/15 mg/kg every 24 h–72 h for patients with different renal functions were required to achieve a target Cmin of 15 mg/L and a target AUC0-24/MIC of 610. For MRSA infections, PTAs and CFRs were not satisfactory for simulated regimens. Prolonging the dosing interval may be easier to achieve the target AUC0-24/MIC than reducing the unit dose for renal insufficient patients. Conclusion: A PPK model for teicoplanin in adult septic patients was successfully developed. Model-based simulations revealed that current standard doses may result in undertherapeutic Cmin and AUC, and a single dose of at least 12 mg/kg may be needed. AUC0-24/MIC should be preferred as the PK/PD indicator of teicoplanin, if AUC estimation is unavailable, in addition to routine detection of teicoplanin Cmin on Day 4, follow-up therapeutic drug monitoring at steady-state is recommended.
isOpenAccess: True
TL\DR: A PPK model for teicoplanin in adult septic patients was successfully developed and revealed that current standard doses may result in undertherapeutic Cmin and AUC, and a single dose of at least 12 mg/kg may be needed.
================================
faculty_name: Lei Li
faculty_authorid: 2066703771
paper_id: c5bb69bbe1d41153d40a9eb31c4af077390c2d99
paper_title: The effects of pharmaceutical interventions on potentially inappropriate medications in older patients: a systematic review and meta-analysis
publication_link: https://www.frontiersin.org/articles/10.3389/fpubh.2023.1154048/pdf 
year_published: 2023 
abstract_paper:Introduction Potentially inappropriate medications (PIMs) is a particular concern in older patients and is associated with negative health outcomes. As various interventions have been developed to manage it, we performed a systematic review and meta-analysis to evaluate the effect of pharmaceutical interventions on outcomes of PIMs in older patients. Methods Meta-analysis of eligible randomized controlled trials (RCTs) was conducted to report the outcomes of pharmaceutical interventions in older patients searching from the databases of Cochrane Library, PubMed, Embase, Web of Science, Clinicaltrials.gov, SinoMed and Chinese Clinical Trial Registry (ChiCTR). The PRISMA guidelines were followed and the protocol was registered in PROSPERO (CRD42019134754). Cochrane bias risk assessment tool and the modified Jadad scale were used to assess the risk bias. RevMan software was used for data processing, analysis and graphical plotting. Results Sixty-five thousand, nine hundred seventy-one patients in 14 RCTs were included. Of the primary outcomes, pharmaceutical interventions could significantly reduce the incidence of PIMs in older patients (OR = 0.51, 95% CI: 0.42, 0.62; p < 0.001), and the number of PIMs per person (MD = -0.41, 95%CI: −0.51, −0.31; p < 0.001), accompanying by a low heterogeneity. Subgroup analysis showed that the application of computer-based clinical decision support for pharmacological interventions could remarkably decrease the incidence of PIMs and two assessment tools were more effective. Of the secondary outcomes, the meta-analysis showed that pharmacological interventions could reduce the number of drugs used per person (MD = -0.94, 95%CI: −1.51, −0.36; p = 0.001) and 30-day readmission rate (OR = 0.58, 95%CI: 0.36, 0.92; p = 0.02), accompanying by a low heterogeneity. However, the pharmaceutical interventions demonstrated no significant improvement on all-cause mortality and the number of falls. Conclusion Our findings supported the efficacy of pharmaceutical interventions to optimize the use and management of drugs in older patients. Systematic review registration https://clinicaltrials.gov/, CRD42019134754.
isOpenAccess: True
TL\DR: The efficacy of pharmaceutical interventions to optimize the use and management of drugs in older patients is supported by a systematic review and meta-analysis of randomized controlled trials.
================================
faculty_name: Lei Li
faculty_authorid: 47930486
paper_id: 01d95a39a3a3f333768a1c123eabaa066bf0d20f
paper_title: P53 protein and the diseases in central nervous system
publication_link: https://www.frontiersin.org/articles/10.3389/fgene.2022.1051395/pdf 
year_published: 2023 
abstract_paper:P53 protein is the product of P53 gene, which is a well acknowledged tumor suppressor gene. The function of P53 and the relevant mechanisms of anti-neoplasm have raised the interest of researchers since many years ago. It is demonstrated that P53 is a basic cell cycle regulator and a strong inhibitor for versatile cancers in humans. However, most research focuses on other organs and systems instead of the central nervous system (CNS). In fact, in recent years, more and more studies have been suggesting that P53 plays a significant role in multiple CNS tumors and other diseases and disorders such as cerebral stroke and neurodegenerative diseases. In this work, we mainly reviewed the P53’s relationship with CNS tumors, cerebral stroke and neurodegenerative diseases, together with the relevant mechanisms, aiming to summarize the research achievements and providing new insight to the future study on diseases in CNS.
isOpenAccess: True
TL\DR: The efficacy of pharmaceutical interventions to optimize the use and management of drugs in older patients is supported by a systematic review and meta-analysis of randomized controlled trials.
================================
faculty_name: Lei Li
faculty_authorid: 2185541065
paper_id: 7a47828ca29d646967e100bfcd8c9457c682bb38
paper_title: Integrated Valve Product Fluid Simulation and Test Verification
publication_link: Not given 
year_published: 2023 
abstract_paper:The integrated valve product’s main function is to electrolytic oxygen generation subsystem to produce hydrogen and oxygen to realize automatic discharge, to maintain the space station astronauts in orbit around in comfort and safety, high reliability, easy maintenance, and the device should be easy replacement of human-computer ergonomics requirements to ensure long-term on-orbit operation station. Based on the above requirements, an integrated valve product based on environmental control and a health protection system is designed. The integrated product includes hydrogen normal and backup emission branches, oxygen normal and backup emission branches. Through fluid simulation and experimental verification, it is verified that the flow rate and other key indicators of the integrated valve product meet the requirements, which has certain reference and guiding significance for the design of similar integrated products in the future.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 2185541065
paper_id: aea4876c3a5b596ef95a828baea8b3d9022cda62
paper_title: Failure Analysis and Improvement of Check Valve Reverse Cut-off Seal
publication_link: https://iopscience.iop.org/article/10.1088/1742-6596/2450/1/012063/pdf 
year_published: 2023 
abstract_paper:Given the failure of reverse cut-off seal performance in the test process of the check valve, the fault location and mechanism analysis were carried out, and the improvement measures were proposed and verified by the test. It is analyzed that the main reason for the failure is the unreasonable design of the moving pair and the welding position of the check valve, which makes the sealing pair cannot fit effectively after the welding of the check valve, leading to the failure of the reverse cut-off seal. By controlling the ratio of the length of the guide surface to the diameter of the guide surface to 1.25, and controlling the distance between the welding position and the sealing pair to 10mm, the failure problem of the reverse cut-off seal of the check valve caused by the unreasonable design of the moving pair and the weld position is successfully solved. The effectiveness of the improved scheme of the check valve is verified by the test.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 84547886
paper_id: 6d91a5ce236d4f97a69eb326296133e7f0a352ba
paper_title: Research on torsional stiffness of flexspline-flexible bearing contact pair in harmonic drive based on macro-micro scale modeling
publication_link: https://www.frontiersin.org/articles/10.3389/fmats.2023.1211019/pdf 
year_published: 2023 
abstract_paper:The flexspline and flexible bearing constitute a critical contact pair in a harmonic drive system, and their torsional stiffness has a significant impact on the performance characteristics manifested by the harmonic drive. In this study, a micro scale three-dimensional fractal model was combined with a macro scale finite element simulation method to establish an equivalent torsional stiffness model for the flexspline-flexible bearing contact pair (FS-FB contact pair), which enables the theoretical prediction of the torsional stiffness of this contact pair. A torsional stiffness testing platform was constructed for a harmonic drive, and the consistency between the experimental results of the torsional stiffness curve and the theoretical predictions validates the effectiveness of the proposed model. The influences of torque, installation eccentricity, and deformation coefficient on the torsional stiffness of the FS-FB contact pair were also discussed. The results indicate that the torsional stiffness of the FS-FB contact pair increases nonlinearly with an increase in torque. On the other hand, the torsional stiffness of the FS-FB contact pair decreases with an increase in installation eccentricity, and increases before subsequently decreasing with an increase in deformation coefficient. Moreover, as torque increases, the impact of installation eccentricity and deformation coefficient on the torsional stiffness diminishes. This article provides a theoretical reference for the optimization design and performance enhancement of harmonic drives.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 12791508
paper_id: 4fac3037fb156bcc42be6d7dbfb90cb933f80f91
paper_title: Correction: Polydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform
publication_link: https://pubs.rsc.org/en/content/articlepdf/2023/ra/d3ra90039h 
year_published: 2023 
abstract_paper:Correction for ‘Polydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform’ by Meng Sun et al., RSC Adv., 2023, 13, 9998–10004, https://doi.org/10.1039/D2RA07737J.
isOpenAccess: True
TL\DR: None
================================
faculty_name: Lei Li
faculty_authorid: 12791508
paper_id: 7fcd5d8f8b492533444a8179a07888df267da5a4
paper_title: Editorial: Strategies for functional polymeric nanocomposites and its multifunctional applications
publication_link: https://www.frontiersin.org/articles/10.3389/fchem.2023.1274460/pdf 
year_published: 2023 
abstract_paper:The development of nanomaterial’s has greatly contributed to the development of modern medicine and optics, and polymers are an important support and branch of nanomaterial’s. They are non-toxic and harmless, can be degraded into small fragments in the body, and are finally excreted without causing inflammation. Due to their many advantages, biodegradable polymers have attracted more and more attention. In this Research Topic, we focus on reviewing and introducing some polymers for wound repair, drug loading or with special optical properties. These articles are categorized into three themes: 1) polydopamine for wound repair; 2) dendrimers as drug carriers; 3) optical polymers.
isOpenAccess: True
TL\DR: None
================================
faculty_name: Lei Li
faculty_authorid: 12791508
paper_id: affdee29f2c6d34e839e9e9a15afd6aa1c9b5af8
paper_title: Polydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform
publication_link: https://pubs.rsc.org/en/content/articlepdf/2023/ra/d2ra07737j 
year_published: 2023 
abstract_paper:A photoresponsive therapeutic antibacterial platform was designed and constructed using polydopamine-functionalized selenium nanoparticles as a carrier loaded with indocyanine green (Se@PDA-ICG). The therapeutic platform was confirmed by characterization and the antibacterial activity of Se@PDA-ICG against Staphylococcus aureus (S. aureus) and Escherichia coli (E. coli) was investigated. Under 808 nm laser irradiation, the antibacterial rate of Se@PDA-ICG against E. coli and S. aureus was 100% at 125 μg mL−1. Furthermore, in a mouse wound infection model, the wound closure rate of the Se@PDA-ICG photoresponse group was 88.74% compared with 45.8% for the control group after 8 days of treatment, indicating that it could effectively kill bacteria and dramatically accelerate the wound healing process. These results suggested that Se@PDA-ICG could be a promising photo-activated antibacterial candidate material for biomedical applications.
isOpenAccess: True
TL\DR: None
================================
faculty_name: Lei Li
faculty_authorid: 12791508
paper_id: c0bdff1f8bd63083641061a1996f844380f91b58
paper_title: Antimicrobial properties of heterojunction BiSnSbO_6-ZnO composites in wastewater treatment
publication_link: https://www.researchsquare.com/article/rs-1747259/latest.pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: None
================================
faculty_name: Lei Li
faculty_authorid: 13072935
paper_id: be141055e9c7d70d37a1ec9499d7455c6816d146
paper_title: A Multilabel Learning-Based Automatic Annotation Method for Semantic Roles in English Text
publication_link: https://ieeexplore.ieee.org/ielx7/6287639/6514899/10264071.pdf 
year_published: 2023 
abstract_paper:With the increasing amount of textual information in the Internet, smart semantic comprehension is a practical demand. Among, automatic annotation for semantic roles remains the fundamental part for effective semantic comprehension. Although machine learning-based methods had received much attention in recent years, they mostly divided each sentences into separable parts for calculation. To deal with such challenge, this paper introduces multilabel learning to propose a novel automatic annotation method for semantic roles in English text. In the semantic representation of words, the method uses convolutional neural networks to extract local feature information of words from the character level. Such design can alleviate the problem of inconspicuous semantic features caused by random initialization of unregistered words. Secondly, in the process of implication recognition, by combining the interactive attention mechanism to construct a capsule for each implication relation separately, the recognition of the final implication relation is completed in the way of categorical learning. At last, some experiments are conducted on real-world data to verify the proposed method with being compared with several typical relevant methods. The obtained results show that the proposal achieves better Macro-F1 results on eight datasets compared to seven algorithms. Besides, the proposal also performs better than others in the sensitivity testing, as its performance can remain stable with the increase of noise input. In summary, the proposal can achieve good results and show strong capability in semantic role labeling tasks.
isOpenAccess: True
TL\DR: None
================================
faculty_name: Lei Li
faculty_authorid: 2151529994
paper_id: a61f910a00c60bbf8b9ba1eae7c1757bb0b36426
paper_title: PTTG1 reprograms asparagine metabolism to promote hepatocellular carcinoma progression.
publication_link: Not given 
year_published: 2023 
abstract_paper:Hepatocellular carcinoma (HCC) is the most common type of primary liver cancer and has a poor prognosis. Pituitary tumor transforming gene 1 (PTTG1) is highly expressed in HCC, suggesting it could play an important role in hepatocellular carcinogenesis. Here, we evaluated the impact of PTTG1 deficiency on HCC development using a diethylnitrosamine (DEN)-induced HCC mouse model and a hepatitis B virus regulatory X protein (HBx)-induced spontaneous HCC mouse model. PTTG1 deficiency significantly suppressed DEN- and HBx-induced hepatocellular carcinogenesis. Mechanistically, PTTG1 promoted asparagine synthetase (ASNS) transcription by binding to its promoter, and asparagine levels were correspondingly increased. The elevated levels of asparagine subsequently activated the mTOR pathway to facilitate HCC progression. In addition, asparaginase treatment reversed the proliferation induced by PTTG1 overexpression. Furthermore, HBx promoted ASNS and asparagine metabolism by upregulating PTTG1 expression. Overall, PTTG1 is involved in the reprogramming of asparagine metabolism to promote HCC progression and may serve as a therapeutic and diagnostic target for HCC.
isOpenAccess: True
TL\DR: None
================================
faculty_name: Lei Li
faculty_authorid: 2151529191
paper_id: 0c840a5a5e483ff48cec60e81aa0b0bfa1a99498
paper_title: A Study of Yuediao Folk Music Knowledge Development in Zhoukou, Henan Province, China
publication_link: https://osf.io/tgyjh/download 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 2151532051
paper_id: 1386e5712607e293f0b0288a133540e60aaeae67
paper_title: Influence of banded ε-martensite and deformation twin on cryogenic toughness of Fe-Mn-xAl-C steel
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 2151532051
paper_id: a64ab230ee2d32f91a05fa2881fb159d90187ee0
paper_title: Study on thermal stability and biocompatibility of bimodal microstructure in Cr–Mn–N austenitic stainless steel
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 2151532051
paper_id: f3ccbd6795a89dc98558679482da836b3c12fac8
paper_title: Effect of intragranular κ carbides and intergranular precipitates on the hot deformation mechanism and dynamic recrystallization mechanism of Fe-28Mn-11Al-1.5C-5Cr lightweight steel
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 2217685348
paper_id: 937bb21fe0836419762ea8410ce989e4840052ec
paper_title: Wavefront shaping improves the transparency of the scattering media: a review
publication_link: https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-29/issue-S1/S11507/Wavefront-shaping-improves-the-transparency-of-the-scattering-media/10.1117/1.JBO.29.S1.S11507.pdf 
year_published: 2023 
abstract_paper:Abstract. Significance Wavefront shaping (WFS) can compensate for distortions by optimizing the wavefront of the input light or reversing the transmission matrix of the media. It is a promising field of research. A thorough understanding of principles and developments of WFS is important for optical research. Aim To provide insight into WFS for researchers who deal with scattering in biomedicine, imaging, and optical communication, our study summarizes the basic principles and methods of WFS and reviews recent progress. Approach The basic principles, methods of WFS, and the latest applications of WFS in focusing, imaging, and multimode fiber (MMF) endoscopy are described. The practical challenges and prospects of future development are also discussed. Results Data-driven learning-based methods are opening up new possibilities for WFS. High-resolution imaging through MMFs can support small-diameter endoscopy in the future. Conclusion The rapid development of WFS over the past decade has shown that the best solution is not to avoid scattering but to find ways to correct it or even use it. WFS with faster speed, more optical modes, and more modulation degrees of freedom will continue to drive exciting developments in various fields.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 2217685348
paper_id: b2274c9fcd2d2c56e64441b4f93013d83faa24cb
paper_title: An ultrahigh-fidelity 3D holographic display using scattering to homogenize the angular spectrum
publication_link: https://www.science.org/doi/pdf/10.1126/sciadv.adi9987?download=true 
year_published: 2023 
abstract_paper:A three-dimensional (3D) holographic display (3DHD) can preserve all the volumetric information about an object. However, the poor fidelity of 3DHD constrains its applications. Here, we present an ultrahigh-fidelity 3D holographic display that uses scattering for homogenization of angular spectrum. A scattering medium randomizes the incident photons and homogenizes the angular spectrum distribution. The redistributed field is recorded by a photopolymer film with numerous modulation modes and a half-wavelength scale pixel size. We have experimentally improved the contrast of a focal spot to 6 × 106 and tightened its spatial resolution to 0.5 micrometers, respectively ~300 and 4.4 times better than digital approaches. By exploiting the spatial multiplexing ability of the photopolymer and the transmission channel selection capability of the scattering medium, we have realized a dynamic holographic display of 3D spirals consisting of 20 foci across 1 millimeter × 1 millimeter × 26 millimeters with uniform intensity.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 2217685348
paper_id: dd3c82415e5704c60703e86a051ab3a003b0122b
paper_title: Intraoperative molecular imaging: 3rd biennial clinical trials update
publication_link: https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-28/issue-5/050901/Intraoperative-molecular-imaging-3rd-biennial-clinical-trials-update/10.1117/1.JBO.28.5.050901.pdf 
year_published: 2023 
abstract_paper:Abstract. Significance This third biennial intraoperative molecular imaging (IMI) conference shows how optical contrast agents have been applied to develop clinically significant endpoints that improve precision cancer surgery. Aim National and international experts on IMI presented ongoing clinical trials in cancer surgery and preclinical work. Previously known dyes (with broader applications), new dyes, novel nonfluorescence-based imaging techniques, pediatric dyes, and normal tissue dyes were discussed. Approach Principal investigators presenting at the Perelman School of Medicine Abramson Cancer Center’s third clinical trials update on IMI were selected to discuss their clinical trials and endpoints. Results Dyes that are FDA-approved or currently under clinical investigation in phase 1, 2, and 3 trials were discussed. Sections on how to move benchwork research to the bedside were also included. There was also a dedicated section for pediatric dyes and nonfluorescence-based dyes that have been newly developed. Conclusions IMI is a valuable adjunct in precision cancer surgery and has broad applications in multiple subspecialties. It has been reliably used to alter the surgical course of patients and in clinical decision making. There remain gaps in the utilization of IMI in certain subspecialties and potential for developing newer and improved dyes and imaging techniques.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 2151532629
paper_id: 8c2fae4c9622fefe0e7594e7637175d2bb4e2125
paper_title: Variation of virtual temperature and wind in the atmospheric boundary layer over the pearl river estuary during 2011–2020
publication_link: https://www.frontiersin.org/articles/10.3389/fenvs.2022.1104553/pdf 
year_published: 2023 
abstract_paper:Most studies of the effects of urbanisation on local climate have been based on ground observation data. In contrast, we used observation data from a boundary layer radar wind profiler, radio-acoustic sounding system, and automatic meteorological station located at Shenzhen Bao’an International Airport to analyse changes in wind and virtual temperature in the upper level atmosphere, with a top height of 1,200 m, over the Pearl River Estuary between 2011 and 2020. Our results show that during the decade evaluated, the wind speed and virtual temperature of the upper level atmosphere over the Pearl River Estuary changed very significantly and faster than the changes observed at ground level. During the study period, the linear warming rate of the virtual temperature of the upper level atmosphere reached 0.24°C/a, whereas that on the land surface was 0.17°C/a. The mean decreases in the upper level atmosphere and land surface wind speeds were −0.12 and −0.05 m/s·a, respectively. Additionally, the rate of change in the upper level climate was faster in winter than in summer for both wind speed and virtual temperature. These changes in the climate of the upper level atmosphere over the Pearl River Estuary may be related to the rapid increase in the number of high-rise buildings in the region during that decade, which generally negatively affected the atmospheric environment.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 2151532629
paper_id: 8e54fd15fb5f8c035a772ecdfdebd8c9449d4656
paper_title: Numerical simulation research on the overturning of gantry crane by downbursts
publication_link: http://www.cell.com/article/S2405844023058498/pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 2185864428
paper_id: 75d672cf3e648bdbeb9bbe31e91d8d721b550304
paper_title: Combining non-negative matrix factorization with graph Laplacian regularization for predicting drug-miRNA associations based on multi-source information fusion
publication_link: https://www.frontiersin.org/articles/10.3389/fphar.2023.1132012/pdf 
year_published: 2023 
abstract_paper:Increasing evidences suggest that miRNAs play a key role in the occurrence and progression of many complex human diseases. Therefore, targeting dysregulated miRNAs with small molecule drugs in the clinical has become a new treatment. Nevertheless, it is high cost and time-consuming for identifying miRNAs-targeted with drugs by biological experiments. Thus, more reliable computational method for identification associations of drugs with miRNAs urgently need to be developed. In this study, we proposed an efficient method, called GNMFDMA, to predict potential associations of drug with miRNA by combining graph Laplacian regularization with non-negative matrix factorization. We first calculated the overall similarity matrices of drugs and miRNAs according to the collected different biological information. Subsequently, the new drug-miRNA association adjacency matrix was reformulated based on the K nearest neighbor profiles so as to put right the false negative associations. Finally, graph Laplacian regularization collaborative non-negative matrix factorization was used to calculate the association scores of drugs with miRNAs. In the cross validation, GNMFDMA obtains AUC of 0.9193, which outperformed the existing methods. In addition, case studies on three common drugs (i.e., 5-Aza-CdR, 5-FU and Gemcitabine), 30, 31 and 34 of the top-50 associations inferred by GNMFDMA were verified. These results reveal that GNMFDMA is a reliable and efficient computational approach for identifying the potential drug-miRNA associations.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 31864483
paper_id: 73c9f93d448a359c744447af6daa0b599fb9be4b
paper_title: Optimizing Heat Treatment to Improve the Microstructures and Mechanical Properties of 5CrNiMoV Steel
publication_link: https://www.mdpi.com/2075-4701/13/7/1263/pdf?version=1689243786 
year_published: 2023 
abstract_paper:A strategy combining intercritical quenching, pre-tempering, and tempering processes was implemented to optimize the microstructures and mechanical properties of 5CrNiMoV steel. By intercritically quenching at 1050 °C, pr-tempering at 600 °C, and tempering at 550 °C, the steel exhibited a comprehensive performance with a yield strength of 1120 MPa, an ultimate tensile strength of 1230 MPa, and an elongation of 8.2%. The high strength of the steel is attributed to the presence of tempered martensite and abundant secondary carbides. The favorable ductility is mainly provided by the pearlite inherited from intercritical quenching and tempering. Additionally, the precipitation of secondary carbides not only enhances precipitation strengthening, but also reduces the dislocation density and lattice strain of the matrix, thereby enhancing strength and ductility. This study offers a scheme for producing strong and ductile 5CrNiMoV steel.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 2151531262
paper_id: acd17a514d5aa3fbdb150205641aa05400e7e96b
paper_title: Phosphorus Availability Affects the Photosynthesis and Antioxidant System of Contrasting Low-P-Tolerant Cotton Genotypes
publication_link: https://www.mdpi.com/2076-3921/12/2/466/pdf?version=1677123742 
year_published: 2023 
abstract_paper:Phosphorus (P) is an essential macronutrient, and an important component of plant metabolism. However, little is known about the effects of low P availability on P absorption, the photosynthetic electron transport chain, and the antioxidant system in cotton. This study used cotton genotypes (sensitive FJA and DLNTDH and tolerant BX014 and LuYuan343) with contrasting low-P tolerance in a hydroponic experiment under 15 µM, 50 µM, and 500 μM P concentrations. The results showed that low P availability reduced plant development and leaf area, shoot length, and dry weight in FJA and DLNADH, compared to BX014 and LuYuan343. The low P availability decreased the gas-exchange parameters such as the net photosynthetic rate, transpiration rate, and stomatal conductance, and increased the intercellular CO2 concentration. Chlorophyll a fluorescence demonstrated that the leaves’ absorption and trapped-energy flux were largely steady. In contrast, considerable gains in absorption and trapped-energy flux per reaction center resulted from decreases in the electron transport per reaction center under low-P conditions. In addition, low P availability reduced the activities of antioxidant enzymes and increased the content of malondialdehyde in the cotton genotypes, especially in FJA and DLNTDH. Moreover, low P availability reduced the activity of PEPC and generated a decline in the content of ATP and NADPH. Our research can provide a theoretical physiological basis for the growth and tolerance of cotton under low-P conditions.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 2151531262
paper_id: af7115085a46a2b884c38164050c0a4f23fb92af
paper_title: Integrated Transcriptome and Small RNA Sequencing Analyses Reveals Insights into the Molecular Mechanism of Seed Germination in Mung Bean
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 2066702652
paper_id: 7005e58d3b5593c4be1d9e2933825d0a99ca93cc
paper_title: Low-Voltage Solution-Processed Zinc-Doped CuI Thin Film Transistors with NOR Logic and Artificial Synaptic Function
publication_link: https://www.mdpi.com/2079-4991/13/16/2345/pdf?version=1692146819 
year_published: 2023 
abstract_paper:Low-voltage Zn-doped CuI thin film transistors (TFTs) gated by chitosan dielectric were fabricated at a low temperature. The Zn-doped CuI TFT exhibited a more superior on/off current ratio than CuI TFT due to the substitution or supplementation of copper vacancies by Zn ions. The Zn-doped CuI films were characterized by scanning electron microscope, X-ray diffraction, and X-ray photoelectron spectroscopy. The Zn-doped CuI TFTs exhibited an on/off current ratio of 1.58 × 104, a subthreshold swing of 70 mV/decade, and a field effect mobility of 0.40 cm2V−1s−1, demonstrating good operational stability. Due to the electric-double-layer (EDL) effect and high specific capacitance (17.3 μF/cm2) of chitosan gate dielectric, Zn-doped CuI TFT operates at a voltage below −2 V. The threshold voltage is −0.2 V. In particular, we have prepared Zn-doped CuI TFTs with two in-plane gates and NOR logic operation is implemented on such TFTs. In addition, using the ion relaxation effect and EDL effect of chitosan film, a simple pain neuron simulation is realized on such a p-type TFTs for the first time through the bottom gate to regulate the carrier transport of the channel. This p-type device has promising applications in low-cost electronic devices, complementary electronic circuit, and biosensors.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 47681096
paper_id: 45e961e87f86888cbe0a117b7a21335690e13c17
paper_title: Oral phage therapy with microencapsulated phage A221 against Escherichia coli infections in weaned piglets
publication_link: https://bmcvetres.biomedcentral.com/counter/pdf/10.1186/s12917-023-03724-y 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 47681096
paper_id: 56de9c4c63ee74757be1b203d2ea852690087ded
paper_title: Hence, Socrates is mortal: A Benchmark for Natural Language Syllogistic Reasoning
publication_link: https://aclanthology.org/2023.findings-acl.148.pdf 
year_published: 2023 
abstract_paper:Syllogistic reasoning, a typical form of deductive reasoning, is a critical capability widely required in natural language understanding tasks, such as text entailment and question answering. To better facilitate research on syllogis-tic reasoning, we develop a benchmark called S YLLO B ASE that differs from existing syllo-gistic datasets in three aspects: (1) Covering a complete taxonomy of syllogism reasoning patterns; (2) Containing both automatically and manually constructed samples; and (3) Involving both the generation and understanding tasks. We automatically construct 50k template-based syllogism samples by mining syllogism patterns from Wikidata and ConceptNet. To improve our dataset’s naturalness and challenge, we apply GPT-3 to paraphrase the template-based data and further manually rewrite 1,000 samples as the test set. State-of-the-art pre-trained language models can achieve the best generation ROUGE-L of 38.72 by T5 and the best multi-choice accuracy of 72.77% by RoBERTa on S YLLO B ASE , which indicates the great challenge of learning diverse syllo-gistic reasoning types on S YLLO B ASE . Our datasets are released at https://github.com/ casually-PYlearner
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 47681096
paper_id: 75b68d0903af9d9f6e47ce3cf7e1a7d27ec811dc
paper_title: Provable Robust Watermarking for AI-Generated Text
publication_link: https://arxiv.org/pdf/2306.17439 
year_published: 2023 
abstract_paper:We study the problem of watermarking large language models (LLMs) generated text -- one of the most promising approaches for addressing the safety challenges of LLM usage. In this paper, we propose a rigorous theoretical framework to quantify the effectiveness and robustness of LLM watermarks. We propose a robust and high-quality watermark method, Unigram-Watermark, by extending an existing approach with a simplified fixed grouping strategy. We prove that our watermark method enjoys guaranteed generation quality, correctness in watermark detection, and is robust against text editing and paraphrasing. Experiments on three varying LLMs and two datasets verify that our Unigram-Watermark achieves superior detection accuracy and comparable generation quality in perplexity, thus promoting the responsible use of LLMs. Code is available at https://github.com/XuandongZhao/Unigram-Watermark.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 47681096
paper_id: 8a9ff288d3800863ec80c5abe3998f0d35f2d6da
paper_title: MCM6 is a Poor Prognostic Biomarker and Promotes Progression in Breast Cancer.
publication_link: https://www.imrpress.com/journal/FBL/28/8/10.31083/j.fbl2808188/pdf 
year_published: 2023 
abstract_paper:BACKGROUND
Breast cancer is the commonest global malignancy and the primary cause of carcinoma death. MCM6 is vital to carcinogenesis, but the pathogenesis of MCM6 remains unclear.


METHODS
MCM6 expression in patients with breast cancer was examined through The Cancer Genome Atlas (TCGA) database, immunohistochemistry, Quantitative Real-Time PCR (qRT‒PCR) and Western blotting. The prognostic factors were assessed by the Kaplan‒Meier method and Cox regression. On the basis of the key factors selected by multivariable Cox regression analysis, a nomogram risk prediction model was adopted for clinical risk assessment. The TCGA database was utilized to determine how MCM6 is correlated with chemotherapy sensitivity, immune checkpoint-related genes (ICGs), tumor-infiltrating immune cells, along with tumor mutation burden (TMB) and methylation. The impact of MCM6 on carcinoma cells was investigated in terms of proliferation, cell cycle as well as migrating and invasive behavior through CCK assays, flow cytometry, wound healing assays, Transwell assays and xenotransplantation experiments.


RESULTS
MCM6 expression was upregulated, which is closely associated with the size of the tumor (p = 0.001) and lymph node metastasis (p = 0.012) in patients with breast cancer. Multivariate analysis revealed MCM6 to be an independent risk factor for prognosis in patients with breast carcinoma. The nomograph prediction model included MCM6, age, ER, M and N stage, which displayed good discrimination with a C index of 0.817 and good calibration. Overexpression of MCM6 correlated with chemotherapy sensitivity, immune checkpoint-related genes (ICGs), tumor-infiltrating immune cells, tumor mutation burden (TMB), and methylation. Silencing MCM6 significantly inhibited proliferation, prolonged the G1 phase of the cell cycle, and restrained the proliferation, migration and invasive behavior of cancerous cells and inhibited tumor growth in vivo.


CONCLUSIONS
Our research shows that MCM6 is highly expressed in breast cancer and can be used as an independent prognostic factor, which is expected to become a new target for the treatment of breast cancer in the future.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 47681096
paper_id: a499e33f815180fa77c5067b0dfc0dc540940da0
paper_title: p53 deacetylation alleviates calcium oxalate deposition-induced renal fibrosis by inhibiting ferroptosis.
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 47681096
paper_id: b3a587d4cbe94d5e86f80ef7cce0b80fd9bf5bcd
paper_title: Gut microbiota in patients with kidney stones: a systematic review and meta-analysis
publication_link: https://bmcmicrobiol.biomedcentral.com/counter/pdf/10.1186/s12866-023-02891-0 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 47681096
paper_id: c10808e5183ece07057050d1896ba81031d6640b
paper_title: Effect of instant surgery compared with traditional management on paediatric complicated acute appendicitis post‐surgery wound: A meta‐analysis
publication_link: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/iwj.14163 
year_published: 2023 
abstract_paper:A meta‐analysis study to assess the influence of instant surgery (IS) compared with conservative therapy (CT) on paediatric complicated acute appendicitis (CAA) post‐surgery wounds. A comprehensive literature examination until January 2023 was implemented, and 2098 linked studies were appraised. The picked studies contained 66 674 subjects with paediatric CAA post‐surgery wounds in the picked studies' baseline; 64 643 of them were using IS, and 2031 were using CT. The odds ratio (OR) in addition to 95% confidence intervals (CIs) were used to calculate the consequence of the IS compared with the CT on paediatric CAA post‐surgery wounds using the dichotomous and continuous styles and a fixed or random model. The IS had a significantly higher wound infection (OR, 4.97; 95% CI, 2.35–10.54, P < .001) with moderate heterogeneity (I2 = 57%) compared with the CT in a paediatric CAA post‐surgery wound. However, no significant difference was found between IS and CT in total antibiotic duration (MD, −5.34; 95% CI,−12.67 to −1.98, P = .15) with high heterogeneity (I2 = 95%) in paediatric CAA post‐surgery wounds. The IS had a significantly higher wound infection; however, no significant difference was found in total antibiotic duration compared with the CT in paediatric CAA post‐surgery wounds. Although precautions should be taken when commerce with the consequences because most of the studies picked for this meta‐analysis had low sample sizes.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 47681096
paper_id: c25d2a27f1abe169d7b68078071b6698f0980469
paper_title: Protecting Language Generation Models via Invisible Watermarking
publication_link: https://arxiv.org/pdf/2302.03162 
year_published: 2023 
abstract_paper:Language generation models have been an increasingly powerful enabler for many applications. Many such models offer free or affordable API access, which makes them potentially vulnerable to model extraction attacks through distillation. To protect intellectual property (IP) and ensure fair use of these models, various techniques such as lexical watermarking and synonym replacement have been proposed. However, these methods can be nullified by obvious countermeasures such as"synonym randomization". To address this issue, we propose GINSEW, a novel method to protect text generation models from being stolen through distillation. The key idea of our method is to inject secret signals into the probability vector of the decoding steps for each target token. We can then detect the secret message by probing a suspect model to tell if it is distilled from the protected one. Experimental results show that GINSEW can effectively identify instances of IP infringement with minimal impact on the generation quality of protected APIs. Our method demonstrates an absolute improvement of 19 to 29 points on mean average precision (mAP) in detecting suspects compared to previous methods against watermark removal attacks.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Lei Li
faculty_authorid: 47681096
paper_id: f7912c9af20f95cddaa3c959246ff63d34ab3a57
paper_title: Comprehensive Analysis of Cuproptosis Genes and Identification of Cuproptosis Subtypes in Breast Cancer
publication_link: Not given 
year_published: 2023 
abstract_paper:Background Copper-induced death (cuproptosis) is copper-dependent regulated cell death, which is different from known death mechanisms and is dependent on mitochondrial respiration. However, its effect on breast cancer (BRCA) is unclear. Objective The objective of this study is to explore the important clinical significance of cuproptosis genes and to provide a new idea for guiding the personalized immunotherapy strategy of BRCA patients. Materials and Methods We collected cuproptosis genes from published work. The gene alteration, differential expression, and prognostic value of cuproptosis genes were explored in BRCA based on TCGA database. We identified two subtypes (clusters A and B) by performing unsupervised clustering. The difference between two clusters was deeply explored, including clinical features, differential expressed genes (DEGs), pathways, and immune cell infiltration. Based on the DEGs between two clusters, a cuproptosis score was constructed and its predictive capability for overall survival of BRCA patients was validated. Results and Discussion Patients with high cuproptosis score have worse survival status, with an increased infiltration level of most immune cells. Further analysis suggested that BRCA patients with high cuproptosis score may be sensitive to immune checkpoint inhibitor (ICI) treatment. Conclusion Our findings may improve our understanding of cuproptosis in BRCA and may distinguish patients suitable for ICI treatment.
isOpenAccess: True
TL\DR: The findings may improve the understanding of cuproptosis in BRCA and may distinguish patients suitable for ICI treatment.
================================
faculty_name: Lei Li
faculty_authorid: 2066699630
paper_id: 3c92fd24ea2a49aeba4b368abe3ef13cbce40987
paper_title: Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions
publication_link: https://aclanthology.org/2023.findings-eacl.81.pdf 
year_published: 2023 
abstract_paper:Extreme Multi-label Text Classification (XMTC) has been a tough challenge in machine learning research and applications due to the sheer sizes of the label spaces and the severe data scarcity problem associated with the long tail of rare labels in highly skewed distributions. This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents (as queries) to relevant label descriptions. To further enhance the quality of label descriptions, we propose to generate pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions.The proposed approach achieves the state-of-the-art (SOTA) performance of overall label prediction on XMTC benchmark datasets and especially outperforms the SOTA models in the tail label prediction. We also provide a theoretical analysis for relating the BoW and neural models w.r.t. performance lower bound.
isOpenAccess: True
TL\DR: The findings may improve the understanding of cuproptosis in BRCA and may distinguish patients suitable for ICI treatment.
================================
faculty_name: Teruko Mitamura
faculty_authorid: 1706595
paper_id: 444737639aeea4e1e616509e368afb0bae8f89d6
paper_title: Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA
publication_link: https://aclanthology.org/2023.dialdoc-1.11.pdf 
year_published: 2023 
abstract_paper:The DialDoc 2023 shared task has expanded the document-grounded dialogue task to encompass multiple languages, despite having limited annotated data. This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-agnostic approach is superior. Additionally, the study investigates the impact of query rewriting techniques using large language models, such as ChatGPT, on multilingual, document-grounded question-answering systems. The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.
isOpenAccess: True
TL\DR: This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-gnostic approach is superior.
================================
faculty_name: Teruko Mitamura
faculty_authorid: 1706595
paper_id: ff77105b2c345f54e1a87f4fbb3a701201f0c1a8
paper_title: Hierarchical Event Grounding
publication_link: http://arxiv.org/pdf/2302.04197 
year_published: 2023 
abstract_paper:Event grounding aims at linking mention references in text corpora to events from a knowledge base (KB). Previous work on this task focused primarily on linking to a single KB event, thereby overlooking the hierarchical aspects of events. Events in documents are typically described at various levels of spatio-temporal granularity. These hierarchical relations are utilized in downstream tasks of narrative understanding and schema construction. In this work, we present an extension to the event grounding task that requires tackling hierarchical event structures from the KB. Our proposed task involves linking a mention reference to a set of event labels from a subevent hierarchy in the KB. We propose a retrieval methodology that leverages event hierarchy through an auxiliary hierarchical loss. On an automatically created multilingual dataset from Wikipedia and Wikidata, our experiments demonstrate the effectiveness of the hierarchical loss against retrieve and re-rank baselines. Furthermore, we demonstrate the systems' ability to aid hierarchical discovery among unseen events. Code is available at https://github.com/JefferyO/Hierarchical-Event-Grounding
isOpenAccess: True
TL\DR: This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-gnostic approach is superior.
================================
faculty_name: Louis-Philippe Morency
faculty_authorid: 49933077
paper_id: 0a425c0d87c674b142104a07e17c5084b3ad28ca
paper_title: Quantifying & Modeling Feature Interactions: An Information Decomposition Framework
publication_link: https://arxiv.org/pdf/2302.12247 
year_published: 2023 
abstract_paper:The recent explosion of interest in multimodal applications has resulted in a wide selection of datasets and methods for representing and inte-grating information from different signals. Despite these empirical advances, there remain fundamental research questions: how can we quantify the nature of interactions that exist among input features? Subsequently, how can we capture these interactions using suitable data-driven methods? To answer this question, we propose an information-theoretic approach to quantify the degree of redundancy , uniqueness , and synergy across input features, which we term the PID statistics of a multimodal distribution. Using 2 newly proposed estimators that scale to high-dimensional distributions, we demonstrate their usefulness in quantifying the interactions within multimodal datasets, the nature of interactions captured by multimodal models, and principled approaches for model selection. We conduct extensive experiments on both synthetic datasets where the PID statistics are known and on large-scale multimodal benchmarks where PID estimation was previously impossible. Finally, to demonstrate the real-world applicability of our approach, we present three case studies in pathology, mood prediction, and robotic perception where our framework accurately recommends strong multimodal models for each application.
isOpenAccess: True
TL\DR: This work proposes an information-theoretic approach to quantify the degree of redundancy, uniqueness, and synergy across input features, which is term the PID statistics of a multimodal distribution.
================================
faculty_name: Louis-Philippe Morency
faculty_authorid: 49933077
paper_id: 114eafdb14145f002d503f259d768d67dae87479
paper_title: Reconstructing the neurodynamics of face perception during real world vision in humans using intracranial EEG recordings
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Louis-Philippe Morency
faculty_authorid: 49933077
paper_id: 40fb36ee67fdde99b196b4d1772de114aa821698
paper_title: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning
publication_link: http://arxiv.org/pdf/2306.16413 
year_published: 2023 
abstract_paper:Learning multimodal representations involves integrating information from multiple heterogeneous sources of data. In order to accelerate progress towards understudied modalities and tasks while ensuring real-world robustness, we release MultiZoo, a public toolkit consisting of standardized implementations of>20 core multimodal algorithms and MultiBench, a large-scale benchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas. Together, these provide an automated end-to-end machine learning pipeline that simplifies and standardizes data loading, experimental setup, and model evaluation. To enable holistic evaluation, we offer a comprehensive methodology to assess (1) generalization, (2) time and space complexity, and (3) modality robustness. MultiBench paves the way towards a better understanding of the capabilities and limitations of multimodal models, while ensuring ease of use, accessibility, and reproducibility. Our toolkits are publicly available, will be regularly updated, and welcome inputs from the community.
isOpenAccess: True
TL\DR: MultiZoo is released, a public toolkit consisting of standardized implementations of>20 core multimodal algorithms and MultiBench, a large-scale benchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas that provide an automated end-to-end machine learning pipeline that simplifies and standardizes data loading, experimental setup, and model evaluation.
================================
faculty_name: Louis-Philippe Morency
faculty_authorid: 49933077
paper_id: 47a4ac301820c3ea7da4efb8e2466cc6468ad631
paper_title: SenteCon: Leveraging Lexicons to Learn Human-Interpretable Language Representations
publication_link: http://arxiv.org/pdf/2305.14728 
year_published: 2023 
abstract_paper:Although deep language representations have become the dominant form of language featurization in recent years, in many settings it is important to understand a model's decision-making process. This necessitates not only an interpretable model but also interpretable features. In particular, language must be featurized in a way that is interpretable while still characterizing the original text well. We present SenteCon, a method for introducing human interpretability in deep language representations. Given a passage of text, SenteCon encodes the text as a layer of interpretable categories in which each dimension corresponds to the relevance of a specific category. Our empirical evaluations indicate that encoding language with SenteCon provides high-level interpretability at little to no cost to predictive performance on downstream tasks. Moreover, we find that SenteCon outperforms existing interpretable language representations with respect to both its downstream performance and its agreement with human characterizations of the text.
isOpenAccess: True
TL\DR: This work presents SenteCon, a method for introducing human interpretability in deep language representations that outperforms existing interpretable language representations with respect to both its downstream performance and its agreement with human characterizations of the text.
================================
faculty_name: Louis-Philippe Morency
faculty_authorid: 49933077
paper_id: 64703e760f662b1c0f647931bb63fe57e5ba91e4
paper_title: Neural Mixed Effects for Nonlinear Personalized Predictions
publication_link: https://dl.acm.org/doi/pdf/10.1145/3577190.3614115 
year_published: 2023 
abstract_paper:Personalized prediction is a machine learning approach that predicts a person’s future observations based on their past labeled observations and is typically used for sequential tasks, e.g., to predict daily mood ratings. When making personalized predictions, a model can combine two types of trends: (a) trends shared across people, i.e., person-generic trends, such as being happier on weekends, and (b) unique trends for each person, i.e., person-specific trends, such as a stressful weekly meeting. Mixed effect models are popular statistical models to study both trends by combining person-generic and person-specific parameters. Though linear mixed effect models are gaining popularity in machine learning by integrating them with neural networks, these integrations are currently limited to linear person-specific parameters: ruling out nonlinear person-specific trends. In this paper, we propose Neural Mixed Effect (NME) models to optimize nonlinear person-specific parameters anywhere in a neural network in a scalable manner1. NME combines the efficiency of neural network optimization with nonlinear mixed effects modeling. Empirically, we observe that NME improves performance across six unimodal and multimodal datasets, including a smartphone dataset to predict daily mood and a mother-adolescent dataset to predict affective state sequences where half the mothers experience symptoms of depression. Furthermore, we evaluate NME for two model architectures, including for neural conditional random fields (CRF) to predict affective state sequences where the CRF learns nonlinear person-specific temporal transitions between affective states. Analysis of these person-specific transitions on the mother-adolescent dataset shows interpretable trends related to the mother’s depression symptoms.
isOpenAccess: True
TL\DR: NME combines the efficiency of neural network optimization with nonlinear mixed effects modeling and improves performance across six unimodal and multimodal datasets, including a smartphone dataset to predict daily mood and a mother-adolescent datasets to predict affective state sequences where half the mothers experience symptoms of depression.
================================
faculty_name: Louis-Philippe Morency
faculty_authorid: 49933077
paper_id: 6838c43e702a3f995967ba2e3edd5f65ff5f5511
paper_title: SHAP-based Prediction of Mother's History of Depression to Understand the Influence on Child Behavior
publication_link: https://dl.acm.org/doi/pdf/10.1145/3577190.3614136 
year_published: 2023 
abstract_paper:Depression strongly impacts parents’ behavior. Does parents’ depression strongly affect the behavior of their children as well? To investigate this question, we compared dyadic interactions between 73 depressed and 75 non-depressed mothers and their adolescent child. Families were of low income and 84% were white. Child behavior was measured from audio-video recordings using manual annotation of verbal and nonverbal behavior by expert coders and by multimodal computational measures of facial expression, face and head dynamics, prosody, speech behavior, and linguistics. For both sets of measures, we used Support Vector Machines. For computational measures, we investigated the relative contribution of single versus multiple modalities using a novel approach to SHapley Additive exPlanations (SHAP). Computational measures outperformed manual ratings by human experts. Among individual computational measures, prosody was the most informative. SHAP reduction resulted in a four-fold decrease in the number of features and highest performance (77% accuracy; positive and negative agreements at 75% and 76%, respectively). These findings suggest that maternal depression strongly impacts the behavior of adolescent children; differences are most revealed in prosody; multimodal features together with SHAP reduction are most powerful.
isOpenAccess: True
TL\DR: NME combines the efficiency of neural network optimization with nonlinear mixed effects modeling and improves performance across six unimodal and multimodal datasets, including a smartphone dataset to predict daily mood and a mother-adolescent datasets to predict affective state sequences where half the mothers experience symptoms of depression.
================================
faculty_name: Louis-Philippe Morency
faculty_authorid: 49933077
paper_id: 7dab13685363176edc5cc7882d0890811d2cb584
paper_title: Counterfactual Augmentation for Multimodal Learning Under Presentation Bias
publication_link: http://arxiv.org/pdf/2305.14083 
year_published: 2023 
abstract_paper:In real-world machine learning systems, labels are often derived from user behaviors that the system wishes to encourage. Over time, new models must be trained as new training examples and features become available. However, feedback loops between users and models can bias future user behavior, inducing a presentation bias in the labels that compromises the ability to train new models. In this paper, we propose counterfactual augmentation, a novel causal method for correcting presentation bias using generated counterfactual labels. Our empirical evaluations demonstrate that counterfactual augmentation yields better downstream performance compared to both uncorrected models and existing bias-correction methods. Model analyses further indicate that the generated counterfactuals align closely with true counterfactuals in an oracle setting.
isOpenAccess: True
TL\DR: NME combines the efficiency of neural network optimization with nonlinear mixed effects modeling and improves performance across six unimodal and multimodal datasets, including a smartphone dataset to predict daily mood and a mother-adolescent datasets to predict affective state sequences where half the mothers experience symptoms of depression.
================================
faculty_name: Louis-Philippe Morency
faculty_authorid: 49933077
paper_id: 8d0c37eee7162f33178979b4183f0211e2dcae0d
paper_title: Difference-Masking: Choosing What to Mask in Continued Pretraining
publication_link: http://arxiv.org/pdf/2305.14577 
year_published: 2023 
abstract_paper:The self-supervised objective of masking-and-predicting has led to promising performance gains on a variety of downstream tasks. However, while most approaches randomly mask tokens, there is strong intuition that deciding what to mask can substantially improve learning outcomes. We investigate this in continued pretraining setting in which pretrained models continue to pretrain on domain-specific data before performing some downstream task. We introduce Difference-Masking, a masking strategy that automatically chooses what to mask during continued pretraining by considering what makes a task domain different from the pretraining domain. Empirically, we find that Difference-Masking outperforms baselines on continued pretraining settings across four diverse language-only and multimodal video tasks.
isOpenAccess: True
TL\DR: NME combines the efficiency of neural network optimization with nonlinear mixed effects modeling and improves performance across six unimodal and multimodal datasets, including a smartphone dataset to predict daily mood and a mother-adolescent datasets to predict affective state sequences where half the mothers experience symptoms of depression.
================================
faculty_name: Louis-Philippe Morency
faculty_authorid: 49933077
paper_id: 8d53c510928ad1164aebea4d9477812ed1893be2
paper_title: Expanding the Role of Affective Phenomena in Multimodal Interaction Research
publication_link: https://dl.acm.org/doi/pdf/10.1145/3577190.3614171 
year_published: 2023 
abstract_paper:In recent decades, the field of affective computing has made substantial progress in advancing the ability of AI systems to recognize and express affective phenomena, such as affect and emotions, during human-human and human-machine interactions. This paper describes our examination of research at the intersection of multimodal interaction and affective computing, with the objective of observing trends and identifying understudied areas. We examined over 16,000 papers from selected conferences in multimodal interaction, affective computing, and natural language processing: ACM International Conference on Multimodal Interaction, AAAC International Conference on Affective Computing and Intelligent Interaction, Annual Meeting of the Association for Computational Linguistics, and Conference on Empirical Methods in Natural Language Processing. We identified 910 affect-related papers and present our analysis of the role of affective phenomena in these papers. We find that this body of research has primarily focused on enabling machines to recognize or express affect and emotion; there has been limited research on how affect and emotion predictions might, in turn, be used by AI systems to enhance machine understanding of human social behaviors and cognitive states. Based on our analysis, we discuss directions to expand the role of affective phenomena in multimodal interaction research.
isOpenAccess: True
TL\DR: An examination of research at the intersection of multimodal interaction and affective computing, with the objective of observing trends and identifying understudied areas, finds that this body of research has primarily focused on enabling machines to recognize or express affect and emotion.
================================
faculty_name: Louis-Philippe Morency
faculty_authorid: 49933077
paper_id: 90b09bdb1bd78875ee8d8d324a568a36955e4765
paper_title: Multimodal Fusion Interactions: A Study of Human and Automatic Quantification
publication_link: https://dl.acm.org/doi/pdf/10.1145/3577190.3614151 
year_published: 2023 
abstract_paper:In order to perform multimodal fusion of heterogeneous signals, we need to understand their interactions: how each modality individually provides information useful for a task and how this information changes in the presence of other modalities. In this paper, we perform a comparative study of how humans annotate two categorizations of multimodal interactions: (1) partial labels, where different annotators annotate the label given the first, second, and both modalities, and (2) counterfactual labels, where the same annotator annotates the label given the first modality before asking them to explicitly reason about how their answer changes when given the second. We further propose an alternative taxonomy based on (3) information decomposition, where annotators annotate the degrees of redundancy: the extent to which modalities individually and together give the same predictions, uniqueness: the extent to which one modality enables a prediction that the other does not, and synergy: the extent to which both modalities enable one to make a prediction that one would not otherwise make using individual modalities. Through experiments and annotations, we highlight several opportunities and limitations of each approach and propose a method to automatically convert annotations of partial and counterfactual labels to information decomposition, yielding an accurate and efficient method for quantifying multimodal interactions.
isOpenAccess: True
TL\DR: A comparative study of how humans annotate two categorizations of multimodal interactions is performed and a method to automatically convert annotations of partial and counterfactual labels to information decomposition is proposed, yielding an accurate and efficient method for quantifying multimodals interactions.
================================
faculty_name: Louis-Philippe Morency
faculty_authorid: 49933077
paper_id: a988c09b7e76e86a93edcbf3f284dd028b0fb406
paper_title: Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications
publication_link: http://arxiv.org/pdf/2306.04539 
year_published: 2023 
abstract_paper:In many machine learning systems that jointly learn from multiple modalities, a core research question is to understand the nature of multimodal interactions: the emergence of new task-relevant information during learning from both modalities that was not present in either alone. We study this challenge of interaction quantification in a semi-supervised setting with only labeled unimodal data and naturally co-occurring multimodal data (e.g., unlabeled images and captions, video and corresponding audio) but when labeling them is time-consuming. Using a precise information-theoretic definition of interactions, our key contributions are the derivations of lower and upper bounds to quantify the amount of multimodal interactions in this semi-supervised setting. We propose two lower bounds based on the amount of shared information between modalities and the disagreement between separately trained unimodal classifiers, and derive an upper bound through connections to approximate algorithms for min-entropy couplings. We validate these estimated bounds and show how they accurately track true interactions. Finally, two semi-supervised multimodal applications are explored based on these theoretical results: (1) analyzing the relationship between multimodal performance and estimated interactions, and (2) self-supervised learning that embraces disagreement between modalities beyond agreement as is typically done.
isOpenAccess: True
TL\DR: A comparative study of how humans annotate two categorizations of multimodal interactions is performed and a method to automatically convert annotations of partial and counterfactual labels to information decomposition is proposed, yielding an accurate and efficient method for quantifying multimodals interactions.
================================
faculty_name: Louis-Philippe Morency
faculty_authorid: 49933077
paper_id: bd94ea913fcf8698f2257f87a17755b46a420458
paper_title: Representation Learning for Interpersonal and Multimodal Behavior Dynamics: A Multiview Extension of Latent Change Score Models
publication_link: https://dl.acm.org/doi/pdf/10.1145/3577190.3614118 
year_published: 2023 
abstract_paper:Characterizing the dynamics of behavior across multiple modalities and individuals is a vital component of computational behavior analysis. This is especially important in certain applications, such as psychotherapy, where individualized tracking of behavior patterns can provide valuable information about the patient’s mental state. Conventional methods that rely on aggregate statistics and correlational metrics may not always suffice, as they are often unable to capture causal relationships or evaluate the true probability of identified patterns. To address these challenges, we present a novel approach to learning multimodal and interpersonal representations of behavior dynamics during one-on-one interaction. Our approach is enabled by the introduction of a multiview extension of latent change score models, which facilitates the concurrent capture of both inter-modal and interpersonal behavior dynamics and the identification of directional relationships between them. A core advantage of our approach is its high level of interpretability while simultaneously achieving strong predictive performance. We evaluate our approach within the domain of therapist-client interactions, with the objective of gaining a deeper understanding about the collaborative relationship between the two, a crucial element of the therapeutic process. Our results demonstrate improved performance over conventional approaches that rely upon summary statistics or correlational metrics. Furthermore, since our multiview approach includes the explicit modeling of uncertainty, it naturally lends itself to integration with probabilistic classifiers, such as Gaussian process models. We demonstrate that this integration leads to even further improved performance, all the while maintaining highly interpretable qualities. Our analysis provides compelling motivation for further exploration of stochastic systems within computational models of behavior.
isOpenAccess: True
TL\DR: A comparative study of how humans annotate two categorizations of multimodal interactions is performed and a method to automatically convert annotations of partial and counterfactual labels to information decomposition is proposed, yielding an accurate and efficient method for quantifying multimodals interactions.
================================
faculty_name: Louis-Philippe Morency
faculty_authorid: 49933077
paper_id: d01cc51c0d06583b809833a5f7ce71101d278528
paper_title: MultiViz: Towards User-Centric Visualizations and Interpretations of Multimodal Models
publication_link: Not given 
year_published: 2023 
abstract_paper:The nature of human and computer interactions are inherently multimodal, which has led to substantial interest in building interpretable, interactive, and reliable multimodal interfaces. However, modern multimodal models and interfaces are typically black-box neural networks, which makes it challenging to understand their internal mechanics. How can we visualize their internal workings in order to empower stakeholders to visualize model behavior, perform model debugging, and promote trust in these models? Our paper proposes MultiViz, a method for analyzing the behavior of multimodal models via 4 stages: (1) unimodal importance, (2) cross-modal interactions, (3) multimodal representations and (4) multimodal prediction. MultiViz includes modular visualization tools for each stage before combining outputs from all stages through an interactive and human-in-the-loop API. Through user studies with 21 participants on 8 trained models across 6 real-world tasks, we show that the complementary stages in MultiViz together enable users to (1) simulate model predictions, (2) assign interpretable concepts to features, (3) perform error analysis on model misclassifications, and (4) use insights from error analysis to debug models. MultiViz is publicly available at https://github.com/pliang279/MultiViz, will be regularly updated with new visualization tools and metrics, and welcomes input from the community1.
isOpenAccess: True
TL\DR: A comparative study of how humans annotate two categorizations of multimodal interactions is performed and a method to automatically convert annotations of partial and counterfactual labels to information decomposition is proposed, yielding an accurate and efficient method for quantifying multimodals interactions.
================================
faculty_name: Louis-Philippe Morency
faculty_authorid: 49933077
paper_id: dcb4f2b9b0e6da0d629878d1ad0469aee3df2020
paper_title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
publication_link: https://arxiv.org/pdf/2306.04898 
year_published: 2023 
abstract_paper:Masked autoencoder (MAE), a simple and effective self-supervised learning framework based on the reconstruction of masked image regions, has recently achieved prominent success in a variety of vision tasks. Despite the emergence of intriguing empirical observations on MAE, a theoretically principled understanding is still lacking. In this work, we formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE. We formulate the underlying data-generating process as a hierarchical latent variable model, and show that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model, explaining why MAE can extract high-level information from pixels. Further, we show how key hyperparameters in MAE (the masking ratio and the patch size) determine which true latent variables to be recovered, therefore influencing the level of semantic information in the representation. Specifically, extremely large or small masking ratios inevitably lead to low-level representations. Our theory offers coherent explanations of existing empirical observations and provides insights for potential empirical improvements and fundamental limitations of the masked-reconstruction paradigm. We conduct extensive experiments to validate our theoretical insights.
isOpenAccess: True
TL\DR: A comparative study of how humans annotate two categorizations of multimodal interactions is performed and a method to automatically convert annotations of partial and counterfactual labels to information decomposition is proposed, yielding an accurate and efficient method for quantifying multimodals interactions.
================================
faculty_name: Louis-Philippe Morency
faculty_authorid: 49933077
paper_id: e1b2a35a000ca296c32284b323c7e36a28fe0693
paper_title: Factorized Contrastive Learning: Going Beyond Multi-view Redundancy
publication_link: http://arxiv.org/pdf/2306.05268 
year_published: 2023 
abstract_paper:In a wide range of multimodal tasks, contrastive learning has become a particularly appealing approach since it can successfully learn representations from abundant unlabeled data with only pairing information (e.g., image-caption or video-audio pairs). Underpinning these approaches is the assumption of multi-view redundancy - that shared information between modalities is necessary and sufficient for downstream tasks. However, in many real-world settings, task-relevant information is also contained in modality-unique regions: information that is only present in one modality but still relevant to the task. How can we learn self-supervised multimodal representations to capture both shared and unique information relevant to downstream tasks? This paper proposes FactorCL, a new multimodal representation learning method to go beyond multi-view redundancy. FactorCL is built from three new contributions: (1) factorizing task-relevant information into shared and unique representations, (2) capturing task-relevant information via maximizing MI lower bounds and removing task-irrelevant information via minimizing MI upper bounds, and (3) multimodal data augmentations to approximate task relevance without labels. On large-scale real-world datasets, FactorCL captures both shared and unique information and achieves state-of-the-art results on six benchmarks
isOpenAccess: True
TL\DR: A comparative study of how humans annotate two categorizations of multimodal interactions is performed and a method to automatically convert annotations of partial and counterfactual labels to information decomposition is proposed, yielding an accurate and efficient method for quantifying multimodals interactions.
================================
faculty_name: Louis-Philippe Morency
faculty_authorid: 49933077
paper_id: f891e9eeedbf20cdc54429ffcc0402a10f48494e
paper_title: Language Models Get a Gender Makeover: Mitigating Gender Bias with Few-Shot Data Interventions
publication_link: http://arxiv.org/pdf/2306.04597 
year_published: 2023 
abstract_paper:Societal biases present in pre-trained large language models are a critical issue as these models have been shown to propagate biases in countless downstream applications, rendering them unfair towards specific groups of people. Since large-scale retraining of these models from scratch is both time and compute-expensive, a variety of approaches have been previously proposed that de-bias a pre-trained model. While the majority of current state-of-the-art debiasing methods focus on changes to the training regime, in this paper, we propose data intervention strategies as a powerful yet simple technique to reduce gender bias in pre-trained models. Specifically, we empirically show that by fine-tuning a pre-trained model on only 10 debiased (intervened) training examples, the tendency to favor any gender is significantly reduced. Since our proposed method only needs a few training examples, we argue that our few-shot de-biasing approach is highly feasible and practical. Through extensive experimentation, we show that our de-biasing technique performs better than competitive state-of-the-art baselines with minimal loss in language modeling ability.
isOpenAccess: True
TL\DR: A comparative study of how humans annotate two categorizations of multimodal interactions is performed and a method to automatically convert annotations of partial and counterfactual labels to information decomposition is proposed, yielding an accurate and efficient method for quantifying multimodals interactions.
================================
faculty_name: David Mortensen
faculty_authorid: 3407646
paper_id: 11a571eaab42a6ffb1d938635a093315e392756d
paper_title: ChatGPT MT: Competitive for High- (but Not Low-) Resource Languages
publication_link: https://arxiv.org/pdf/2309.07423 
year_published: 2023 
abstract_paper:Large language models (LLMs) implicitly learn to perform a range of language tasks, including machine translation (MT). Previous studies explore aspects of LLMs’ MT capabilities. However, there exist a wide variety of languages for which recent LLM MT performance has never before been evaluated. Without published experimental evidence on the matter, it is difficult for speakers of the world’s diverse languages to know how and whether they can use LLMs for their languages. We present the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark. Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered. Our analysis reveals that a language’s resource level is the most important feature in determining ChatGPT’s relative ability to translate it, and suggests that ChatGPT is especially disadvantaged for LRLs and African languages.
isOpenAccess: True
TL\DR: This work presents the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark, and reveals that a language’s resource level is the most important feature in determining ChatGPT's relative ability to translate it, and suggests thatChatGPT is especially disadvantaged for LRLs and African languages.
================================
faculty_name: David Mortensen
faculty_authorid: 3407646
paper_id: 17fbffb05fa14e21d1c506fd5f0f568b955fe983
paper_title: Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models
publication_link: http://arxiv.org/pdf/2305.13707 
year_published: 2023 
abstract_paper:Language models have graduated from being research prototypes to commercialized products offered as web APIs, and recent works have highlighted the multilingual capabilities of these products. The API vendors charge their users based on usage, more specifically on the number of ``tokens'' processed or generated by the underlying language models. What constitutes a token, however, is training data and model dependent with a large variance in the number of tokens required to convey the same information in different languages. In this work, we analyze the effect of this non-uniformity on the fairness of an API's pricing policy across languages. We conduct a systematic analysis of the cost and utility of OpenAI's language model API on multilingual benchmarks in 22 typologically diverse languages. We show evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results. These speakers tend to also come from regions where the APIs are less affordable to begin with. Through these analyses, we aim to increase transparency around language model APIs' pricing policies and encourage the vendors to make them more equitable.
isOpenAccess: True
TL\DR: This work presents the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark, and reveals that a language’s resource level is the most important feature in determining ChatGPT's relative ability to translate it, and suggests thatChatGPT is especially disadvantaged for LRLs and African languages.
================================
faculty_name: David Mortensen
faculty_authorid: 3407646
paper_id: 659be1ff350634f50cc066d258ee6a45e697e552
paper_title: SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing
publication_link: https://aclanthology.org/2023.sigmorphon-1.22.pdf 
year_published: 2023 
abstract_paper:In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.
isOpenAccess: True
TL\DR: In this submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), approaches to data augmentation and modeling across seven low-resource languages are explored and token classification models are found to be the best performing.
================================
faculty_name: David Mortensen
faculty_authorid: 3407646
paper_id: 7a08051aac75a809737096e39820bf836908d4e1
paper_title: Construction Grammar Provides Unique Insight into Neural Language Models
publication_link: http://arxiv.org/pdf/2302.02178 
year_published: 2023 
abstract_paper:Construction Grammar (CxG) has recently been used as the basis for probing studies that have investigated the performance of large pretrained language models (PLMs) with respect to the structure and meaning of constructions. In this position paper, we make suggestions for the continuation and augmentation of this line of research. We look at probing methodology that was not designed with CxG in mind, as well as probing methodology that was designed for specific constructions. We analyse selected previous work in detail, and provide our view of the most important challenges and research questions that this promising new field faces.
isOpenAccess: True
TL\DR: In this submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), approaches to data augmentation and modeling across seven low-resource languages are explored and token classification models are found to be the best performing.
================================
faculty_name: David Mortensen
faculty_authorid: 3407646
paper_id: bf42c0462d1415cdde877c90d58da11545407b8a
paper_title: Generalized Glossing Guidelines: An Explicit, Human- and Machine-Readable, Item-and-Process Convention for Morphological Annotation
publication_link: https://aclanthology.org/2023.sigmorphon-1.7.pdf 
year_published: 2023 
abstract_paper:Interlinear glossing provides a vital type of morphosyntactic annotation, both for linguists and language revitalists, and numerous conventions exist for representing it formally and computationally. Some of these formats are human readable; others are machine readable. Some are easy to edit with general-purpose tools. Few represent non-concatentative processes like infixation, reduplication, mutation, truncation, and tonal overwriting in a consistent and formally rigorous way (on par with affixation). We propose an annotation conventionâ€”Generalized Glossing Guidelines (GGG) that combines all of these positive properties using an Item-and-Process (IP) framework. We describe the format, demonstrate its linguistic adequacy, and compare it with two other interlinear glossed text annotation schemes.
isOpenAccess: True
TL\DR: In this submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), approaches to data augmentation and modeling across seven low-resource languages are explored and token classification models are found to be the best performing.
================================
faculty_name: David Mortensen
faculty_authorid: 3407646
paper_id: c5c6d006e399386c99068daba138021a62d6cc17
paper_title: Transformed Protoform Reconstruction
publication_link: https://arxiv.org/pdf/2307.01896 
year_published: 2023 
abstract_paper:Protoform reconstruction is the task of inferring what morphemes or words appeared like in the ancestral languages of a set of daughter languages. Meloni et al (2021) achieved the state-of-the-art on Latin protoform reconstruction with an RNN-based encoder-decoder with attention model. We update their model with the state-of-the-art seq2seq model: the Transformer. Our model outperforms their model on a suite of different metrics on two different datasets: their Romance data of 8,000 cognates spanning 5 languages and a Chinese dataset (Hou 2004) of 800+ cognates spanning 39 varieties. We also probe our model for potential phylogenetic signal contained in the model. Our code is publicly available at https://github.com/cmu-llab/acl-2023.
isOpenAccess: True
TL\DR: The Meloni et al (2021) model is updated with the state-of-the-art seq2seq model: the Transformer, which outperforms their model on a suite of different metrics on two different datasets: their Romance data of 8,000 cognate spanning 5 languages and a Chinese dataset (Hou 2004) of 800+ cognates spanning 39 varieties.
================================
faculty_name: David Mortensen
faculty_authorid: 3407646
paper_id: db14d05b18ec852f8afcd6d2d10bbd9eeaef8325
paper_title: PWESuite: Phonetic Word Embeddings and Tasks They Facilitate
publication_link: http://arxiv.org/pdf/2304.02541 
year_published: 2023 
abstract_paper:Mapping words into a fixed-dimensional vector space is the backbone of modern NLP. While most word embedding methods successfully encode semantic information, they overlook phonetic information that is crucial for many tasks. We develop three methods that use articulatory features to build phonetically informed word embeddings. To address the inconsistent evaluation of existing phonetic word embedding methods, we also contribute a task suite to fairly evaluate past, current, and future methods. We evaluate both (1) intrinsic aspects of phonetic word embeddings, such as word retrieval and correlation with sound similarity, and (2) extrinsic performance on tasks such as rhyme and cognate detection and sound analogies. We hope our task suite will promote reproducibility and inspire future phonetic embedding research.
isOpenAccess: True
TL\DR: Three methods that use articulatory features to build phonetically informed word embeddings are developed that address the inconsistent evaluation of existing phonetic word embedding methods and contribute a task suite to fairly evaluate past, current, and future methods.
================================
faculty_name: David Mortensen
faculty_authorid: 2280090550
paper_id: 1d343a435c8b27b986cbeac1708e2b76abf2f9bc
paper_title: Kuki-Chin Phonology: An Overview
publication_link: https://escholarship.org/content/qt1d326124/qt1d326124.pdf?t=s7jt1o 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: 03c7f61b0c6bc4c480ed6da4e9d7dda104ddfec3
paper_title: Cross-Modal Fine-Tuning: Align then Refine
publication_link: http://arxiv.org/pdf/2302.05738 
year_published: 2023 
abstract_paper:Fine-tuning large-scale pretrained models has led to tremendous progress in well-studied modalities such as vision and NLP. However, similar gains have not been observed in many other modalities due to a lack of relevant pretrained models. In this work, we propose ORCA, a general cross-modal fine-tuning framework that extends the applicability of a single large-scale pretrained model to diverse modalities. ORCA adapts to a target task via an align-then-refine workflow: given the target input, ORCA first learns an embedding network that aligns the embedded feature distribution with the pretraining modality. The pretrained model is then fine-tuned on the embedded data to exploit the knowledge shared across modalities. Through extensive experiments, we show that ORCA obtains state-of-the-art results on 3 benchmarks containing over 60 datasets from 12 modalities, outperforming a wide range of hand-designed, AutoML, general-purpose, and task-specific methods. We highlight the importance of data alignment via a series of ablation studies and demonstrate ORCA's utility in data-limited regimes.
isOpenAccess: True
TL\DR: This work proposes ORCA, a general cross-modal fine-tuning framework that extends the applicability of a single large-scale pretrained model to diverse modalities and highlights the importance of data alignment via a series of ablation studies and demonstrates ORCA's utility in data-limited regimes.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: 11a571eaab42a6ffb1d938635a093315e392756d
paper_title: ChatGPT MT: Competitive for High- (but Not Low-) Resource Languages
publication_link: https://arxiv.org/pdf/2309.07423 
year_published: 2023 
abstract_paper:Large language models (LLMs) implicitly learn to perform a range of language tasks, including machine translation (MT). Previous studies explore aspects of LLMs’ MT capabilities. However, there exist a wide variety of languages for which recent LLM MT performance has never before been evaluated. Without published experimental evidence on the matter, it is difficult for speakers of the world’s diverse languages to know how and whether they can use LLMs for their languages. We present the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark. Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered. Our analysis reveals that a language’s resource level is the most important feature in determining ChatGPT’s relative ability to translate it, and suggests that ChatGPT is especially disadvantaged for LRLs and African languages.
isOpenAccess: True
TL\DR: This work presents the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark, and reveals that a language’s resource level is the most important feature in determining ChatGPT's relative ability to translate it, and suggests thatChatGPT is especially disadvantaged for LRLs and African languages.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: 17605c43ca3eb982c99642052ddc21a93d116594
paper_title: GlobalBench: A Benchmark for Global Progress in Natural Language Processing
publication_link: http://arxiv.org/pdf/2305.14716 
year_published: 2023 
abstract_paper:Despite the major advances in NLP, significant disparities in NLP system performance across languages still exist. Arguably, these are due to uneven resource allocation and sub-optimal incentives to work on less resourced languages. To track and further incentivize the global development of equitable language technology, we introduce GlobalBench. Prior multilingual benchmarks are static and have focused on a limited number of tasks and languages. In contrast, GlobalBench is an ever-expanding collection that aims to dynamically track progress on all NLP datasets in all languages. Rather than solely measuring accuracy, GlobalBench also tracks the estimated per-speaker utility and equity of technology across all languages, providing a multi-faceted view of how language technology is serving people of the world. Furthermore, GlobalBench is designed to identify the most under-served languages, and rewards research efforts directed towards those languages. At present, the most under-served languages are the ones with a relatively high population, but nonetheless overlooked by composite multilingual benchmarks (like Punjabi, Portuguese, and Wu Chinese). Currently, GlobalBench covers 966 datasets in 190 languages, and has 1,128 system submissions spanning 62 languages.
isOpenAccess: True
TL\DR: This work introduces GlobalBench, an ever-expanding collection that aims to dynamically track progress on all NLP datasets in all languages and tracks the estimated per-speaker utility and equity of technology across all languages, providing a multi-faceted view of how language technology is serving people of the world.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: 1786a2f9140ed7211b21302977de64e948b92308
paper_title: Learning Performance-Improving Code Edits
publication_link: http://arxiv.org/pdf/2302.07867 
year_published: 2023 
abstract_paper:The waning of Moore's Law has shifted the focus of the tech industry towards alternative methods for continued performance gains. While optimizing compilers are a standard tool to help increase program efficiency, programmers continue to shoulder much responsibility in crafting and refactoring code with better performance characteristics. In this paper, we investigate the ability of large language models (LLMs) to suggest functionally correct, performance improving code edits. We hypothesize that language models can suggest such edits in ways that would be impractical for static analysis alone. We investigate these questions by curating a large-scale dataset of Performance-Improving Edits, PIE. PIE contains trajectories of programs, where a programmer begins with an initial, slower version and iteratively makes changes to improve the program's performance. We use PIE to evaluate and improve the capacity of large language models. Specifically, use examples from PIE to fine-tune multiple variants of CODEGEN, a billion-scale Transformer-decoder model. Additionally, we use examples from PIE to prompt OpenAI's CODEX using a few-shot prompting. By leveraging PIE, we find that both CODEX and CODEGEN can generate performance-improving edits, with speedups of more than 2.5x for over 25% of the programs, for C++ and Python, even after the C++ programs were compiled using the O3 optimization level. Crucially, we show that PIE allows CODEGEN, an open-sourced and 10x smaller model than CODEX, to match the performance of CODEX on this challenging task. Overall, this work opens new doors for creating systems and methods that can help programmers write efficient code.
isOpenAccess: True
TL\DR: This paper investigates the ability of large language models (LLMs) to suggest functionally correct, performance improving code edits, and hypothesizes that language models can suggest such edits in ways that would be impractical for static analysis alone.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: 31366ff634fc905affd78dbd8ddc9a872c006a87
paper_title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
publication_link: http://arxiv.org/pdf/2302.05527 
year_published: 2023 
abstract_paper:Since the rise of neural natural-language-to-code models (NL->Code) that can generate long expressions and statements rather than a single next-token, one of the major problems has been reliably evaluating their generated output. In this paper, we propose CodeBERTScore: an evaluation metric for code generation, which builds on BERTScore (Zhang et al., 2020). Instead of encoding only the generated tokens as in BERTScore, CodeBERTScore also encodes the natural language input preceding the generated code, thus modeling the consistency between the generated code and its given natural language context as well. We perform an extensive evaluation of CodeBERTScore across four programming languages. We find that CodeBERTScore achieves a higher correlation with human preference and with functional correctness than all existing metrics. That is, generated code that receives a higher score by CodeBERTScore is more likely to be preferred by humans, as well as to function correctly when executed. We release five language-specific pretrained models to use with our publicly available code. Our language-specific models have been downloaded more than 1,000,000 times from the Huggingface Hub. Our code and data are available at https://github.com/neulab/code-bert-score
isOpenAccess: True
TL\DR: It is found that generated code that receives a higher score by CodeBERTScore is more likely to be preferred by humans, as well as to function correctly when executed, than all existing metrics.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: 405f1a5602867c66e015491c26d2be5504eed458
paper_title: Neural Machine Translation for the Indigenous Languages of the Americas: An Introduction
publication_link: http://arxiv.org/pdf/2306.06804 
year_published: 2023 
abstract_paper:Neural models have drastically advanced state of the art for machine translation (MT) between high-resource languages. Traditionally, these models rely on large amounts of training data, but many language pairs lack these resources. However, an important part of the languages in the world do not have this amount of data. Most languages from the Americas are among them, having a limited amount of parallel and monolingual data, if any. Here, we present an introduction to the interested reader to the basic challenges, concepts, and techniques that involve the creation of MT systems for these languages. Finally, we discuss the recent advances and findings and open questions, product of an increased interest of the NLP community in these languages.
isOpenAccess: True
TL\DR: An introduction to the interested reader to the basic challenges, concepts, and techniques that involve the creation of MT systems for high- resource languages between high-resource languages.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: 43c0f77f116f986b53eb04f5c9b33f10132ded55
paper_title: User-Centric Evaluation of OCR Systems for Kwak’wala
publication_link: http://arxiv.org/pdf/2302.13410 
year_published: 2023 
abstract_paper:There has been recent interest in improving optical character recognition (OCR) for endangered languages, particularly because a large number of documents and books in these languages are not in machine-readable formats. The performance of OCR systems is typically evaluated using automatic metrics such as character and word error rates. While error rates are useful for the comparison of different models and systems, they do not measure whether and how the transcriptions produced from OCR tools are useful to downstream users. In this paper, we present a human-centric evaluation of OCR systems, focusing on the Kwak'wala language as a case study. With a user study, we show that utilizing OCR reduces the time spent in the manual transcription of culturally valuable documents -- a task that is often undertaken by endangered language community members and researchers -- by over 50%. Our results demonstrate the potential benefits that OCR tools can have on downstream language documentation and revitalization efforts.
isOpenAccess: True
TL\DR: This paper presents a human-centric evaluation of OCR systems, focusing on the Kwak'wala language as a case study, and shows that utilizing OCR reduces the time spent in the manual transcription of culturally valuable documents by over 50%.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: 4d74a5048b884e8bb3842240abf98915c619c8f8
paper_title: Multi-Dimensional Evaluation of Text Summarization with In-Context Learning
publication_link: https://aclanthology.org/2023.findings-acl.537.pdf 
year_published: 2023 
abstract_paper:Evaluation of natural language generation (NLG) is complex and multi-dimensional. Generated text can be evaluated for fluency, coherence, factuality, or any other dimensions of interest. Most frameworks that perform such multi-dimensional evaluation require training on large manually or synthetically generated datasets. In this paper, we study the efficacy of large language models as multi-dimensional evaluators using in-context learning, obviating the need for large training datasets. Our experiments show that in-context learning-based evaluators are competitive with learned evaluation frameworks for the task of text summarization, establishing state-of-the-art on dimensions such as relevance and factual consistency. We then analyze the effects of factors such as the selection and number of in-context examples on performance. Finally, we study the efficacy of in-context learning based evaluators in evaluating zero-shot summaries written by large language models such as GPT-3.
isOpenAccess: True
TL\DR: This paper presents a human-centric evaluation of OCR systems, focusing on the Kwak'wala language as a case study, and shows that utilizing OCR reduces the time spent in the manual transcription of culturally valuable documents by over 50%.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: 5ea8eedcb31859c5730dd1da3804e1be529ffabb
paper_title: A Gold Standard Dataset for the Reviewer Assignment Problem
publication_link: http://arxiv.org/pdf/2303.16750 
year_published: 2023 
abstract_paper:Many peer-review venues are either using or looking to use algorithms to assign submissions to reviewers. The crux of such automated approaches is the notion of the"similarity score"--a numerical estimate of the expertise of a reviewer in reviewing a paper--and many algorithms have been proposed to compute these scores. However, these algorithms have not been subjected to a principled comparison, making it difficult for stakeholders to choose the algorithm in an evidence-based manner. The key challenge in comparing existing algorithms and developing better algorithms is the lack of the publicly available gold-standard data that would be needed to perform reproducible research. We address this challenge by collecting a novel dataset of similarity scores that we release to the research community. Our dataset consists of 477 self-reported expertise scores provided by 58 researchers who evaluated their expertise in reviewing papers they have read previously. We use this data to compare several popular algorithms employed in computer science conferences and come up with recommendations for stakeholders. Our main findings are as follows. First, all algorithms make a non-trivial amount of error. For the task of ordering two papers in terms of their relevance for a reviewer, the error rates range from 12%-30% in easy cases to 36%-43% in hard cases, highlighting the vital need for more research on the similarity-computation problem. Second, most existing algorithms are designed to work with titles and abstracts of papers, and in this regime the Specter+MFR algorithm performs best. Third, to improve performance, it may be important to develop modern deep-learning based algorithms that can make use of the full texts of papers: the classical TD-IDF algorithm enhanced with full texts of papers is on par with the deep-learning based Specter+MFR that cannot make use of this information.
isOpenAccess: True
TL\DR: A novel dataset of similarity scores provided by 58 researchers who evaluated their expertise in reviewing papers they have read previously is collected and used to compare several popular algorithms employed in computer science conferences and come up with recommendations for stakeholders.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: 659be1ff350634f50cc066d258ee6a45e697e552
paper_title: SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing
publication_link: https://aclanthology.org/2023.sigmorphon-1.22.pdf 
year_published: 2023 
abstract_paper:In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.
isOpenAccess: True
TL\DR: In this submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), approaches to data augmentation and modeling across seven low-resource languages are explored and token classification models are found to be the best performing.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: 74b05bba46db21e589a2cc0f916f81069b0368ef
paper_title: Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation
publication_link: http://arxiv.org/pdf/2305.00955 
year_published: 2023 
abstract_paper:Many recent advances in natural language generation have been fueled by training large language models on internet-scale data. However, this paradigm can lead to models that generate toxic, inaccurate, and unhelpful content, and automatic evaluation metrics often fail to identify these behaviors. As models become more capable, human feedback is an invaluable signal for evaluating and improving models. This survey aims to provide an overview of the recent research that has leveraged human feedback to improve natural language generation. First, we introduce an encompassing formalization of feedback, and identify and organize existing research into a taxonomy following this formalization. Next, we discuss how feedback can be described by its format and objective, and cover the two approaches proposed to use feedback (either for training or decoding): directly using the feedback or training feedback models. We also discuss existing datasets for human-feedback data collection, and concerns surrounding feedback collection. Finally, we provide an overview of the nascent field of AI feedback, which exploits large language models to make judgments based on a set of principles and minimize the need for human intervention.
isOpenAccess: True
TL\DR: In this submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), approaches to data augmentation and modeling across seven low-resource languages are explored and token classification models are found to be the best performing.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: 7a5b44ea10a51708e18786595c8d70b18950da11
paper_title: FacTool: Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios
publication_link: https://arxiv.org/pdf/2307.13528 
year_published: 2023 
abstract_paper:The emergence of generative pre-trained models has facilitated the synthesis of high-quality text, but it has also posed challenges in identifying factual errors in the generated text. In particular: (1) A wider range of tasks now face an increasing risk of containing factual errors when handled by generative models. (2) Generated texts tend to be lengthy and lack a clearly defined granularity for individual facts. (3) There is a scarcity of explicit evidence available during the process of fact checking. With the above challenges in mind, in this paper, we propose FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT). Experiments on four different tasks (knowledge-based QA, code generation, mathematical reasoning, and scientific literature review) show the efficacy of the proposed method. We release the code of FacTool associated with ChatGPT plugin interface at https://github.com/GAIR-NLP/factool .
isOpenAccess: True
TL\DR: In this submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), approaches to data augmentation and modeling across seven low-resource languages are explored and token classification models are found to be the best performing.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: 88884b8806262a4095036041e3567d450dba39f7
paper_title: Active Retrieval Augmented Generation
publication_link: http://arxiv.org/pdf/2305.06983 
year_published: 2023 
abstract_paper:Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. Code and datasets are available at https://github.com/jzbjyb/FLARE.
isOpenAccess: True
TL\DR: This work proposes Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: 8e8a1489bf4d782d2435cdeb93f7d1f165747c63
paper_title: Large Language Models Enable Few-Shot Clustering
publication_link: http://arxiv.org/pdf/2307.00524 
year_published: 2023 
abstract_paper:Unlike traditional unsupervised clustering, semi-supervised clustering allows users to provide meaningful structure to the data, which helps the clustering algorithm to match the user's intent. Existing approaches to semi-supervised clustering require a significant amount of feedback from an expert to improve the clusters. In this paper, we ask whether a large language model can amplify an expert's guidance to enable query-efficient, few-shot semi-supervised text clustering. We show that LLMs are surprisingly effective at improving clustering. We explore three stages where LLMs can be incorporated into clustering: before clustering (improving input features), during clustering (by providing constraints to the clusterer), and after clustering (using LLMs post-correction). We find incorporating LLMs in the first two stages can routinely provide significant improvements in cluster quality, and that LLMs enable a user to make trade-offs between cost and accuracy to produce desired clusters. We release our code and LLM prompts for the public to use.
isOpenAccess: True
TL\DR: It is found that incorporating LLMs in the first two stages can routinely provide significant improvements in cluster quality, and that LLMs enable a user to make trade-offs between cost and accuracy to produce desired clusters.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: 9bce3661f01825ad56dc9d2b3d254fd9e3792360
paper_title: Solving NLP Problems through Human-System Collaboration: A Discussion-based Approach
publication_link: http://arxiv.org/pdf/2305.11789 
year_published: 2023 
abstract_paper:Humans work together to solve common problems by having discussions, explaining, and agreeing or disagreeing with each other. Similarly, if a system can have discussions with humans when solving tasks, it can improve the system's performance and reliability. In previous research on explainability, it has only been possible for the system to make predictions and for humans to ask questions about them rather than having a mutual exchange of opinions. This research aims to create a dataset and computational framework for systems that discuss and refine their predictions through dialogue. Through experiments, we show that the proposed system can have beneficial discussions with humans improving the accuracy by up to 25 points in the natural language inference task.
isOpenAccess: True
TL\DR: This research aims to create a dataset and computational framework for systems that discuss and refine their predictions through dialogue and shows that the proposed system can have beneficial discussions with humans improving the accuracy by up to 25 points in the natural language inference task.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: b4987da792dd45a84232cfb06d71b1c2ec488f38
paper_title: Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting
publication_link: https://arxiv.org/pdf/2310.07081 
year_published: 2023 
abstract_paper:Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the meanings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic translation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based machine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of ~4k natural sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences.
isOpenAccess: True
TL\DR: To improve translation of natural idioms, this work introduces two straightforward yet effective techniques: the strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: c432aff446d55e72a28394a1508e760cc9a25c08
paper_title: Why do Nearest Neighbor Language Models Work?
publication_link: http://arxiv.org/pdf/2301.02828 
year_published: 2023 
abstract_paper:Language models (LMs) compute the probability of a text by sequentially computing a representation of an already-seen context and using this representation to predict the next word. Currently, most LMs calculate these representations through a neural network consuming the immediate previous context. However recently, retrieval-augmented LMs have shown to improve over standard neural LMs, by accessing information retrieved from a large datastore, in addition to their standard, parametric, next-word prediction. In this paper, we set out to understand why retrieval-augmented language models, and specifically why k-nearest neighbor language models (kNN-LMs) perform better than standard parametric LMs, even when the k-nearest neighbor component retrieves examples from the same training set that the LM was originally trained on. To this end, we perform a careful analysis of the various dimensions over which kNN-LM diverges from standard LMs, and investigate these dimensions one by one. Empirically, we identify three main reasons why kNN-LM performs better than standard LMs: using a different input representation for predicting the next tokens, approximate kNN search, and the importance of softmax temperature for the kNN distribution. Further, we incorporate these insights into the model architecture or the training procedure of the standard parametric LM, improving its results without the need for an explicit retrieval component. The code is available at https://github.com/frankxu2004/knnlm-why.
isOpenAccess: True
TL\DR: This paper identifies three main reasons why k-nearest neighbor language models (kNN-LM) perform better than standard LMs: using a different input representation for predicting the next tokens, approximate kNN search, and the importance of softmax temperature for the kNN distribution.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: c5207241406586f4263b235667e004b71ea68953
paper_title: Syntax and Semantics Meet in the “Middle”: Probing the Syntax-Semantics Interface of LMs Through Agentivity
publication_link: https://arxiv.org/pdf/2305.18185 
year_published: 2023 
abstract_paper:Recent advances in large language models have prompted researchers to examine their abilities across a variety of linguistic tasks, but little has been done to investigate how models handle the interactions in meaning across words and larger syntactic forms—i.e. phenomena at the intersection of syntax and semantics. We present the semantic notion of agentivity as a case study for probing such interactions. We created a novel evaluation dataset by utilitizing the unique linguistic properties of a subset of optionally transitive English verbs. This dataset was used to prompt varying sizes of three model classes to see if they are sensitive to agentivity at the lexical level, and if they can appropriately employ these word-level priors given a specific syntactic context. Overall, GPT-3 text-davinci-003 performs extremely well across all experiments, outperforming all other models tested by far. In fact, the results are even better correlated with human judgements than both syntactic and semantic corpus statistics. This suggests that LMs may potentially serve as more useful tools for linguistic annotation, theory testing, and discovery than select corpora for certain tasks.
isOpenAccess: True
TL\DR: This paper identifies three main reasons why k-nearest neighbor language models (kNN-LM) perform better than standard LMs: using a different input representation for predicting the next tokens, approximate kNN search, and the importance of softmax temperature for the kNN distribution.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: cc1705fe421c70d85254b557634bd4669fdd49b0
paper_title: DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions
publication_link: http://arxiv.org/pdf/2305.16636 
year_published: 2023 
abstract_paper:Modern machine learning relies on datasets to develop and validate research ideas. Given the growth of publicly available data, finding the right dataset to use is increasingly difficult. Any research question imposes explicit and implicit constraints on how well a given dataset will enable researchers to answer this question, such as dataset size, modality, and domain. We operationalize the task of recommending datasets given a short natural language description of a research idea, to help people find relevant datasets for their needs. Dataset recommendation poses unique challenges as an information retrieval problem; datasets are hard to directly index for search and there are no corpora readily available for this task. To facilitate this task, we build the DataFinder Dataset which consists of a larger automatically-constructed training set (17.5K queries) and a smaller expert-annotated evaluation set (392 queries). Using this data, we compare various information retrieval algorithms on our test set and present a superior bi-encoder retriever for text-based dataset recommendation. This system, trained on the DataFinder Dataset, finds more relevant search results than existing third-party dataset search engines. To encourage progress on dataset recommendation, we release our dataset and models to the public.
isOpenAccess: True
TL\DR: This paper identifies three main reasons why k-nearest neighbor language models (kNN-LM) perform better than standard LMs: using a different input representation for predicting the next tokens, approximate kNN search, and the importance of softmax temperature for the kNN distribution.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: d5dd7230cccace7e77095d3b5fd8394850f59170
paper_title: Multi-lingual and Multi-cultural Figurative Language Understanding
publication_link: http://arxiv.org/pdf/2305.16171 
year_published: 2023 
abstract_paper:Figurative language permeates human communication, but at the same time is relatively understudied in NLP. Datasets have been created in English to accelerate progress towards measuring and improving figurative language processing in language models (LMs). However, the use of figurative language is an expression of our cultural and societal experiences, making it difficult for these phrases to be universally applicable. In this work, we create a figurative language inference dataset, \datasetname, for seven diverse languages associated with a variety of cultures: Hindi, Indonesian, Javanese, Kannada, Sundanese, Swahili and Yoruba. Our dataset reveals that each language relies on cultural and regional concepts for figurative expressions, with the highest overlap between languages originating from the same region. We assess multilingual LMs' abilities to interpret figurative language in zero-shot and few-shot settings. All languages exhibit a significant deficiency compared to English, with variations in performance reflecting the availability of pre-training and fine-tuning data, emphasizing the need for LMs to be exposed to a broader range of linguistic and cultural variation during training.
isOpenAccess: True
TL\DR: This paper identifies three main reasons why k-nearest neighbor language models (kNN-LM) perform better than standard LMs: using a different input representation for predicting the next tokens, approximate kNN search, and the importance of softmax temperature for the kNN distribution.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: d6ae4c0679bdceb029f652efd2a854ac5ade772f
paper_title: It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk
publication_link: https://arxiv.org/pdf/2310.01387 
year_published: 2023 
abstract_paper:Minimum Bayes Risk (MBR) decoding is a method for choosing the outputs of a machine learning system based not on the output with the highest probability, but the output with the lowest risk (expected error) among multiple candidates. It is a simple but powerful method: for an additional cost at inference time, MBR provides reliable several-point improvements across metrics for a wide variety of tasks without any additional data or training. Despite this, MBR is not frequently applied in NLP works, and knowledge of the method itself is limited. We first provide an introduction to the method and the recent literature. We show that several recent methods that do not reference MBR can be written as special cases of MBR; this reformulation provides additional theoretical justification for the performance of these methods, explaining some results that were previously only empirical. We provide theoretical and empirical results about the effectiveness of various MBR variants and make concrete recommendations for the application of MBR in NLP models, including future directions in this area.
isOpenAccess: True
TL\DR: It is shown that several recent methods that do not reference MBR can be written as special cases of MBR; this reformulation provides additional theoretical justification for the performance of these methods, explaining some results that were previously only empirical.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: dbc368bc8b49347dd27679894524fa62f88492c9
paper_title: Unlimiformer: Long-Range Transformers with Unlimited Length Input
publication_link: http://arxiv.org/pdf/2305.01625 
year_published: 2023 
abstract_paper:Since the proposal of transformers, these models have been limited to bounded input lengths, because of their need to attend to every token in the input. In this work, we propose Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer retrieves its top-k keys, instead of attending to every key. We evaluate Unlimiformer on several long-document and book-summarization benchmarks, showing that it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without additional learned weights and without modifying their code. We make our code and models publicly available at https://github.com/abertsch72/unlimiformer .
isOpenAccess: True
TL\DR: This work proposes Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: e41482f4ee984f17382f6cdd900df094d928be06
paper_title: WebArena: A Realistic Web Environment for Building Autonomous Agents
publication_link: https://arxiv.org/pdf/2307.13854 
year_published: 2023 
abstract_paper:With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41%, significantly lower than the human performance of 78.24%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.
isOpenAccess: True
TL\DR: This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: e69684fb06a7b1fe621d7ef0c97fc2ca0e122c43
paper_title: Prompt2Model: Generating Deployable Models from Natural Language Instructions
publication_link: https://arxiv.org/pdf/2308.12261 
year_published: 2023 
abstract_paper:Large language models (LLMs) enable system builders today to create competent NLP systems through prompting, where they only need to describe the task in natural language and provide a few examples. However, in other ways, LLMs are a step backward from traditional special-purpose NLP models; they require extensive computational resources for deployment and can be gated behind APIs. In this paper, we propose Prompt2Model, a general-purpose method that takes a natural language task description like the prompts provided to LLMs, and uses it to train a special-purpose model that is conducive to deployment. This is done through a multi-step process of retrieval of existing datasets and pretrained models, dataset generation using LLMs, and supervised fine-tuning on these retrieved and generated datasets. Over three tasks, we demonstrate that given the same few-shot prompt as input, Prompt2Model trains models that outperform the results of a strong LLM, gpt-3.5-turbo, by an average of 20% while being up to 700 times smaller. We also show that this data can be used to obtain reliable performance estimates of model performance, enabling model developers to assess model reliability before deployment. Prompt2Model is available open-source at https://github.com/neulab/prompt2model.
isOpenAccess: True
TL\DR: This paper proposes Prompt2Model, a general-purpose method that takes a natural language task description like the prompts provided to LLMs, and uses it to train a special-purpose model that is conducive to deployment.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: e7b3b692b0816821aafc0d354749bc3802cbf6ac
paper_title: Computational Language Acquisition with Theory of Mind
publication_link: http://arxiv.org/pdf/2303.01502 
year_published: 2023 
abstract_paper:Unlike current state-of-the-art language models, young children actively acquire language through interactions with their surrounding environment and caretakers. One mechanism that has been argued to be critical to language learning is the ability to infer the mental states of other agents in social environments, coined Theory of Mind (ToM) by Premack&Woodruff (1978). Drawing inspiration from the modern operationalized versions of ToM implemented in Rabinowitz et al. (2018) and Zhu et al. (2021), we build language-learning agents equipped with ToM, and measure its effects on the learning process. We model ToM by giving the speaker agent an internal listener model that is trained alongside the speaker and used to rerank potential utterances. We experiment with varying task difficulty, hypothesizing that models will acquire more complex language to adapt to stronger environmental pressures. We find that training speakers with a highly weighted ToM listener component leads to performance gains in our image referential game setting. We also find some evidence that increasing task difficulty in the training process results in more fluent and precise utterances in evaluation. This suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.
isOpenAccess: True
TL\DR: It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: f640e89fcede075b4bde3b2fa0dc78f591589ba3
paper_title: Improving Factuality of Abstractive Summarization via Contrastive Reward Learning
publication_link: https://arxiv.org/pdf/2307.04507 
year_published: 2023 
abstract_paper:Modern abstractive summarization models often generate summaries that contain hallucinated or contradictory information. In this paper, we propose a simple but effective contrastive learning framework that incorporates recent developments in reward learning and factuality metrics. Empirical studies demonstrate that the proposed framework enables summarization models to learn from feedback of factuality metrics using contrastive reward learning, leading to more factual summaries by human evaluations. This suggests that further advances in learning and evaluation algorithms can feed directly into providing more factual summaries. Code and human evaluation results will be publicly available at \url{https://github.com/EthanC111/factuality_summarization}.
isOpenAccess: True
TL\DR: Empirical studies demonstrate that the proposed framework enables summarization models to learn from feedback of factuality metrics using contrastive reward learning, leading to more factual summaries by human evaluations, suggesting that further advances in learning and evaluation algorithms can feed directly into providing morefactuality summaries.
================================
faculty_name: Graham Neubig
faculty_authorid: 1700325
paper_id: fd80f7f3673fc6ca02f192d5d73426f11a4be659
paper_title: The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation
publication_link: https://arxiv.org/pdf/2308.07286 
year_published: 2023 
abstract_paper:Automatic evaluation of machine translation (MT) is a critical tool driving the rapid iterative development of MT systems. While considerable progress has been made on estimating a single scalar quality score, current metrics lack the informativeness of more detailed schemes that annotate individual errors, such as Multidimensional Quality Metrics (MQM). In this paper, we help fill this gap by proposing AutoMQM, a prompting technique which leverages the reasoning and in-context learning capabilities of large language models (LLMs) and asks them to identify and categorize errors in translations. We start by evaluating recent LLMs, such as PaLM and PaLM-2, through simple score prediction prompting, and we study the impact of labeled data through in-context learning and finetuning. We then evaluate AutoMQM with PaLM-2 models, and we find that it improves performance compared to just prompting for scores (with particularly large gains for larger models) while providing interpretability through error spans that align with human annotations.
isOpenAccess: True
TL\DR: This paper proposes AutoMQM, a prompting technique which leverages the reasoning and in-context learning capabilities of large language models (LLMs) and asks them to identify and categorize errors in translations, and finds that it improves performance compared to just prompting for scores.
================================
faculty_name: Eric Nyberg
faculty_authorid: 144287919
paper_id: 0f008e07d601e8f21d1df5db3d36e85484840083
paper_title: GameQA: Gamified Mobile App Platform for Building Multiple-Domain Question-Answering Datasets
publication_link: https://aclanthology.org/2023.eacl-demo.18.pdf 
year_published: 2023 
abstract_paper:The methods used to create many of the well-known Question-Answering (QA) datasets are hard to replicate for low-resource languages. A commonality amongst these methods is hiring annotators to source answers from the internet by querying a single answer source, such as Wikipedia. Applying these methods for low-resource languages can be problematic since there is no single large answer source for these languages. Consequently, this can result in a high ratio of unanswered questions, since the amount of information in any single source is limited. To address this problem, we developed a novel crowd-sourcing platform to gather multiple-domain QA data for low-resource languages. Our platform, which consists of a mobile app and a web API, gamifies the data collection process. We successfully released the app for Icelandic (a low-resource language with about 350,000 native speakers) to build a dataset which rivals large QA datasets for high-resource languages both in terms of size and ratio of answered questions. We have made the platform open source with instructions on how to localize and deploy it to gather data for other low-resource languages.
isOpenAccess: True
TL\DR: This work developed a novel crowd-sourcing platform to gather multiple-domain QA data for low-resource languages and successfully released the app for Icelandic to build a dataset which rivals large QA datasets for high- resource languages both in terms of size and ratio of answered questions.
================================
faculty_name: Eric Nyberg
faculty_authorid: 144287919
paper_id: 3a30217c4115777fb30c182c97cc77d34d065556
paper_title: InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers
publication_link: http://arxiv.org/pdf/2301.02998 
year_published: 2023 
abstract_paper:We carried out a reproducibility study of InPars, which is a method for unsupervised training of neural rankers (Bonifacio et al., 2022). As a by-product, we developed InPars-light, which is a simple-yet-effective modification of InPars. Unlike InPars, InPars-light uses 7x-100x smaller ranking models and only a freely available language model BLOOM, which -- as we found out -- produced more accurate rankers compared to a proprietary GPT-3 model. On all five English retrieval collections (used in the original InPars study) we obtained substantial (7%-30%) and statistically significant improvements over BM25 (in nDCG and MRR) using only a 30M parameter six-layer MiniLM-30M ranker and a single three-shot prompt. In contrast, in the InPars study only a 100x larger monoT5-3B model consistently outperformed BM25, whereas their smaller monoT5-220M model (which is still 7x larger than our MiniLM ranker) outperformed BM25 only on MS MARCO and TREC DL 2020. In the same three-shot prompting scenario, our 435M parameter DeBERTA v3 ranker was at par with the 7x larger monoT5-3B (average gain over BM25 of 1.3 vs 1.32): In fact, on three out of five datasets, DeBERTA slightly outperformed monoT5-3B. Finally, these good results were achieved by re-ranking only 100 candidate documents compared to 1000 used by Bonifacio et al. (2022). We believe that InPars-light is the first truly cost-effective prompt-based unsupervised recipe to train and deploy neural ranking models that outperform BM25. Our code and data is publicly available. https://github.com/searchivarius/inpars_light/
isOpenAccess: True
TL\DR: InPars-light is the first truly cost-effective prompt-based unsupervised recipe to train and deploy neural ranking models that outperform BM25.
================================
faculty_name: Eric Nyberg
faculty_authorid: 144287919
paper_id: 444737639aeea4e1e616509e368afb0bae8f89d6
paper_title: Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA
publication_link: https://aclanthology.org/2023.dialdoc-1.11.pdf 
year_published: 2023 
abstract_paper:The DialDoc 2023 shared task has expanded the document-grounded dialogue task to encompass multiple languages, despite having limited annotated data. This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-agnostic approach is superior. Additionally, the study investigates the impact of query rewriting techniques using large language models, such as ChatGPT, on multilingual, document-grounded question-answering systems. The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.
isOpenAccess: True
TL\DR: This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-gnostic approach is superior.
================================
faculty_name: Eric Nyberg
faculty_authorid: 144287919
paper_id: 61354e45bca908ad08f24e44bd507b4e1c958e6f
paper_title: Chain-of-Skills: A Configurable Model for Open-Domain Question Answering
publication_link: http://arxiv.org/pdf/2305.03130 
year_published: 2023 
abstract_paper:The retrieval model is an indispensable component for real-world knowledge-intensive tasks, e.g., open-domain question answering (ODQA). As separate retrieval skills are annotated for different datasets, recent work focuses on customized methods, limiting the model transfer- ability and scalability. In this work, we propose a modular retriever where individual modules correspond to key skills that can be reused across datasets. Our approach supports flexible skill configurations based on the target domain to boost performance. To mitigate task interference, we design a novel modularization parameterization inspired by sparse Transformer. We demonstrate that our model can benefit from self-supervised pretraining on Wikipedia and fine-tuning using multiple ODQA datasets, both in a multi-task fashion. Our approach outperforms recent self-supervised retrievers in zero-shot evaluations and achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA and OTT-QA.
isOpenAccess: True
TL\DR: This work proposes a modular retriever where individual modules correspond to key skills that can be reused across datasets and achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA and OTT-QA.
================================
faculty_name: Eric Nyberg
faculty_authorid: 17080434
paper_id: c251d929c2e54a61366c02c7052f055d408072a1
paper_title: A super wear-resistant coating for Mg alloys achieved by plasma electrolytic oxidation and discontinuous deposition
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Eric Nyberg
faculty_authorid: 46841006
paper_id: 8d0c37eee7162f33178979b4183f0211e2dcae0d
paper_title: Difference-Masking: Choosing What to Mask in Continued Pretraining
publication_link: http://arxiv.org/pdf/2305.14577 
year_published: 2023 
abstract_paper:The self-supervised objective of masking-and-predicting has led to promising performance gains on a variety of downstream tasks. However, while most approaches randomly mask tokens, there is strong intuition that deciding what to mask can substantially improve learning outcomes. We investigate this in continued pretraining setting in which pretrained models continue to pretrain on domain-specific data before performing some downstream task. We introduce Difference-Masking, a masking strategy that automatically chooses what to mask during continued pretraining by considering what makes a task domain different from the pretraining domain. Empirically, we find that Difference-Masking outperforms baselines on continued pretraining settings across four diverse language-only and multimodal video tasks.
isOpenAccess: True
TL\DR: Difference-Masking is introduced, a masking strategy that automatically chooses what to mask during continued pretraining by considering what makes a task domain different from the pretraining domain.
================================
faculty_name: Eric Nyberg
faculty_authorid: 46841006
paper_id: daf657e9dc60e104827b6f574d3946c489188e69
paper_title: Using Implicit Feedback to Improve Question Generation
publication_link: http://arxiv.org/pdf/2304.13664 
year_published: 2023 
abstract_paper:Question Generation (QG) is a task of Natural Language Processing (NLP) that aims at automatically generating questions from text. Many applications can benefit from automatically generated questions, but often it is necessary to curate those questions, either by selecting or editing them. This task is informative on its own, but it is typically done post-generation, and, thus, the effort is wasted. In addition, most existing systems cannot incorporate this feedback back into them easily. In this work, we present a system, GEN, that learns from such (implicit) feedback. Following a pattern-based approach, it takes as input a small set of sentence/question pairs and creates patterns which are then applied to new unseen sentences. Each generated question, after being corrected by the user, is used as a new seed in the next iteration, so more patterns are created each time. We also take advantage of the corrections made by the user to score the patterns and therefore rank the generated questions. Results show that GEN is able to improve by learning from both levels of implicit feedback when compared to the version with no learning, considering the top 5, 10, and 20 questions. Improvements go up from 10%, depending on the metric and strategy used.
isOpenAccess: True
TL\DR: Difference-Masking is introduced, a masking strategy that automatically chooses what to mask during continued pretraining by considering what makes a task domain different from the pretraining domain.
================================
faculty_name: Kemal Oflazer
faculty_authorid: 2250930714
paper_id: 3b623333145c69cb29c63975213f7b3bac025954
paper_title: Abstractive summarization with deep reinforcement learning using semantic similarity rewards
publication_link: https://www.cambridge.org/core/services/aop-cambridge-core/content/view/740B4B5903AE80FE14709F5DAEE7AD41/S1351324923000505a.pdf/div-class-title-abstractive-summarization-with-deep-reinforcement-learning-using-semantic-similarity-rewards-div.pdf 
year_published: 2023 
abstract_paper:
 Abstractive summarization is an approach to document summarization that is not limited to selecting sentences from the document but can generate new sentences as well. We address the two main challenges in abstractive summarization: how to evaluate the performance of a summarization model and what is a good training objective. We first introduce new evaluation measures based on the semantic similarity of the input and corresponding summary. The similarity scores are obtained by the fine-tuned BERTurk model using either the cross-encoder or a bi-encoder architecture. The fine-tuning is done on the Turkish Natural Language Inference and Semantic Textual Similarity benchmark datasets. We show that these measures have better correlations with human evaluations compared to Recall-Oriented Understudy for Gisting Evaluation (ROUGE) scores and BERTScore. We then introduce a deep reinforcement learning algorithm that uses the proposed semantic similarity measures as rewards, together with a mixed training objective, in order to generate more natural summaries in terms of human readability. We show that training with a mixed training objective function compared to only the maximum-likelihood objective improves similarity scores.
isOpenAccess: True
TL\DR: A deep reinforcement learning algorithm is introduced that uses the proposed semantic similarity measures as rewards, together with a mixed training objective, in order to generate more natural summaries in terms of human readability.
================================
faculty_name: Bhiksha Ramakrishnan
faculty_authorid: 1880336
paper_id: 45b7d6e09d11e496e941481056177cf0164b5278
paper_title: GPT-Sentinel: Distinguishing Human and ChatGPT Generated Content
publication_link: http://arxiv.org/pdf/2305.07969 
year_published: 2023 
abstract_paper:This paper presents a novel approach for detecting ChatGPT-generated vs. human-written text using language models. To this end, we first collected and released a pre-processed dataset named OpenGPTText, which consists of rephrased content generated using ChatGPT. We then designed, implemented, and trained two different models for text classification, using Robustly Optimized BERT Pretraining Approach (RoBERTa) and Text-to-Text Transfer Transformer (T5), respectively. Our models achieved remarkable results, with an accuracy of over 97% on the test dataset, as evaluated through various metrics. Furthermore, we conducted an interpretability study to showcase our model's ability to extract and differentiate key features between human-written and ChatGPT-generated text. Our findings provide important insights into the effective use of language models to detect generated text.
isOpenAccess: True
TL\DR: This paper designed, implemented, and trained two different models for text classification, using Robustly Optimized BERT Pretraining Approach (RoBERTa) and Text-to-Text Transfer Transformer (T5), respectively, and achieved remarkable results, with an accuracy of over 97% on the test dataset.
================================
faculty_name: Bhiksha Ramakrishnan
faculty_authorid: 2243194988
paper_id: 786294f4008732a5dac9895a8507bc4c80450075
paper_title: Dynamic-SUPERB: Towards A Dynamic, Collaborative, and Comprehensive Instruction-Tuning Benchmark for Speech
publication_link: https://arxiv.org/pdf/2309.09510 
year_published: 2023 
abstract_paper:Text language models have shown remarkable zero-shot capability in generalizing to unseen tasks when provided with well-formulated instructions. However, existing studies in speech processing primarily focus on limited or specific tasks. Moreover, the lack of standardized benchmarks hinders a fair comparison across different approaches. Thus, we present Dynamic-SUPERB, a benchmark designed for building universal speech models capable of leveraging instruction tuning to perform multiple tasks in a zero-shot fashion. To achieve comprehensive coverage of diverse speech tasks and harness instruction tuning, we invite the community to collaborate and contribute, facilitating the dynamic growth of the benchmark. To initiate, Dynamic-SUPERB features 55 evaluation instances by combining 33 tasks and 22 datasets. This spans a broad spectrum of dimensions, providing a comprehensive platform for evaluation. Additionally, we propose several approaches to establish benchmark baselines. These include the utilization of speech models, text language models, and the multimodal encoder. Evaluation results indicate that while these baselines perform reasonably on seen tasks, they struggle with unseen ones. We also conducted an ablation study to assess the robustness and seek improvements in the performance. We release all materials to the public and welcome researchers to collaborate on the project, advancing technologies in the field together.
isOpenAccess: True
TL\DR: This paper designed, implemented, and trained two different models for text classification, using Robustly Optimized BERT Pretraining Approach (RoBERTa) and Text-to-Text Transfer Transformer (T5), respectively, and achieved remarkable results, with an accuracy of over 97% on the test dataset.
================================
faculty_name: Carolyn Rosé
faculty_authorid: 2053634036
paper_id: 7ec990ab7362e8eac0c074830d44a58a1d89b4a6
paper_title: Enhancing student learning and achievement through orchestration of group processes and group composition
publication_link: https://link.springer.com/content/pdf/10.1007/s11412-023-09408-x.pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: This September issue of the International Journal of Computer-Supported Collaborative Learning reflects on the importance of productive collaborative processes, with an emphasis on feedback processes, and the scaffolding that upholds and promotes productive learning processes, whether it is explicit or implicit.
================================
faculty_name: Carolyn Rosé
faculty_authorid: 2053634036
paper_id: bc936884d358d73d6b514f7e5899e67ad09690d8
paper_title: Editorial: Nine elements for robust collaborative learning analytics: A constructive collaborative critique
publication_link: https://link.springer.com/content/pdf/10.1007/s11412-023-09389-x.pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: The four full articles of this March issue offer a view of the kind of work that the CSCL community is engaging in to capture meaningful traces of learning, map them onto valued learning constructs, and discover useful ways to present them back to teachers, students and other educational stakeholders.
================================
faculty_name: Carolyn Rosé
faculty_authorid: 35959897
paper_id: 06dc7b3d8cbc40fb4e39b42de1bc664deaacca74
paper_title: High school students’ data modeling practices and processes: from modeling unstructured data to evaluating automated decisions
publication_link: https://www.tandfonline.com/doi/pdf/10.1080/17439884.2023.2189735?needAccess=true&role=button 
year_published: 2023 
abstract_paper:ABSTRACT It’s critical to foster artificial intelligence (AI) literacy for high school students, the first generation to grow up surrounded by AI, to understand working mechanism of data-driven AI technologies and critically evaluate automated decisions from predictive models. While efforts have been made to engage youth in understanding AI through developing machine learning models, few provided in-depth insights into the nuanced learning processes. In this study, we examined high school students’ data modeling practices and processes. Twenty-eight students developed machine learning models with text data for classifying negative and positive reviews of ice cream stores. We identified nine data modeling practices that describe students’ processes of model exploration, development, and testing and two themes about evaluating automated decisions from data technologies. The results provide implications for designing accessible data modeling experiences for students to understand data justice as well as the role and responsibility of data modelers in creating AI technologies.
isOpenAccess: True
TL\DR: It’s critical to foster artificial intelligence literacy for high school students to understand working mechanism of data-driven AI technologies and critically evaluate automated decisions from predictive models.
================================
faculty_name: Carolyn Rosé
faculty_authorid: 35959897
paper_id: 0c0d8ea1c1745e7b56bc3b1513a715ae3df30c44
paper_title: Linguistic representations for fewer-shot relation extraction across domains
publication_link: https://arxiv.org/pdf/2307.03823 
year_published: 2023 
abstract_paper:Recent work has demonstrated the positive impact of incorporating linguistic representations as additional context and scaffolds on the in-domain performance of several NLP tasks. We extend this work by exploring the impact of linguistic representations on cross-domain performance in a few-shot transfer setting. An important question is whether linguistic representations enhance generalizability by providing features that function as cross-domain pivots. We focus on the task of relation extraction on three datasets of procedural text in two domains, cooking and materials science. Our approach augments a popular transformer-based architecture by alternately incorporating syntactic and semantic graphs constructed by freely available off-the-shelf tools. We examine their utility for enhancing generalization, and investigate whether earlier findings, e.g. that semantic representations can be more helpful than syntactic ones, extend to relation extraction in multiple domains. We find that while the inclusion of these graphs results in significantly higher performance in few-shot transfer, both types of graph exhibit roughly equivalent utility.
isOpenAccess: True
TL\DR: It’s critical to foster artificial intelligence literacy for high school students to understand working mechanism of data-driven AI technologies and critically evaluate automated decisions from predictive models.
================================
faculty_name: Carolyn Rosé
faculty_authorid: 35959897
paper_id: 117e1323677cb5d78ece0fd07b5cfa81618f4866
paper_title: Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning
publication_link: https://aclanthology.org/2023.acl-long.834.pdf 
year_published: 2023 
abstract_paper:In quantitative question answering, compositional generalization is one of the main challenges of state of the art models, especially when longer sequences of reasoning steps are required. In this paper we propose CounterComp, a method that uses counterfactual scenarios to generate samples with compositional contrast. Instead of a data augmentation approach, CounterComp is based on metric learning, which allows for direct sampling from the training set and circumvents the need for additional human labels. Our proposed auxiliary metric learning loss improves the performance of three state of the art models on four recently released datasets. We also show how the approach can improve OOD performance on unseen domains, as well as unseen compositions. Lastly, we demonstrate how the method can lead to better compositional attention patterns during training.
isOpenAccess: True
TL\DR: It’s critical to foster artificial intelligence literacy for high school students to understand working mechanism of data-driven AI technologies and critically evaluate automated decisions from predictive models.
================================
faculty_name: Carolyn Rosé
faculty_authorid: 35959897
paper_id: 15d85036b15388bcb0199c83c01ba833e6095a31
paper_title: Towards Extracting and Understanding the Implicit Rubrics of Transformer Based Automatic Essay Scoring Models
publication_link: https://aclanthology.org/2023.bea-1.20.pdf 
year_published: 2023 
abstract_paper:By aligning the functional components derived from the activations of transformer models trained for AES with external knowledge such as human-understandable feature groups, the proposed method improves the interpretability of a Longformer Automatic Essay Scoring (AES) system and provides tools for performing such analyses on further neural AES systems. The analysis focuses on models trained to score essays based on organization, main idea, support, and language. The findings provide insights into the models’ decision-making processes, biases, and limitations, contributing to the development of more transparent and reliable AES systems.
isOpenAccess: True
TL\DR: It’s critical to foster artificial intelligence literacy for high school students to understand working mechanism of data-driven AI technologies and critically evaluate automated decisions from predictive models.
================================
faculty_name: Carolyn Rosé
faculty_authorid: 35959897
paper_id: 27ca2d927421035e10b48c96a96db32224f1f8e6
paper_title: Exploring Artificial Intelligence in English Language Arts with StoryQ
publication_link: https://ojs.aaai.org/index.php/AAAI/article/download/26899/26671 
year_published: 2023 
abstract_paper:Exploring Artificial Intelligence (AI) in English Language Arts (ELA) with StoryQ is a 10-hour curriculum module designed for high school ELA classes. The module introduces students to fundamental AI concepts and essential machine learning workflow using StoryQ, a web-based GUI environment for Grades 6-12 learners. In this module, students work with unstructured text data and learn to train, test, and improve text classification models such as intent recognition, clickbait filter, and sentiment analysis. As they interact with machine-learning language models deeply, students also gain a nuanced understanding of language and how to wield it, not just as a data structure, but as a tool in our human-human encounters as well. The current version contains eight lessons, all delivered through a full-featured online learning and teaching platform. Computers and Internet access are required to implement the module. The module was piloted in an ELA class in the Spring of 2022, and the student learning outcomes were positive. The module is currently undergoing revision and will be further tested and improved in Fall 2022.
isOpenAccess: True
TL\DR: None
================================
faculty_name: Carolyn Rosé
faculty_authorid: 2260652406
paper_id: 9fdc5ca71d1600bee600a4398315af5c29b3955e
paper_title: SPEERLoom: An Open-Source Loom Kit for Interdisciplinary Engagement in Math, Engineering, and Textiles
publication_link: https://dl.acm.org/doi/pdf/10.1145/3586183.3606724 
year_published: 2023 
abstract_paper:Weaving is a fabrication process that is grounded in mathematics and engineering: from the binary, matrix-like nature of the pattern drafts weavers have used for centuries, to the punch card programming of the first Jacquard looms. This intersection of disciplines provides an opportunity to ground abstract mathematical concepts in a concrete and embodied art, viewing this textile art through the lens of engineering. Currently, available looms are not optimized to take advantage of this opportunity to increase mathematics learning by providing hands-on interdisciplinary learning in collegiate classrooms. In this work, we present SPEERLoom: an open-source, robotic Jacquard loom kit designed to be a tool for interweaving cloth fabrication, mathematics, and engineering to support interdisciplinary learning in the classroom. We discuss the design requirements and subsequent design of SPEERLoom. We also present the results of a pilot study in a post-secondary class finding that SPEERLoom supports hands-on, interdisciplinary learning of math, engineering, and textiles.
isOpenAccess: True
TL\DR: The design requirements and subsequent design of SPEERLoom, an open-source, robotic Jacquard loom kit designed to be a tool for interweaving cloth fabrication, mathematics, and engineering to support interdisciplinary learning in the classroom are discussed.
================================
faculty_name: Carolyn Rosé
faculty_authorid: 2261985726
paper_id: 2f760d84babe36f98d2fdc5b6dcb60c0169a3466
paper_title: Studying Interdisciplinary Collaboration as a Core Skill
publication_link: https://repository.isls.org//bitstream/1/9240/1/CSCL2023_378-379.pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: The design requirements and subsequent design of SPEERLoom, an open-source, robotic Jacquard loom kit designed to be a tool for interweaving cloth fabrication, mathematics, and engineering to support interdisciplinary learning in the classroom are discussed.
================================
faculty_name: Alexander Rudnicky
faculty_authorid: 1783635
paper_id: 06a8f2e3c4266196b008851f1ec7ef9f340809da
paper_title: Advancing Regular Language Reasoning in Linear Recurrent Neural Networks
publication_link: https://arxiv.org/pdf/2309.07412 
year_published: 2023 
abstract_paper:In recent studies, linear recurrent neural networks (LRNNs) have achieved Transformer-level performance in natural language modeling and long-range modeling while offering rapid parallel training and constant inference costs. With the resurged interest in LRNNs, we study whether they can learn the hidden rules in training sequences, such as the grammatical structures of regular language. We theoretically analyze some existing LRNNs and discover their limitations on regular language. Motivated by the analysis, we propose a new LRNN equipped with a block-diagonal and input-dependent transition matrix. Experiments suggest that the proposed model is the only LRNN that can perform length extrapolation on regular language tasks such as Sum, Even Pair, and Modular Arithmetic.
isOpenAccess: True
TL\DR: The design requirements and subsequent design of SPEERLoom, an open-source, robotic Jacquard loom kit designed to be a tool for interweaving cloth fabrication, mathematics, and engineering to support interdisciplinary learning in the classroom are discussed.
================================
faculty_name: Alexander Rudnicky
faculty_authorid: 1783635
paper_id: 2670612b5e11297cd9b98f4d7ff796725f77fe35
paper_title: Structured Dialogue Discourse Parsing
publication_link: http://arxiv.org/pdf/2306.15103 
year_published: 2023 
abstract_paper:Dialogue discourse parsing aims to uncover the internal structure of a multi-participant conversation by finding all the discourse links and corresponding relations. Previous work either treats this task as a series of independent multiple-choice problems, in which the link existence and relations are decoded separately, or the encoding is restricted to only local interaction, ignoring the holistic structural information. In contrast, we propose a principled method that improves upon previous work from two perspectives: encoding and decoding. From the encoding side, we perform structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm, where all discourse links and relations in the dialogue are jointly optimized based on latent tree-level distribution. From the decoding side, we perform structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best captures the discourse structure. In addition, unlike in previous work, we do not rely on hand-crafted features; this improves the model’s robustness. Experiments show that our method achieves new state-of-the-art, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores).
isOpenAccess: True
TL\DR: This work proposes a principled method that improves upon previous work from two perspectives: encoding and decoding and achieves new state-of-the-art results, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores).
================================
faculty_name: Alexander Rudnicky
faculty_authorid: 1783635
paper_id: 4b8d3ede673ddeab9dfb5184da6b748d7a526754
paper_title: A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech
publication_link: http://arxiv.org/pdf/2302.04215 
year_published: 2023 
abstract_paper:Recent Text-to-Speech (TTS) systems trained on reading or acted corpora have achieved near human-level naturalness. The diversity of human speech, however, often goes beyond the coverage of these corpora. We believe the ability to handle such diversity is crucial for AI systems to achieve human-level communication. Our work explores the use of more abundant real-world data for building speech synthesizers. We train TTS systems using real-world speech from YouTube and podcasts. We observe the mismatch between training and inference alignments in mel-spectrogram based autoregressive models, leading to unintelligible synthesis, and demonstrate that learned discrete codes within multiple code groups effectively resolves this issue. We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality. We conduct ablation analyses to identify the efficacy of our methods. We show that MQTTS outperforms existing TTS systems in several objective and subjective measures.
isOpenAccess: True
TL\DR: This work introduces the MQTTS system, a Text-to-Speech system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality, and shows that MqTTS outperforms existing TTS systems in several objective and subjective measures.
================================
faculty_name: Alexander Rudnicky
faculty_authorid: 1783635
paper_id: 9799c17fd287bb9e8d231fe032c6dbf9c0c9d675
paper_title: Overview of Robust and Multilingual Automatic Evaluation Metrics

for Open-Domain Dialogue Systems at DSTC 11 Track 4
publication_link: https://arxiv.org/pdf/2306.12794 
year_published: 2023 
abstract_paper:The advent and fast development of neural networks have revolutionized the research on dialogue systems and subsequently have triggered various challenges regarding their automatic evaluation. Automatic evaluation of open-domain dialogue systems as an open challenge has been the center of the attention of many researchers. Despite the consistent efforts to improve automatic metrics’ correlations with human evaluation, there have been very few attempts to assess their robustness over multiple domains and dimensions. Also, their focus is mainly on the English language. All of these challenges prompt the development of automatic evaluation metrics that are reliable in various domains, dimensions, and languages. This track in the 11th Dialogue System Technology Challenge (DSTC11) is part of the ongoing effort to promote robust and multilingual automatic evaluation metrics. This article describes the datasets and baselines provided to participants and discusses the submission and result details of the two proposed subtasks.
isOpenAccess: True
TL\DR: The datasets and baselines provided to participants are described and the submission and result details of the two proposed subtasks are discussed, which promote robust and multilingual automatic evaluation metrics.
================================
faculty_name: Alexander Rudnicky
faculty_authorid: 1783635
paper_id: f743324682d5d50db9b114fa60b908f09c10c9a0
paper_title: Learning to Ask Questions for Zero-shot Dialogue State Tracking
publication_link: https://dl.acm.org/doi/pdf/10.1145/3539618.3592010 
year_published: 2023 
abstract_paper:We present a method for performing zero-shot Dialogue State Tracking (DST) by casting the task as a learning-to-ask-questions framework. The framework learns to pair the best question generation (QG) strategy with in-domain question answering (QA) methods to extract slot values from a dialogue without any human intervention. A novel self-supervised QA pretraining step using in-domain data is essential to learn the structure without requiring any slot-filling annotations. Moreover, we show that QG methods need to be aligned with the same grammatical person used in the dialogue. Empirical evaluation on the MultiWOZ 2.1 dataset demonstrates that our approach, when used alongside robust QA models, outperforms existing zero-shot methods in the challenging task of zero-shot cross domain adaptation-given a comparable amount of domain knowledge during data creation. Finally, we analyze the impact of the types of questions used, and demonstrate that the algorithmic approach outperforms template-based question generation.
isOpenAccess: True
TL\DR: This work presents a method for performing zero-shot Dialogue State Tracking by casting the task as a learning-to-ask-questions framework that outperforms template-based question generation and shows that QG methods need to be aligned with the same grammatical person used in the dialogue.
================================
faculty_name: Alexander Rudnicky
faculty_authorid: 3156164
paper_id: 161bf3f0705ef8e088f53b383363338daac9af44
paper_title: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings
publication_link: http://arxiv.org/pdf/2305.13571 
year_published: 2023 
abstract_paper:The use of positional embeddings in transformer language models is widely accepted. However, recent research has called into question the necessity of such embeddings. We further extend this inquiry by demonstrating that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance. To quantify this variance, we derive the underlying distribution of each step within a transformer layer. Through empirical validation using a fully pretrained model, we show that the variance shrinkage effect still persists after extensive gradient updates. Our findings serve to justify the decision to discard positional embeddings and thus facilitate more efficient pretraining of transformer language models.
isOpenAccess: True
TL\DR: This work demonstrates that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance, and derives the underlying distribution of each step within a transformer layer.
================================
faculty_name: Alexander Rudnicky
faculty_authorid: 3156164
paper_id: 465ec2212d865e875e64638b3dd1ecaac21c5ddd
paper_title: Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation
publication_link: http://arxiv.org/pdf/2305.03796 
year_published: 2023 
abstract_paper:Unlike recurrent models, conventional wisdom has it that Transformers cannot perfectly model regular languages. Inspired by the notion of working memory, we propose a new Transformer variant named RegularGPT. With its novel combination of Weight-Sharing, Adaptive-Depth, and Sliding-Dilated-Attention, RegularGPT constructs working memory along the depth dimension, thereby enabling efficient and successful modeling of regular languages such as PARITY. We further test RegularGPT on the task of natural language length extrapolation and surprisingly find that it rediscovers the local windowed attention effect deemed necessary in prior work for length extrapolation.
isOpenAccess: True
TL\DR: Inspired by the notion of working memory, a new Transformer variant named RegularGPT is proposed, which constructs working memory along the depth dimension, thereby enabling efficient and successful modeling of regular languages such as PARITY.
================================
faculty_name: Maarten Sap
faculty_authorid: 2729164
paper_id: 14ddefae2be4b5bb50b9fcb4a085e45fbecb5c5c
paper_title: Modeling Empathic Similarity in Personal Narratives
publication_link: http://arxiv.org/pdf/2305.14246 
year_published: 2023 
abstract_paper:The most meaningful connections between people are often fostered through expression of shared vulnerability and emotional experiences in personal narratives. We introduce a new task of identifying similarity in personal stories based on empathic resonance, i.e., the extent to which two people empathize with each others' experiences, as opposed to raw semantic or lexical similarity, as has predominantly been studied in NLP. Using insights from social psychology, we craft a framework that operationalizes empathic similarity in terms of three key features of stories: main events, emotional trajectories, and overall morals or takeaways. We create EmpathicStories, a dataset of 1,500 personal stories annotated with our empathic similarity features, and 2,000 pairs of stories annotated with empathic similarity scores. Using our dataset, we fine-tune a model to compute empathic similarity of story pairs, and show that this outperforms semantic similarity models on automated correlation and retrieval metrics. Through a user study with 150 participants, we also assess the effect our model has on retrieving stories that users empathize with, compared to naive semantic similarity-based retrieval, and find that participants empathized significantly more with stories retrieved by our model. Our work has strong implications for the use of empathy-aware models to foster human connection and empathy between people.
isOpenAccess: True
TL\DR: A new task of identifying similarity in personal stories based on empathic resonance is introduced, i.e., the extent to which two people empathize with each others' experiences, as opposed to raw semantic or lexical similarity, as has predominantly been studied in NLP.
================================
faculty_name: Maarten Sap
faculty_authorid: 2729164
paper_id: 185ace5661963e2e1eb998e739e4110272a6bb43
paper_title: COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements
publication_link: http://arxiv.org/pdf/2306.01985 
year_published: 2023 
abstract_paper:Warning: This paper contains content that may be offensive or upsetting. Understanding the harms and offensiveness of statements requires reasoning about the social and situational context in which statements are made. For example, the utterance"your English is very good"may implicitly signal an insult when uttered by a white man to a non-white colleague, but uttered by an ESL teacher to their student would be interpreted as a genuine compliment. Such contextual factors have been largely ignored by previous approaches to toxic language detection. We introduce COBRA frames, the first context-aware formalism for explaining the intents, reactions, and harms of offensive or biased statements grounded in their social and situational context. We create COBRACORPUS, a dataset of 33k potentially offensive statements paired with machine-generated contexts and free-text explanations of offensiveness, implied biases, speaker intents, and listener reactions. To study the contextual dynamics of offensiveness, we train models to generate COBRA explanations, with and without access to the context. We find that explanations by context-agnostic models are significantly worse than by context-aware ones, especially in situations where the context inverts the statement's offensiveness (29% accuracy drop). Our work highlights the importance and feasibility of contextualized NLP by modeling social factors.
isOpenAccess: True
TL\DR: COBRA frames are introduced, the first context-aware formalism for explaining the intents, reactions, and harms of offensive or biased statements grounded in their social and situational context, and the importance and feasibility of contextualized NLP by modeling social factors are highlighted.
================================
faculty_name: Maarten Sap
faculty_authorid: 2729164
paper_id: 27553f8bd9cbee90f6e65b9cdecadff0e7cc55ee
paper_title: Riveter: Measuring Power and Social Dynamics Between Entities
publication_link: https://aclanthology.org/2023.acl-demo.36.pdf 
year_published: 2023 
abstract_paper:Riveter provides a complete easy-to-use pipeline for analyzing verb connotations associated with entities in text corpora. We prepopulate the package with connotation frames of sentiment, power, and agency, which have demonstrated usefulness for capturing social phenomena, such as gender bias, in a broad range of corpora. For decades, lexical frameworks have been foundational tools in computational social science, digital humanities, and natural language processing, facilitating multifaceted analysis of text corpora. But working with verb-centric lexica specifically requires natural language processing skills, reducing their accessibility to other researchers. By organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions, Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research.
isOpenAccess: True
TL\DR: Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research by organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions.
================================
faculty_name: Maarten Sap
faculty_authorid: 2729164
paper_id: 57d65e85c62aef04dfb2a48380e415fbb790e5ee
paper_title: Don't Take This Out of Context!: On the Need for Contextual Models and Evaluations for Stylistic Rewriting
publication_link: https://aclanthology.org/2023.emnlp-main.701.pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research by organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions.
================================
faculty_name: Maarten Sap
faculty_authorid: 2729164
paper_id: 85a5ffc509fa50c96b415e09ae87fb6e5f435b37
paper_title: BiasX: "Thinking Slow" in Toxic Content Moderation with Explanations of Implied Social Biases
publication_link: http://arxiv.org/pdf/2305.13589 
year_published: 2023 
abstract_paper:Toxicity annotators and content moderators often default to mental shortcuts when making decisions. This can lead to subtle toxicity being missed, and seemingly toxic but harmless content being over-detected. We introduce BiasX, a framework that enhances content moderation setups with free-text explanations of statements' implied social biases, and explore its effectiveness through a large-scale crowdsourced user study. We show that indeed, participants substantially benefit from explanations for correctly identifying subtly (non-)toxic content. The quality of explanations is critical: imperfect machine-generated explanations (+2.4% on hard toxic examples) help less compared to expert-written human explanations (+7.2%). Our results showcase the promise of using free-text explanations to encourage more thoughtful toxicity moderation.
isOpenAccess: True
TL\DR: Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research by organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions.
================================
faculty_name: Maarten Sap
faculty_authorid: 2729164
paper_id: 9d2dc57903e99f33b9cf727c3903718751d82663
paper_title: Improving Language Models with Advantage-based Offline Policy Gradients
publication_link: https://arxiv.org/pdf/2305.14718 
year_published: 2023 
abstract_paper:Language Models (LMs) achieve substantial language capabilities when finetuned using Reinforcement Learning with Human Feedback (RLHF). However, RLHF is an unstable and data-hungry process that continually requires new high-quality LM-generated data for finetuning. We introduce Advantage-Leftover Lunch RL (A-LoL), a new class of offline policy gradient algorithms that enable RL training on any pre-existing data. By assuming the entire LM output sequence as a single action, A-LoL allows incorporating sequence-level classifiers or human-designed scoring functions as rewards. Subsequently, by using LM's internal sequence-level value estimate, A-LoL filters negative advantage (low-quality) data points during training, making it resilient to noise. Overall, A-LoL is an easy-to-implement LM training recipe that is sample-efficient and stable. We demonstrate the effectiveness of A-LoL and its variants with a set of four different language generation tasks. We compare against both online RL (PPO) and recent preference-based (DPO, PRO) and reward-based (GOLD) offline RL baselines. On the commonly-used RLHF benchmark, Helpful and Harmless Assistant (HHA), LMs trained with A-LoL methods achieve the highest diversity while also being rated more safe and helpful than baselines according to humans. Additionally, in the remaining three tasks, A-LoL could optimize multiple distinct reward functions even when using noisy or suboptimal training data. We also release our experimental code. https://github.com/abaheti95/LoL-RL
isOpenAccess: True
TL\DR: Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research by organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions.
================================
faculty_name: Maarten Sap
faculty_authorid: 2729164
paper_id: a5731b32060909bfc8848fa5f7e1e14ca3b53240
paper_title: From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models
publication_link: http://arxiv.org/pdf/2305.17174 
year_published: 2023 
abstract_paper:Dogwhistles are coded expressions that simultaneously convey one meaning to a broad audience and a second, often hateful or provocative, meaning to a narrow in-group; they are deployed to evade both political repercussions and algorithmic content moderation. For example, the word “cosmopolitan” in a sentence such as “we need to end the cosmopolitan experiment” can mean “worldly” to many but also secretly mean “Jewish” to a select few. We present the first large-scale computational investigation of dogwhistles. We develop a typology of dogwhistles, curate the largest-to-date glossary of over 300 dogwhistles with rich contextual information and examples, and analyze their usage in historical U.S. politicians’ speeches. We then assess whether a large language model (GPT-3) can identify dogwhistles and their meanings, and find that GPT-3’s performance varies widely across types of dogwhistles and targeted groups. Finally, we show that harmful content containing dogwhistles avoids toxicity detection, highlighting online risks presented by such coded language. This work sheds light on the theoretical and applied importance of dogwhistles in both NLP and computational social science, and provides resources to facilitate future research in modeling dogwhistles and mitigating their online harms.
isOpenAccess: True
TL\DR: Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research by organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions.
================================
faculty_name: Maarten Sap
faculty_authorid: 2729164
paper_id: a66ff335f5934fe7503a99d3eb3abed493994df1
paper_title: NLPositionality: Characterizing Design Biases of Datasets and Models
publication_link: http://arxiv.org/pdf/2306.01943 
year_published: 2023 
abstract_paper:Design biases in NLP systems, such as performance differences for different populations, often stem from their creator’s positionality, i.e., views and lived experiences shaped by identity and background. Despite the prevalence and risks of design biases, they are hard to quantify because researcher, system, and dataset positionality is often unobserved. We introduce NLPositionality, a framework for characterizing design biases and quantifying the positionality of NLP datasets and models. Our framework continuously collects annotations from a diverse pool of volunteer participants on LabintheWild, and statistically quantifies alignment with dataset labels and model predictions. We apply NLPositionality to existing datasets and models for two tasks—social acceptability and hate speech detection. To date, we have collected 16,299 annotations in over a year for 600 instances from 1,096 annotators across 87 countries.We find that datasets and models align predominantly with Western, White, college-educated, and younger populations. Additionally, certain groups, such as non-binary people and non-native English speakers, are further marginalized by datasets and models as they rank least in alignment across all tasks. Finally, we draw from prior literature to discuss how researchers can examine their own positionality and that of their datasets and models, opening the door for more inclusive NLP systems.
isOpenAccess: True
TL\DR: NLPositionality, a framework for characterizing design biases and quantifying the positionality of NLP datasets and models, is introduced and it is found that dataset and models align predominantly with Western, White, college-educated, and younger populations.
================================
faculty_name: Maarten Sap
faculty_authorid: 2729164
paper_id: a89c30ceca55783a1b2ff843eb6a4793e4a54b66
paper_title: Don't Take This Out of Context! On the Need for Contextual Models and Evaluations for Stylistic Rewriting
publication_link: http://arxiv.org/pdf/2305.14755 
year_published: 2023 
abstract_paper:Most existing stylistic text rewriting methods and evaluation metrics operate on a sentence level, but ignoring the broader context of the text can lead to preferring generic, ambiguous, and incoherent rewrites. In this paper, we investigate integrating the preceding textual context into both the $\textit{rewriting}$ and $\textit{evaluation}$ stages of stylistic text rewriting, and introduce a new composite contextual evaluation metric $\texttt{CtxSimFit}$ that combines similarity to the original sentence with contextual cohesiveness. We comparatively evaluate non-contextual and contextual rewrites in formality, toxicity, and sentiment transfer tasks. Our experiments show that humans significantly prefer contextual rewrites as more fitting and natural over non-contextual ones, yet existing sentence-level automatic metrics (e.g., ROUGE, SBERT) correlate poorly with human preferences ($\rho$=0--0.3). In contrast, human preferences are much better reflected by both our novel $\texttt{CtxSimFit}$ ($\rho$=0.7--0.9) as well as proposed context-infused versions of common metrics ($\rho$=0.4--0.7). Overall, our findings highlight the importance of integrating context into the generation and especially the evaluation stages of stylistic text rewriting.
isOpenAccess: True
TL\DR: NLPositionality, a framework for characterizing design biases and quantifying the positionality of NLP datasets and models, is introduced and it is found that dataset and models align predominantly with Western, White, college-educated, and younger populations.
================================
faculty_name: Maarten Sap
faculty_authorid: 2729164
paper_id: c2850c897a179c07a25023029306600e0ea82f75
paper_title: Queer In AI: A Case Study in Community-Led Participatory AI
publication_link: https://arrow.tudublin.ie/context/scschcomcon/article/1430/viewcontent/Queer_In_AI___A_Case_Study_in_Community_Led_Participatory_AI.pdf 
year_published: 2023 
abstract_paper:Queerness and queer people face an uncertain future in the face of ever more widely deployed and invasive artificial intelligence (AI). These technologies have caused numerous harms to queer people, including privacy violations, censoring and downranking queer content, exposing queer people and spaces to harassment by making them hypervisible, deadnaming and outing queer people. More broadly, they have violated core tenets of queerness by classifying and controlling queer identities. In response to this, the queer community in AI has organized Queer in AI, a global, decentralized, volunteer-run grassroots organization that employs intersectional and community-led participatory design to build an inclusive and equitable AI future. In this paper, we present Queer in AI as a case study for community-led participatory design in AI. We examine how participatory design and intersectional tenets started and shaped this community’s programs over the years. We discuss different challenges that emerged in the process, look at ways this organization has fallen short of operationalizing participatory and intersectional principles, and then assess the organization’s impact. Queer in AI provides important lessons and insights for practitioners and theorists of participatory methods broadly through its rejection of hierarchy in favor of decentralization, success at building aid and programs by and for the queer community, and effort to change actors and institutions outside of the queer community. Finally, we theorize how communities like Queer in AI contribute to the participatory design in AI more broadly by fostering cultures of participation in AI, welcoming and empowering marginalized participants, critiquing poor or exploitative participatory practices, and bringing participation to institutions outside of individual research projects. Queer in AI’s work serves as a case study of grassroots activism and participatory methods within AI, demonstrating the potential of community-led participatory methods and intersectional praxis, while also providing challenges, case studies, and nuanced insights to researchers developing and using participatory methods.
isOpenAccess: True
TL\DR: This paper examines how participatory design and intersectional tenets started and shaped this community’s programs over the years, and discusses different challenges that emerged in the process, and looks at ways this organization has fallen short of operationalizing participatory and intersectionsal principles.
================================
faculty_name: Maarten Sap
faculty_authorid: 2729164
paper_id: d655f652d02251b45db43181c5e3c73dfc59cd51
paper_title: Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties
publication_link: https://arxiv.org/pdf/2309.00779 
year_published: 2023 
abstract_paper:Human values are crucial to human decision-making. Value pluralism is the view that multiple correct values may be held in tension with one another (e.g., when considering lying to a friend to protect their feelings, how does one balance honesty with friendship?). As statistical learners, AI systems fit to averages by default, washing out these potentially irreducible value conflicts. To improve AI systems to better reflect value pluralism, the first-order challenge is to explore the extent to which AI systems can model pluralistic human values, rights, and duties as well as their interaction. We introduce ValuePrism, a large-scale dataset of 218k values, rights, and duties connected to 31k human-written situations. ValuePrism's contextualized values are generated by GPT-4 and deemed high-quality by human annotators 91% of the time. We conduct a large-scale study with annotators across diverse social and demographic backgrounds to try to understand whose values are represented. With ValuePrism, we build Kaleido, an open, light-weight, and structured language-based multi-task model that generates, explains, and assesses the relevance and valence (i.e., support or oppose) of human values, rights, and duties within a specific context. Humans prefer the sets of values output by our system over the teacher GPT-4, finding them more accurate and with broader coverage. In addition, we demonstrate that Kaleido can help explain variability in human decision-making by outputting contrasting values. Finally, we show that Kaleido's representations transfer to other philosophical frameworks and datasets, confirming the benefit of an explicit, modular, and interpretable approach to value pluralism. We hope that our work will serve as a step to making more explicit the implicit values behind human decision-making and to steering AI systems to make decisions that are more in accordance with them.
isOpenAccess: True
TL\DR: Kaleido is built, an open, light-weight, and structured language-based multi-task model that generates, explains, and assesses the relevance and valence of human values, rights, and duties within a specific context and demonstrates that Kaleido can help explain variability in human decision-making by outputting contrasting values.
================================
faculty_name: Maarten Sap
faculty_authorid: 2729164
paper_id: ddcd2bcc809bd0c2755a4a9487473d61ac327c50
paper_title: Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models
publication_link: http://arxiv.org/pdf/2305.14763 
year_published: 2023 
abstract_paper:The escalating debate on AI's capabilities warrants developing reliable metrics to assess machine"intelligence". Recently, many anecdotal examples were used to suggest that newer large language models (LLMs) like ChatGPT and GPT-4 exhibit Neural Theory-of-Mind (N-ToM); however, prior work reached conflicting conclusions regarding those abilities. We investigate the extent of LLMs' N-ToM through an extensive evaluation on 6 tasks and find that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust. We further examine the factors impacting performance on N-ToM tasks and discover that LLMs struggle with adversarial examples, indicating reliance on shallow heuristics rather than robust ToM abilities. We caution against drawing conclusions from anecdotal examples, limited benchmark testing, and using human-designed psychological tests to evaluate models.
isOpenAccess: True
TL\DR: It is found that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust, indicating reliance on shallow heuristics rather than robust ToM abilities.
================================
faculty_name: Maarten Sap
faculty_authorid: 2729164
paper_id: ea0585ed23e25d5f8682eb91f20c6ddbeb6a27b4
paper_title: Towards Countering Essentialism through Social Bias Reasoning
publication_link: http://arxiv.org/pdf/2303.16173 
year_published: 2023 
abstract_paper:Essentialist beliefs (i.e., believing that members of the same group are fundamentally alike) play a central role in social stereotypes and can lead to harm when left unchallenged. In our work, we conduct exploratory studies into the task of countering essentialist beliefs (e.g., ``liberals are stupid''). Drawing on prior work from psychology and NLP, we construct five types of counterstatements and conduct human studies on the effectiveness of these different strategies. Our studies also investigate the role in choosing a counterstatement of the level of explicitness with which an essentialist belief is conveyed. We find that statements that broaden the scope of a stereotype (e.g., to other groups, as in ``conservatives can also be stupid'') are the most popular countering strategy. We conclude with a discussion of challenges and open questions for future work in this area (e.g., improving factuality, studying community-specific variation) and we emphasize the importance of work at the intersection of NLP and psychology.
isOpenAccess: True
TL\DR: It is found that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust, indicating reliance on shallow heuristics rather than robust ToM abilities.
================================
faculty_name: Rita Singh
faculty_authorid: 47609362
paper_id: d77d82c224bf953cf67cb94e1c65b69497859fbb
paper_title: Implementing International Federation of Gynecology and Obstetrics Nutrition Checklist for Pregnant Women: Opportunities and Challenges in Low- and Middle-income Countries
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: It is found that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust, indicating reliance on shallow heuristics rather than robust ToM abilities.
================================
faculty_name: Rita Singh
faculty_authorid: 2237461908
paper_id: b5d8e7e1e1543cf39b84cd894a6a899e086e058b
paper_title: Mean Platelet Volume in Type 2 Diabetes: Correlation with Poor Glycaemic Control
publication_link: https://www.emjreviews.com/wp-content/uploads/2023/11/Mean-Platelet-Volume-in-Type-2-Diabetes.pdf 
year_published: 2023 
abstract_paper:Background: Diabetes is a global pandemic. Mean platelet volume (MPV) is an indicator of increased platelet activity, which is considered to play a role in the development of vascular complications in diabetes. Platelet volume is strongly and independently related with glycaemic control in Type 2 diabetes (T2D).

Aim: To study the MPV in patients with T2D, and its correlation with HbA1c, duration of T2D, and microvascular complications.

Methodology: This was a cross-sectional, observational study conducted at the Department of Medicine, Gandhi Medical College, Bhopal, India, during a period of 18 months on 300 patients with T2D. Blood glucose, HbA1c, MPV, fundoscopy, and 24-hour urine protein were done. Data were represented as mean+/-standard deviation and statistical analysis was done using SPSS software (IBM, Armonk, New York, USA).

Results: The mean age of patients was 56.64±8.69 years, with 52% of the patients being females. Of these patients, 18.3% had HbA1c between 6.5–8.0%, 51.7% between 8.1–10.0% and the rest above 10.0%. A total of 51% of the patients had diabetes for 6–10 years of duration and 30% for more than 10 years. Patients with higher HbA1c level and prolonged duration of diabetes had higher MPV (p<0.001). Patients with advanced diabetic retinopathy changes and nephropathy also had higher MPV (p<0.05).

Conclusion: Measurement of MPV in patients with T2D can be a useful and easily available prognostic marker, and hence assist clinicians to anticipate the occurrence of microvascular complications associated with the disease, especially in resource-poor settings, and reduce the burden of cost for the patient.
isOpenAccess: True
TL\DR: Measurement of MPV in patients with T2D can be a useful and easily available prognostic marker, and hence assist clinicians to anticipate the occurrence of microvascular complications associated with the disease, especially in resource-poor settings, and reduce the burden of cost for the patient.
================================
faculty_name: Rita Singh
faculty_authorid: 2240446387
paper_id: 1de2dcb5de694920f50f000a3795eb0ca54d57ab
paper_title: LoFT: Local Proxy Fine-tuning For Improving Transferability Of Adversarial Attacks Against Large Language Model
publication_link: https://arxiv.org/pdf/2310.04445 
year_published: 2023 
abstract_paper:It has been shown that Large Language Model (LLM) alignments can be circumvented by appending specially crafted attack suffixes with harmful queries to elicit harmful responses. To conduct attacks against private target models whose characterization is unknown, public models can be used as proxies to fashion the attack, with successful attacks being transferred from public proxies to private target models. The success rate of attack depends on how closely the proxy model approximates the private model. We hypothesize that for attacks to be transferrable, it is sufficient if the proxy can approximate the target model in the neighborhood of the harmful query. Therefore, in this paper, we propose \emph{Local Fine-Tuning (LoFT)}, \textit{i.e.}, fine-tuning proxy models on similar queries that lie in the lexico-semantic neighborhood of harmful queries to decrease the divergence between the proxy and target models. First, we demonstrate three approaches to prompt private target models to obtain similar queries given harmful queries. Next, we obtain data for local fine-tuning by eliciting responses from target models for the generated similar queries. Then, we optimize attack suffixes to generate attack prompts and evaluate the impact of our local fine-tuning on the attack's success rate. Experiments show that local fine-tuning of proxy models improves attack transferability and increases attack success rate by $39\%$, $7\%$, and $0.5\%$ (absolute) on target models ChatGPT, GPT-4, and Claude respectively.
isOpenAccess: True
TL\DR: Measurement of MPV in patients with T2D can be a useful and easily available prognostic marker, and hence assist clinicians to anticipate the occurrence of microvascular complications associated with the disease, especially in resource-poor settings, and reduce the burden of cost for the patient.
================================
faculty_name: Rita Singh
faculty_authorid: 2240446387
paper_id: 255bad49d29202e2d255926ab0983c125dcce835
paper_title: Evaluating Speech Synthesis by Training Recognizers on Synthetic Speech
publication_link: https://arxiv.org/pdf/2310.00706 
year_published: 2023 
abstract_paper:Modern speech synthesis systems have improved significantly, with synthetic speech being indistinguishable from real speech. However, efficient and holistic evaluation of synthetic speech still remains a significant challenge. Human evaluation using Mean Opinion Score (MOS) is ideal, but inefficient due to high costs. Therefore, researchers have developed auxiliary automatic metrics like Word Error Rate (WER) to measure intelligibility. Prior works focus on evaluating synthetic speech based on pre-trained speech recognition models, however, this can be limiting since this approach primarily measures speech intelligibility. In this paper, we propose an evaluation technique involving the training of an ASR model on synthetic speech and assessing its performance on real speech. Our main assumption is that by training the ASR model on the synthetic speech, the WER on real speech reflects the similarity between distributions, a broader assessment of synthetic speech quality beyond intelligibility. Our proposed metric demonstrates a strong correlation with both MOS naturalness and MOS intelligibility when compared to SpeechLMScore and MOSNet on three recent Text-to-Speech (TTS) systems: MQTTS, StyleTTS, and YourTTS.
isOpenAccess: True
TL\DR: This paper proposes an evaluation technique involving the training of an ASR model on synthetic speech and assessing its performance on real speech, and demonstrates a strong correlation with both MOS naturalness and MOS intelligibility when compared to SpeechLMScore and MosNet on three recent Text-to-Speech systems.
================================
faculty_name: Rita Singh
faculty_authorid: 2240446387
paper_id: 2a8f592c31d8de9906183b081095b9842025f792
paper_title: Rethinking Audiovisual Segmentation with Semantic Quantization and Decomposition
publication_link: https://arxiv.org/pdf/2310.00132 
year_published: 2023 
abstract_paper:Audiovisual segmentation (AVS) is a challenging task that aims to segment visual objects in videos based on their associated acoustic cues. With multiple sound sources involved, establishing robust correspondences between audio and visual contents poses unique challenges due to its (1) intricate entanglement across sound sources and (2) frequent shift among sound events. Assuming sound events occur independently, the multi-source semantic space (which encompasses all possible semantic categories) can be represented as the Cartesian product of single-source sub-spaces. This motivates us to decompose the multi-source audio semantics into single-source semantics, enabling more effective interaction with visual content. Specifically, we propose a semantic decomposition method based on product quantization, where the multi-source semantics can be decomposed and represented by several quantized single-source semantics. Furthermore, we introduce a global-to-local quantization mechanism, which distills knowledge from stable global (clip-level) features into local (frame-level) ones, to handle the constant shift of audio semantics. Extensive experiments demonstrate that semantically quantized and decomposed audio representation significantly improves AVS performance, e.g., +21.2% mIoU on the most challenging AVS-Semantic benchmark.
isOpenAccess: True
TL\DR: This paper proposes an evaluation technique involving the training of an ASR model on synthetic speech and assessing its performance on real speech, and demonstrates a strong correlation with both MOS naturalness and MOS intelligibility when compared to SpeechLMScore and MosNet on three recent Text-to-Speech systems.
================================
faculty_name: Rita Singh
faculty_authorid: 2240446387
paper_id: 37e8e07d3ecfa43a1e64d48202c73f597e6f9fee
paper_title: Towards Noise-Tolerant Speech-Referring Video Object Segmentation: Bridging Speech and Text
publication_link: https://aclanthology.org/2023.emnlp-main.140.pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: This paper proposes an evaluation technique involving the training of an ASR model on synthetic speech and assessing its performance on real speech, and demonstrates a strong correlation with both MOS naturalness and MOS intelligibility when compared to SpeechLMScore and MosNet on three recent Text-to-Speech systems.
================================
faculty_name: Rita Singh
faculty_authorid: 2240446387
paper_id: b7e2074934985b6112b6bce8c3680b14e621fdfe
paper_title: Importance of negative sampling in weak label learning
publication_link: https://arxiv.org/pdf/2309.13227 
year_published: 2023 
abstract_paper:Weak-label learning is a challenging task that requires learning from data"bags"containing positive and negative instances, but only the bag labels are known. The pool of negative instances is usually larger than positive instances, thus making selecting the most informative negative instance critical for performance. Such a selection strategy for negative instances from each bag is an open problem that has not been well studied for weak-label learning. In this paper, we study several sampling strategies that can measure the usefulness of negative instances for weak-label learning and select them accordingly. We test our method on CIFAR-10 and AudioSet datasets and show that it improves the weak-label classification performance and reduces the computational cost compared to random sampling methods. Our work reveals that negative instances are not all equally irrelevant, and selecting them wisely can benefit weak-label learning.
isOpenAccess: True
TL\DR: This paper proposes an evaluation technique involving the training of an ASR model on synthetic speech and assessing its performance on real speech, and demonstrates a strong correlation with both MOS naturalness and MOS intelligibility when compared to SpeechLMScore and MosNet on three recent Text-to-Speech systems.
================================
faculty_name: Rita Singh
faculty_authorid: 2240446387
paper_id: d7911ff6f80bd9f053ef8d304f15791f510f5cda
paper_title: Completing Visual Objects via Bridging Generation and Segmentation
publication_link: https://arxiv.org/pdf/2310.00808 
year_published: 2023 
abstract_paper:This paper presents a novel approach to object completion, with the primary goal of reconstructing a complete object from its partially visible components. Our method, named MaskComp, delineates the completion process through iterative stages of generation and segmentation. In each iteration, the object mask is provided as an additional condition to boost image generation, and, in return, the generated images can lead to a more accurate mask by fusing the segmentation of images. We demonstrate that the combination of one generation and one segmentation stage effectively functions as a mask denoiser. Through alternation between the generation and segmentation stages, the partial object mask is progressively refined, providing precise shape guidance and yielding superior object completion results. Our experiments demonstrate the superiority of MaskComp over existing approaches, e.g., ControlNet and Stable Diffusion, establishing it as an effective solution for object completion.
isOpenAccess: True
TL\DR: The method, named MaskComp, delineates the completion process through iterative stages of generation and segmentation, and demonstrates that the combination of one generation and one segmentation stage effectively functions as a mask denoiser.
================================
faculty_name: Rita Singh
faculty_authorid: 2240446387
paper_id: e2572e0adacfb116b19b25691e7f6b3749490a88
paper_title: Training Audio Captioning Models without Audio
publication_link: https://arxiv.org/pdf/2309.07372 
year_published: 2023 
abstract_paper:Automated Audio Captioning (AAC) is the task of generating natural language descriptions given an audio stream. A typical AAC system requires manually curated training data of audio segments and corresponding text caption annotations. The creation of these audio-caption pairs is costly, resulting in general data scarcity for the task. In this work, we address this major limitation and propose an approach to train AAC systems using only text. Our approach leverages the multimodal space of contrastively trained audio-text models, such as CLAP. During training, a decoder generates captions conditioned on the pretrained CLAP text encoder. During inference, the text encoder is replaced with the pretrained CLAP audio encoder. To bridge the modality gap between text and audio embeddings, we propose the use of noise injection or a learnable adapter, during training. We find that the proposed text-only framework performs competitively with state-of-the-art models trained with paired audio, showing that efficient text-to-audio transfer is possible. Finally, we showcase both stylized audio captioning and caption enrichment while training without audio or human-created text captions.
isOpenAccess: True
TL\DR: The method, named MaskComp, delineates the completion process through iterative stages of generation and segmentation, and demonstrates that the combination of one generation and one segmentation stage effectively functions as a mask denoiser.
================================
faculty_name: Rita Singh
faculty_authorid: 2240446387
paper_id: f5b88ca9d74e8ddc679adcd07a292bd8481062fa
paper_title: Prompting Audios Using Acoustic Properties For Emotion Representation
publication_link: https://arxiv.org/pdf/2310.02298 
year_published: 2023 
abstract_paper:Emotions lie on a continuum, but current models treat emotions as a finite valued discrete variable. This representation does not capture the diversity in the expression of emotion. To better represent emotions we propose the use of natural language descriptions (or prompts). In this work, we address the challenge of automatically generating these prompts and training a model to better learn emotion representations from audio and prompt pairs. We use acoustic properties that are correlated to emotion like pitch, intensity, speech rate, and articulation rate to automatically generate prompts i.e. 'acoustic prompts'. We use a contrastive learning objective to map speech to their respective acoustic prompts. We evaluate our model on Emotion Audio Retrieval and Speech Emotion Recognition. Our results show that the acoustic prompts significantly improve the model's performance in EAR, in various Precision@K metrics. In SER, we observe a 3.8% relative accuracy improvement on the Ravdess dataset.
isOpenAccess: True
TL\DR: The method, named MaskComp, delineates the completion process through iterative stages of generation and segmentation, and demonstrates that the combination of one generation and one segmentation stage effectively functions as a mask denoiser.
================================
faculty_name: Rita Singh
faculty_authorid: 2240446387
paper_id: f969f059b01be02f9995396b6cc397959b574635
paper_title: Pairwise Similarity Learning is SimPLE
publication_link: https://arxiv.org/pdf/2310.09449 
year_published: 2023 
abstract_paper:In this paper, we focus on a general yet important learning problem, pairwise similarity learning (PSL). PSL subsumes a wide range of important applications, such as open-set face recognition, speaker verification, image retrieval and person re-identification. The goal of PSL is to learn a pairwise similarity function assigning a higher similarity score to positive pairs (i.e., a pair of samples with the same label) than to negative pairs (i.e., a pair of samples with different label). We start by identifying a key desideratum for PSL, and then discuss how existing methods can achieve this desideratum. We then propose a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition. We apply the proposed method to three challenging PSL tasks: open-set face recognition, image retrieval and speaker verification. Comprehensive experimental results on large-scale benchmarks show that our method performs significantly better than current state-of-the-art methods. Our project page is available at simple.is.tue.mpg.de.
isOpenAccess: True
TL\DR: This work identifies a key desideratum for PSL, and proposes a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition.
================================
faculty_name: Rita Singh
faculty_authorid: 2236887676
paper_id: 7ce9a6ad52408b9ab0113d0ae9b413585fe2accc
paper_title: Effect of myo-inositol and di-chiro inositol plus vitamin D supplementation during pregnancy on prevention of gestational diabetes: a multi-centric, prospective, randomized, double-blind clinical trial
publication_link: https://www.ijrcog.org/index.php/ijrcog/article/download/13237/8254 
year_published: 2023 
abstract_paper:Background: Aim of study was to evaluate the impact of myoinositol and D-chiro inositol plus vitamin D supplementation on the prevention of gestational diabetes mellitus (GDM) in pregnant women.
Methods: In the multi-centric, prospective, randomised, double-blind clinical trial, either vitamin D alone (group I) or myoinositol and D-chiro inositol plus Vitamin D (group II) were administered to pregnant women from 12 weeks of gestation. The administration was continued until delivery to primigravids who were normoglycemic at 12 weeks of gestation and consented. From October 2018 to December 2019. A total of 1250 women were enrolled, and randomly allocated to either of the groups: 630 women in Group I and 620 in Group II. The allocation was blinded. The primary outcome was the rate of GDM as assessed by oral glucose tolerance test (OGTT) recommended by diabetes in pregnancy Study Group India (DIPSI), International Federation of Gynecology and Obstetrics (FIGO) and the Government of India, at first antenatal visit followed by at weeks 24 to 28 in both the groups.
Results: The rate of GDM was found more in group I as compared to group II treated with myoinositol and D-chiro Inositol plus vitamin D, but the difference was not statistically significant (5.08% in group I and 3.22% in group II).
Conclusions: In conclusion, an improved trend has been noticed in the reduction of the rate of GDM with myoinositol and D-chiro inositol plus vitamin D as compared to vitamin D alone. Myoinositol and D-chiro inositol plus vitamin D supplementation may be a good option for pregnant women to prevent the GDM occurrence especially in women having positive risk factors for GDM.
 
isOpenAccess: True
TL\DR: This work identifies a key desideratum for PSL, and proposes a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition.
================================
faculty_name: Rita Singh
faculty_authorid: 2256938240
paper_id: 49e173279a64a1e6b849cbfcd002cf3f0dbb1948
paper_title: Plant-Avian Frugivory in the Urban Ecosystem of Delhi
publication_link: https://doi.org/10.53550/eec.2023.v29i04s.026 
year_published: 2023 
abstract_paper:Plant-frugivore interactions are important ecological processes that play a vital role in maintaining the dynamics of the ecosystem. Birds are very important frugivores and very little is known about the plant-avian interaction matrix in the urban ecosystems of India. The present study endeavours to understand and document the plant–avian frugivory interactions in the human-dominated green spaces which is a mosaic of selectively planted exotic and native tree species in Delhi. A total of thirty avian frugivore species were recorded feeding on twenty-two focal tree species using phyto-centric approach. Characteristic traits of fruits like fruit diameter, colour and type and their interacting avian species were studied based on their fruit handling behaviour. The highest number of avian frugivore species were observed on native Ficus tree species in urban Delhi ecosystem, thereby providing evident proof of being an important food resource for avian disperser communities. The study suggests to introduce more native fig tree species in the city plantations to enhance and sustain the avian diversity in the novel fragmented urban ecosystems.
isOpenAccess: True
TL\DR: This work identifies a key desideratum for PSL, and proposes a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition.
================================
faculty_name: Rita Singh
faculty_authorid: 2248392964
paper_id: fcddb888f01eae5c5530b2d1533d6064f207ea2b
paper_title: Gonadotropin Receptor Cross-Talk and Altered Functions in Gonadal and Non-Gonadal Tissues
publication_link: https://informaticsjournals.com/index.php/jer/article/download/34991/22766 
year_published: 2023 
abstract_paper:Reproduction depends on the responses of gonadotropins through their specific receptors. The gonadotropin family has three members; Follicle Stimulating Hormone (FSH), Luteinizing Hormone (LH), and Human Chorionic Gonadotropin (hCG). These glycoprotein hormones comprise two subunits, an identical α-subunit and a hormone-specific-β subunit. Their cognate receptors (FSHR and LHCGR) are two adrenergic receptor-like family A/rhodopsin-like G-Protein Coupled Receptors (GPCRs) with structurally distinct ligand binding domains. The hCG binds to LHCGR but has a longer half-life and higher affinity to LHCGR. The expression of FSHR and LHCGR is observed in both gonadal and nongonadal cells. In this review, we will be emphasizing the differential expression of gonadotropin receptors in different cells of the human body, their specific responses through cross-talk, and how a defect in the expression and activity of FSHR and LHCGR may alter the responses of FSH and LH/hCG leading to diseases like PCOS, cancer and metabolic disorders.
isOpenAccess: True
TL\DR: This work identifies a key desideratum for PSL, and proposes a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition.
================================
faculty_name: Rita Singh
faculty_authorid: 2167047722
paper_id: 47b70ad4c09a3195d24f926279afd5f35badbe86
paper_title: Comparison of freeze-thaw and sonication cycle-based methods for extracting AMR-associated metabolites from Staphylococcus aureus
publication_link: https://www.frontiersin.org/articles/10.3389/fmicb.2023.1152162/pdf 
year_published: 2023 
abstract_paper:Emerging antimicrobial resistance (AMR) among Gram-positive pathogens, specifically in Staphylococcus aureus (S. aureus), is becoming a leading public health concern demanding effective therapeutics. Metabolite modulation can improve the efficacy of existing antibiotics and facilitate the development of effective therapeutics. However, it remained unexplored for drug-resistant S. aureus (gentamicin and methicillin-resistant), primarily due to the dearth of optimal metabolite extraction protocols including a protocol for AMR-associated metabolites. Therefore, in this investigation, we have compared the performance of the two most widely used methods, i.e., freeze-thaw cycle (FTC) and sonication cycle (SC), alone and in combination (FTC + SC), and identified the optimal method for this purpose. A total of 116, 119, and 99 metabolites were identified using the FTC, SC, and FTC + SC methods, respectively, leading to the identification of 163 metabolites cumulatively. Out of 163, 69 metabolites were found to be associated with AMR in published literature consisting of the highest number of metabolites identified by FTC (57) followed by SC (54) and FTC + SC (40). Thus, the performances of FTC and SC methods were comparable with no additional benefits of combining both. Moreover, each method showed biasness toward specific metabolite(s) or class of metabolites, suggesting that the choice of metabolite extraction method shall be decided based on the metabolites of interest in the investigation.
isOpenAccess: True
TL\DR: The performances of FTC and SC methods were comparable with no additional benefits of combining both, and each method showed biasness toward specific metabolite(s) or class of metabolites, suggesting that the choice of metabolite extraction method shall be decided based on the metabolites of interest in the investigation.
================================
faculty_name: Rita Singh
faculty_authorid: 2267017786
paper_id: 8aac453851c7b6178e2aea7c4d53f070380c25e2
paper_title: APPLIED ASPECT OF SATVAVAJAYA CHIKITSA
publication_link: https://doi.org/10.46607/iamj2011112023 
year_published: 2023 
abstract_paper:The human being is a tripod having three pillars, Satva (mind), Atma (soul) and Sharira (body). Here, Satva is a connecting link between Atma and Sharira, which is otherwise called Manas. It has an immense influence on the health and ill health of the individual. ‘Prasanna’ Manah is a sign of a healthy life. 
In Ayurvedic contexts, Chikitsa is classified into two parts based on resources (Vyapashraya Bheden): 1. Daivvyapashray Chikitsa 2. Yuktivyapashray Chikitsa. Daivvyapashray Chikitsa refers to Mantra, Ausadhi, Mani, Mangala, Bali, Upahara, Home, Niyam, Prayashchita, Upvasa, Swastyayanapatha, Pranipata, Gamana etc. Yuktivyapashrya Chikitsa refers to Samsodhana (Vamanadi) and Upshamana (Pachanadi). In another context, Acharya Charak and Acharya Vagbhat explained Trividham Ausdham as; 1. Daivvyapashray Chikitsa, 2. Yuktivyapashrya Chikitsa 3. Satvavajaya Chikitsa. Their Satvavajaya Chikitsa further explained, "Aiming to control the mind or is a method of restraining the mind from unwholesome objects.” Satvavajaya Chikitsa is that typical Ayurvedic approach that prevents the impaired Dhi, Dhriti and Smriti and brings them back to a normal state. Hence, it plays a significant role in maintaining a harmonious state between these three factors, ultimately leading to a happy and healthy state of the individual.
isOpenAccess: True
TL\DR: The performances of FTC and SC methods were comparable with no additional benefits of combining both, and each method showed biasness toward specific metabolite(s) or class of metabolites, suggesting that the choice of metabolite extraction method shall be decided based on the metabolites of interest in the investigation.
================================
faculty_name: Rita Singh
faculty_authorid: 2109454768
paper_id: 45b7d6e09d11e496e941481056177cf0164b5278
paper_title: GPT-Sentinel: Distinguishing Human and ChatGPT Generated Content
publication_link: http://arxiv.org/pdf/2305.07969 
year_published: 2023 
abstract_paper:This paper presents a novel approach for detecting ChatGPT-generated vs. human-written text using language models. To this end, we first collected and released a pre-processed dataset named OpenGPTText, which consists of rephrased content generated using ChatGPT. We then designed, implemented, and trained two different models for text classification, using Robustly Optimized BERT Pretraining Approach (RoBERTa) and Text-to-Text Transfer Transformer (T5), respectively. Our models achieved remarkable results, with an accuracy of over 97% on the test dataset, as evaluated through various metrics. Furthermore, we conducted an interpretability study to showcase our model's ability to extract and differentiate key features between human-written and ChatGPT-generated text. Our findings provide important insights into the effective use of language models to detect generated text.
isOpenAccess: True
TL\DR: The performances of FTC and SC methods were comparable with no additional benefits of combining both, and each method showed biasness toward specific metabolite(s) or class of metabolites, suggesting that the choice of metabolite extraction method shall be decided based on the metabolites of interest in the investigation.
================================
faculty_name: Rita Singh
faculty_authorid: 2109454768
paper_id: 7a25aa397ae2a7f82df87a936ce6ff7f03b7ac4c
paper_title: Token Prediction as Implicit Classification to Identify LLM-Generated Text
publication_link: https://aclanthology.org/2023.emnlp-main.810.pdf 
year_published: 2023 
abstract_paper:This paper introduces a novel approach for identifying the possible large language models (LLMs) involved in text generation. Instead of adding an additional classification layer to a base LM, we reframe the classification task as a next-token prediction task and directly fine-tune the base LM to perform it. We utilize the Text-to-Text Transfer Transformer (T5) model as the backbone for our experiments. We compared our approach to the more direct approach of utilizing hidden states for classification. Evaluation shows the exceptional performance of our method in the text classification task, highlighting its simplicity and efficiency. Furthermore, interpretability studies on the features extracted by our model reveal its ability to differentiate distinctive writing styles among various LLMs even in the absence of an explicit classifier. We also collected a dataset named OpenLLMText, containing approximately 340k text samples from human and LLMs, including GPT3.5, PaLM, LLaMA, and GPT2.
isOpenAccess: True
TL\DR: Evaluation shows the exceptional performance of the method in the text classification task, highlighting its simplicity and efficiency, and interpretability studies on the features extracted by the model reveal its ability to differentiate distinctive writing styles among various LLMs even in the absence of an explicit classifier.
================================
faculty_name: Rita Singh
faculty_authorid: 153915824
paper_id: 3bd320ddb25886417ae90011b00f13f5d558097b
paper_title: BASS: Block-wise Adaptation for Speech Summarization
publication_link: https://arxiv.org/pdf/2307.08217 
year_published: 2023 
abstract_paper:End-to-end speech summarization has been shown to improve performance over cascade baselines. However, such models are difficult to train on very large inputs (dozens of minutes or hours) owing to compute restrictions and are hence trained with truncated model inputs. Truncation leads to poorer models, and a solution to this problem rests in block-wise modeling, i.e., processing a portion of the input frames at a time. In this paper, we develop a method that allows one to train summarization models on very long sequences in an incremental manner. Speech summarization is realized as a streaming process, where hypothesis summaries are updated every block based on new acoustic information. We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.
isOpenAccess: True
TL\DR: Evaluation shows the exceptional performance of the method in the text classification task, highlighting its simplicity and efficiency, and interpretability studies on the features extracted by the model reveal its ability to differentiate distinctive writing styles among various LLMs even in the absence of an explicit classifier.
================================
faculty_name: Rita Singh
faculty_authorid: 153915824
paper_id: 5a3307b2e64bbcaff1202e261b8a83f7d03418a8
paper_title: Rethinking Voice-Face Correlation: A Geometry View
publication_link: https://arxiv.org/pdf/2307.13948 
year_published: 2023 
abstract_paper:Previous works on voice-face matching and voice-guided face synthesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emotion. In this paper, we aim to investigate the capability of reconstructing the 3D facial shape from voice from a geometry perspective without any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face correlation and can serve as a good empirical study for anthropometry science.
isOpenAccess: True
TL\DR: This work proposes a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction and finds significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium.
================================
faculty_name: Rita Singh
faculty_authorid: 153915824
paper_id: 63a4150c9ad87c003de43b32828c8ceec6bb4468
paper_title: A Gene-Based Algorithm for Identifying Factors That May Affect a Speaker’s Voice
publication_link: https://www.mdpi.com/1099-4300/25/6/897/pdf?version=1685718244 
year_published: 2023 
abstract_paper:Over the past decades, many machine-learning- and artificial-intelligence-based technologies have been created to deduce biometric or bio-relevant parameters of speakers from their voice. These voice profiling technologies have targeted a wide range of parameters, from diseases to environmental factors, based largely on the fact that they are known to influence voice. Recently, some have also explored the prediction of parameters whose influence on voice is not easily observable through data-opportunistic biomarker discovery techniques. However, given the enormous range of factors that can possibly influence voice, more informed methods for selecting those that may be potentially deducible from voice are needed. To this end, this paper proposes a simple path-finding algorithm that attempts to find links between vocal characteristics and perturbing factors using cytogenetic and genomic data. The links represent reasonable selection criteria for use by computational by profiling technologies only, and are not intended to establish any unknown biological facts. The proposed algorithm is validated using a simple example from medical literature—that of the clinically observed effects of specific chromosomal microdeletion syndromes on the vocal characteristics of affected people. In this example, the algorithm attempts to link the genes involved in these syndromes to a single example gene (FOXP2) that is known to play a broad role in voice production. We show that in cases where strong links are exposed, vocal characteristics of the patients are indeed reported to be correspondingly affected. Validation experiments and subsequent analyses confirm that the methodology could be potentially useful in predicting the existence of vocal signatures in naïve cases where their existence has not been otherwise observed.
isOpenAccess: True
TL\DR: This work proposes a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction and finds significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium.
================================
faculty_name: Rita Singh
faculty_authorid: 153915824
paper_id: 721b39472c801124b5e3102edffe9d6f0754e1c2
paper_title: Deriving Vocal Fold Oscillation Information from Recorded Voice Signals Using Models of Phonation
publication_link: https://www.mdpi.com/1099-4300/25/7/1039/pdf?version=1689132568 
year_published: 2023 
abstract_paper:During phonation, the vocal folds exhibit a self-sustained oscillatory motion, which is influenced by the physical properties of the speaker’s vocal folds and driven by the balance of bio-mechanical and aerodynamic forces across the glottis. Subtle changes in the speaker’s physical state can affect voice production and alter these oscillatory patterns. Measuring these can be valuable in developing computational tools that analyze voice to infer the speaker’s state. Traditionally, vocal fold oscillations (VFOs) are measured directly using physical devices in clinical settings. In this paper, we propose a novel analysis-by-synthesis approach that allows us to infer the VFOs directly from recorded speech signals on an individualized, speaker-by-speaker basis. The approach, called the ADLES-VFT algorithm, is proposed in the context of a joint model that combines a phonation model (with a glottal flow waveform as the output) and a vocal tract acoustic wave propagation model such that the output of the joint model is an estimated waveform. The ADLES-VFT algorithm is a forward-backward algorithm which minimizes the error between the recorded waveform and the output of this joint model to estimate its parameters. Once estimated, these parameter values are used in conjunction with a phonation model to obtain its solutions. Since the parameters correlate with the physical properties of the vocal folds of the speaker, model solutions obtained using them represent the individualized VFOs for each speaker. The approach is flexible and can be applied to various phonation models. In addition to presenting the methodology, we show how the VFOs can be quantified from a dynamical systems perspective for classification purposes. Mathematical derivations are provided in an appendix for better readability.
isOpenAccess: True
TL\DR: A novel analysis-by-synthesis approach that allows us to infer the VFOs directly from recorded speech signals on an individualized, speaker- by-speaker basis is proposed and it is shown how the V FOs can be quantified from a dynamical systems perspective for classification purposes.
================================
faculty_name: Rita Singh
faculty_authorid: 153915824
paper_id: 8665c864d71df1e918d2010778fc06712f4e5550
paper_title: Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations
publication_link: https://arxiv.org/pdf/2305.12715 
year_published: 2023 
abstract_paper:Learning with reduced labeling standards, such as noisy label, partial label, and multiple label candidates, which we generically refer to as \textit{imprecise} labels, is a commonplace challenge in machine learning tasks. Previous methods tend to propose specific designs for every emerging imprecise label configuration, which is usually unsustainable when multiple configurations of imprecision coexist. In this paper, we introduce imprecise label learning (ILL), a framework for the unification of learning with various imprecise label configurations. ILL leverages expectation-maximization (EM) for modeling the imprecise label information, treating the precise labels as latent variables.Instead of approximating the correct labels for training, it considers the entire distribution of all possible labeling entailed by the imprecise information. We demonstrate that ILL can seamlessly adapt to partial label learning, semi-supervised learning, noisy label learning, and, more importantly, a mixture of these settings. Notably, ILL surpasses the existing specified techniques for handling imprecise labels, marking the first unified framework with robust and effective performance across various challenging settings. We hope our work will inspire further research on this topic, unleashing the full potential of ILL in wider scenarios where precise labels are expensive and complicated to obtain.
isOpenAccess: True
TL\DR: Imprecise label learning (ILL) is introduced, a framework for the unification of learning with various imprecise label configurations, marking the first unified framework with robust and effective performance across various challenging settings.
================================
faculty_name: Rita Singh
faculty_authorid: 153915824
paper_id: a6e3a10a6286967413e3406374bbeea533640030
paper_title: The Hidden Dance of Phonemes and Visage: Unveiling the Enigmatic Link between Phonemes and Facial Features
publication_link: https://arxiv.org/pdf/2307.13953 
year_published: 2023 
abstract_paper:This work unveils the enigmatic link between phonemes and facial features. Traditional studies on voice-face correlations typically involve using a long period of voice input, including generating face images from voices and reconstructing 3D face meshes from voices. However, in situations like voice-based crimes, the available voice evidence may be short and limited. Additionally, from a physiological perspective, each segment of speech -- phoneme -- corresponds to different types of airflow and movements in the face. Therefore, it is advantageous to discover the hidden link between phonemes and face attributes. In this paper, we propose an analysis pipeline to help us explore the voice-face relationship in a fine-grained manner, i.e., phonemes v.s. facial anthropometric measurements (AM). We build an estimator for each phoneme-AM pair and evaluate the correlation through hypothesis testing. Our results indicate that AMs are more predictable from vowels compared to consonants, particularly with plosives. Additionally, we observe that if a specific AM exhibits more movement during phoneme pronunciation, it is more predictable. Our findings support those in physiology regarding correlation and lay the groundwork for future research on speech-face multimodal learning.
isOpenAccess: True
TL\DR: Imprecise label learning (ILL) is introduced, a framework for the unification of learning with various imprecise label configurations, marking the first unified framework with robust and effective performance across various challenging settings.
================================
faculty_name: Rita Singh
faculty_authorid: 153915824
paper_id: ad22af138fa1d1490cda0301abf8159a7c30c5a2
paper_title: Pengi: An Audio Language Model for Audio Tasks
publication_link: http://arxiv.org/pdf/2305.11834 
year_published: 2023 
abstract_paper:In the domain of audio processing, Transfer Learning has facilitated the rise of Self-Supervised Learning and Zero-Shot Learning techniques. These approaches have led to the development of versatile models capable of tackling a wide array of tasks, while delivering state-of-the-art performance. However, current models inherently lack the capacity to produce the requisite language for open-ended tasks, such as Audio Captioning or Audio Question&Answering. We introduce Pengi, a novel Audio Language Model that leverages Transfer Learning by framing all audio tasks as text-generation tasks. It takes as input, an audio recording, and text, and generates free-form text as output. The input audio is represented as a sequence of continuous embeddings by an audio encoder. A text encoder does the same for the corresponding text input. Both sequences are combined as a prefix to prompt a pre-trained frozen language model. The unified architecture of Pengi enables open-ended tasks and close-ended tasks without any additional fine-tuning or task-specific extensions. When evaluated on 22 downstream tasks, our approach yields state-of-the-art performance in several of them. Our results show that connecting language models with audio models is a major step towards general-purpose audio understanding
isOpenAccess: True
TL\DR: Imprecise label learning (ILL) is introduced, a framework for the unification of learning with various imprecise label configurations, marking the first unified framework with robust and effective performance across various challenging settings.
================================
faculty_name: Rita Singh
faculty_authorid: 2443208
paper_id: 7de69ba0381aa265803b79ccaedf247d266d19ab
paper_title: Utilization of the Whole Cowpea Pod and Barley Husk in The Production of Nutritionally Enriched Composite Flour
publication_link: https://arccarticles.s3.amazonaws.com/OnlinePublish/Final-article-attachemnt-with-doi-DR-1986-6089603e9087340b9bdcbbb1.pdf 
year_published: 2023 
abstract_paper:Background: Cowpea is a climbing annual crop from Fabaceae family which is grown for its edible seeds and pods. Cowpea is rich in various nutrients such as fibre, protein, iron, potassium and is low in fat and calories. It has been observed that non-Communicable diseases are increasing at a rapid rate in India as well as globally. The need of the hour is to control the rate of diseases through modification in dietary practices. This study has focused on formulation of whole cowpea pod enriched composite flour by including more fibre and various nutrients in the diet. Methods: In the study, composite flour using whole cowpea pod flour, barley husk flour and whole wheat flour was developed. The nutritional characteristics of composite flour and barley husk were analyzed. Storage study with two different packaging materials was also done. Result: The composite flour was found to have good nutritional properties as it contained valuable amount of protein, energy and crude fibre. It was also found that the flour had higher content of iron, magnesium and calcium while barley husk had higher content of manganese. Laminated aluminium pouches found to be more suitable for use as a packaging material.

isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Emma Strubell
faculty_authorid: 2268272
paper_id: 1433b8d43d446fcc7f3e1370b22f744a4dd7c8e4
paper_title: To Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing
publication_link: https://arxiv.org/pdf/2310.07715 
year_published: 2023 
abstract_paper:NLP is in a period of disruptive change that is impacting our methodologies, funding sources, and public perception. In this work, we seek to understand how to shape our future by better understanding our past. We study factors that shape NLP as a field, including culture, incentives, and infrastructure by conducting long-form interviews with 26 NLP researchers of varying seniority, research area, institution, and social identity. Our interviewees identify cyclical patterns in the field, as well as new shifts without historical parallel, including changes in benchmark culture and software infrastructure. We complement this discussion with quantitative analysis of citation, authorship, and language use in the ACL Anthology over time. We conclude by discussing shared visions, concerns, and hopes for the future of NLP. We hope that this study of our field's past and present can prompt informed discussion of our community's implicit norms and more deliberate action to consciously shape the future.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Emma Strubell
faculty_authorid: 2268272
paper_id: 45e50baac4d341f0cf1a40af096bfa9c3f555235
paper_title: Understanding the Effect of Model Compression on Social Bias in Large Language Models
publication_link: https://aclanthology.org/2023.emnlp-main.161.pdf 
year_published: 2023 
abstract_paper:Large Language Models (LLMs) trained with self-supervision on vast corpora of web text fit to the social biases of that text. Without intervention, these social biases persist in the model's predictions in downstream tasks, leading to representational harm. Many strategies have been proposed to mitigate the effects of inappropriate social biases learned during pretraining. Simultaneously, methods for model compression have become increasingly popular to reduce the computational burden of LLMs. Despite the popularity and need for both approaches, little work has been done to explore the interplay between these two. We perform a carefully controlled study of the impact of model compression via quantization and knowledge distillation on measures of social bias in LLMs. Longer pretraining and larger models led to higher social bias, and quantization showed a regularizer effect with its best trade-off around 20% of the original pretraining time.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Emma Strubell
faculty_authorid: 2268272
paper_id: 667ba2e8f1933b6c32e9672012526904b4c5dc31
paper_title: Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research
publication_link: http://arxiv.org/pdf/2306.16900 
year_published: 2023 
abstract_paper:Many recent improvements in NLP stem from the development and use of large pre-trained language models (PLMs) with billions of parameters. Large model sizes makes computational cost one of the main limiting factors for training and evaluating such models; and has raised severe concerns about the sustainability, reproducibility, and inclusiveness for researching PLMs. These concerns are often based on personal experiences and observations. However, there had not been any large-scale surveys that investigate them. In this work, we provide a first attempt to quantify these concerns regarding three topics, namely, environmental impact, equity, and impact on peer reviewing. By conducting a survey with 312 participants from the NLP community, we capture existing (dis)parities between different and within groups with respect to seniority, academia, and industry; and their impact on the peer reviewing process. For each topic, we provide an analysis and devise recommendations to mitigate found disparities, some of which already successfully implemented. Finally, we discuss additional concerns raised by many participants in free-text responses.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Emma Strubell
faculty_authorid: 2268272
paper_id: 71debf888acd57bb1baa4c146f31e58c66ea51af
paper_title: On the Interactions of Structural Constraints and Data Resources for Structured Prediction
publication_link: https://aclanthology.org/2023.sustainlp-1.10.pdf 
year_published: 2023 
abstract_paper:,
isOpenAccess: True
TL\DR: None
================================
faculty_name: Emma Strubell
faculty_authorid: 2268272
paper_id: 84d20ad9f42d80dfd5130a6362d5422be8a6bdc3
paper_title: Efficiency Pentathlon: A Standardized Arena for Efficiency Evaluation
publication_link: https://arxiv.org/pdf/2307.09701 
year_published: 2023 
abstract_paper:Rising computational demands of modern natural language processing (NLP) systems have increased the barrier to entry for cutting-edge research while posing serious environmental concerns. Yet, progress on model efficiency has been impeded by practical challenges in model evaluation and comparison. For example, hardware is challenging to control due to disparate levels of accessibility across different institutions. Moreover, improvements in metrics such as FLOPs often fail to translate to progress in real-world applications. In response, we introduce Pentathlon, a benchmark for holistic and realistic evaluation of model efficiency. Pentathlon focuses on inference, which accounts for a majority of the compute in a model's lifecycle. It offers a strictly-controlled hardware platform, and is designed to mirror real-world applications scenarios. It incorporates a suite of metrics that target different aspects of efficiency, including latency, throughput, memory overhead, and energy consumption. Pentathlon also comes with a software library that can be seamlessly integrated into any codebase and enable evaluation. As a standardized and centralized evaluation platform, Pentathlon can drastically reduce the workload to make fair and reproducible efficiency comparisons. While initially focused on natural language processing (NLP) models, Pentathlon is designed to allow flexible extension to other fields. We envision Pentathlon will stimulate algorithmic innovations in building efficient models, and foster an increased awareness of the social and environmental implications in the development of future-generation NLP models.
isOpenAccess: True
TL\DR: None
================================
faculty_name: Emma Strubell
faculty_authorid: 2268272
paper_id: 88549b4f48b9709acdfb8b9e41656b6d133c5390
paper_title: Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models
publication_link: http://arxiv.org/pdf/2307.00101 
year_published: 2023 
abstract_paper:Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.
isOpenAccess: True
TL\DR: It is shown that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.
================================
faculty_name: Emma Strubell
faculty_authorid: 2268272
paper_id: a815c3209e7baff4466dbf6e129129511f842b7e
paper_title: Making Scalable Meta Learning Practical
publication_link: https://arxiv.org/pdf/2310.05674 
year_published: 2023 
abstract_paper:Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.
isOpenAccess: True
TL\DR: SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients.
================================
faculty_name: Emma Strubell
faculty_authorid: 2268272
paper_id: b13da1161d65a8de7a96051b5bc68d5eaa8eb37b
paper_title: Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints
publication_link: http://arxiv.org/pdf/2305.00131 
year_published: 2023 
abstract_paper:Self-training based on pseudo-labels has emerged as a dominant approach for addressing conditional distribution shifts in unsupervised domain adaptation (UDA) for semantic segmentation problems. A notable drawback, however, is that this family of approaches is susceptible to erroneous pseudo labels that arise from confirmation biases in the source domain and that manifest as nuisance factors in the target domain. A possible source for this mismatch is the reliance on only photometric cues provided by RGB image inputs, which may ultimately lead to sub-optimal adaptation. To mitigate the effect of mismatched pseudo-labels, we propose to incorporate structural cues from auxiliary modalities, such as depth, to regularise conventional self-training objectives. Specifically, we introduce a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart. To obtain object regions consistent with the true underlying object, we extract information from both depth maps and RGB-images in the form of multimodal clustering. Crucially, the objectness constraint is agnostic to the ground-truth semantic labels and, hence, appropriate for unsupervised domain adaptation. In this work, we show that our regularizer significantly improves top performing self-training methods (by up to $2$ points) in various UDA benchmarks for semantic segmentation. We include all code in the supplementary.
isOpenAccess: True
TL\DR: The regularizer significantly improves top performing self-training methods in various UDA benchmarks for semantic segmentation and introduces a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart.
================================
faculty_name: Emma Strubell
faculty_authorid: 2268272
paper_id: b777aa86b5a1d49ce8eababc5c2ee56d3562801e
paper_title: The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment
publication_link: http://arxiv.org/pdf/2302.06117 
year_published: 2023 
abstract_paper:Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.
isOpenAccess: True
TL\DR: This work examines the effects of model design decisions, framework paradigms, and hardware platforms on total model latency through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency.
================================
faculty_name: Emma Strubell
faculty_authorid: 2268272
paper_id: ba31ccac5fe5ea151727e8427e78bb300c35f899
paper_title: Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training
publication_link: http://arxiv.org/pdf/2305.12634 
year_published: 2023 
abstract_paper:In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model's automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.
isOpenAccess: True
TL\DR: This work examines the effects of model design decisions, framework paradigms, and hardware platforms on total model latency through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency.
================================
faculty_name: Alexander Waibel
faculty_authorid: 2064429921
paper_id: aab2ed83bc3739a20e90ae1d97dcf45f3bc8e508
paper_title: AdapITN: A Fast, Reliable, and Dynamic Adaptive Inverse Text Normalization
publication_link: Not given 
year_published: 2023 
abstract_paper:Inverse text normalization (ITN) is the task that transforms text in spoken-form into written-form. While automatic speech recognition (ASR) produces text in spoken-form, human and natural language understanding systems prefer to consume text in written-form. ITN generally deals with semiotic phrases (e.g., numbers, date, time). However, lack of studies to deal with phonetization phrases, which is ASR’s output when it handles unseen data (e.g., foreign-named entities, domain names), although these exist in the same form in the spoken-form text. The reason is that phonetization phrases are infinite patterns and language-dependent. In this study, we introduce a novel end2end model that can handle both semiotic phrases (SEP) and phonetization phrases (PHP), named AdapITN. We call it "Adap" because it allows for handling unseen PHP. The model performs only when necessary by providing a mechanism to narrow normalized regions and external query knowledge, reducing the runtime significantly.
isOpenAccess: True
TL\DR: A novel end2end model that can handle both semiotic phrases (SEP) and phonetization phrases (PHP), named AdapITN is introduced, named "Adap" because it allows for handling unseen PHP.
================================
faculty_name: Alexander Waibel
faculty_authorid: 2064429921
paper_id: f3e237e794bc4cd8df7f3e31d0caa2f7ee8cd06b
paper_title: Train Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages
publication_link: http://arxiv.org/pdf/2305.03873 
year_published: 2023 
abstract_paper:In many humanitarian scenarios, translation into severely low resource languages often does not require a universal translation engine, but a dedicated text-specific translation engine. For example, healthcare records, hygienic procedures, government communication, emergency procedures and religious texts are all limited texts. While generic translation engines for all languages do not exist, translation of multilingually known limited texts into new, endangered languages may be possible and reduce human translation effort. We attempt to leverage translation resources from rich resource languages to efficiently produce best possible translation quality for well known texts, which is available in multiple languages, in a new, severely low resource language. We examine two approaches: 1.) best selection of seed sentences to jump start translations in a new language in view of best generalization to the remainder of a larger targeted text(s), and 2.) we adapt large general multilingual translation engines from many other languages to focus on a specific text in a new, unknown language. We find that adapting large pretrained multilingual models to the domain/text first and then to the severely low resource language works best. If we also select a best set of seed sentences, we can improve average chrF performance on new test languages from a baseline of 21.9 to 50.7, while reducing the number of seed sentences to only ∼1,000 in the new, unknown language.
isOpenAccess: True
TL\DR: This work examines two approaches to best selection of seed sentences to jump start translations in a new language in view of best generalization to the remainder of a larger targeted text(s), and it finds that adapting large pretrained multilingual models to the domain/text first and then to the severely low resource language works best.
================================
faculty_name: Alexander Waibel
faculty_authorid: 2064429921
paper_id: f547c7ec86cbc0989e87f0e23f7e0b2cfc5259c3
paper_title: Towards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023
publication_link: https://aclanthology.org/2023.iwslt-1.37.pdf 
year_published: 2023 
abstract_paper:In this paper, we describe our submission to the Simultaneous Track at IWSLT 2023. This year, we continue with the successful setup from the last year, however, we adopt the latest methods that further improve the translation quality. Additionally, we propose a novel online policy for attentional encoder-decoder models. The policy prevents the model to generate translation beyond the current speech input by using an auxiliary CTC output layer. We show that the proposed simultaneous policy can be applied to both streaming blockwise models and offline encoder-decoder models. We observe significant improvements in quality (up to 1.1 BLEU) and the computational footprint (up to 45% relative RTF).
isOpenAccess: True
TL\DR: This work examines two approaches to best selection of seed sentences to jump start translations in a new language in view of best generalization to the remainder of a larger targeted text(s), and it finds that adapting large pretrained multilingual models to the domain/text first and then to the severely low resource language works best.
================================
faculty_name: Alexander Waibel
faculty_authorid: 1724972
paper_id: 100eb82862a66e264686d015934c97c54bdadb4f
paper_title: SYNTACC : Synthesizing Multi-Accent Speech By Weight Factorization
publication_link: Not given 
year_published: 2023 
abstract_paper:Conventional multi-speaker text-to-speech synthesis (TTS) is known to be capable of synthesizing speech for multiple voices, yet it cannot generate speech in different accents. This limitation has motivated us to develop SYNTACC (Synthesizing speech with accents) which adapts conventional multi-speaker TTS to produce multi-accent speech. Our method uses the YourTTS model and involves a novel multi-accent training mechanism. The method works by decomposing each weight matrix into a shared component and an accent-dependent component, with the former being initialized by the pretrained multi-speaker TTS model and the latter being factorized into vectors using rank-1 matrices to reduce the number of training parameters per accent. This weight factorization method proves to be effective in fine-tuning the SYNTACC on multi-accent data sets in a low-resource condition. Our SYNTACC model eventually allows speech synthesis in not only different voices but also in different accents.
isOpenAccess: True
TL\DR: This work examines two approaches to best selection of seed sentences to jump start translations in a new language in view of best generalization to the remainder of a larger targeted text(s), and it finds that adapting large pretrained multilingual models to the domain/text first and then to the severely low resource language works best.
================================
faculty_name: Alexander Waibel
faculty_authorid: 1724972
paper_id: 610d9958390ab83515d0d81e19f8e5264faf8e9b
paper_title: KIT’s Multilingual Speech Translation System for IWSLT 2023
publication_link: https://arxiv.org/pdf/2306.05320 
year_published: 2023 
abstract_paper:Many existing speech translation benchmarks focus on native-English speech in high-quality recording conditions, which often do not match the conditions in real-life use-cases. In this paper, we describe our speech translation system for the multilingual track of IWSLT 2023, which focuses on the translation of scientific conference talks. The test condition features accented input speech and terminology-dense contents. The tasks requires translation into 10 languages of varying amounts of resources. In absence of training data from the target domain, we use a retrieval-based approach (kNN-MT) for effective adaptation (+0.8 BLEU for speech translation). We also use adapters to easily integrate incremental training data from data augmentation, and show that it matches the performance of re-training. We observe that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules. Our cascaded speech system outperforms its end-to-end counterpart on scientific talk translation, although their performance remains similar on TED talks.
isOpenAccess: True
TL\DR: This paper describes the speech translation system for the multilingual track of IWSLT 2023, which focuses on the translation of scientific conference talks, and observes that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules.
================================
faculty_name: Alexander Waibel
faculty_authorid: 1724972
paper_id: 7e13fcb7b7bae202fb9087e87abaa71a4b19a3e3
paper_title: Convoifilter: A case study of doing cocktail party speech recognition
publication_link: https://arxiv.org/pdf/2308.11380 
year_published: 2023 
abstract_paper:This paper presents an end-to-end model designed to improve automatic speech recognition (ASR) for a particular speaker in a crowded, noisy environment. The model utilizes a single-channel speech enhancement module that isolates the speaker's voice from background noise (ConVoiFilter) and an ASR module. The model can decrease ASR's word error rate (WER) from 80% to 26.4% through this approach. Typically, these two components are adjusted independently due to variations in data requirements. However, speech enhancement can create anomalies that decrease ASR efficiency. By implementing a joint fine-tuning strategy, the model can reduce the WER from 26.4% in separate tuning to 14.5% in joint tuning. We openly share our pre-trained model to foster further research hf.co/nguyenvulebinh/voice-filter.
isOpenAccess: True
TL\DR: An end-to-end model designed to improve automatic speech recognition for a particular speaker in a crowded, noisy environment that utilizes a single-channel speech enhancement module that isolates the speaker's voice from background noise and an ASR module.
================================
faculty_name: Alexander Waibel
faculty_authorid: 1724972
paper_id: 954ca9ab894df43e2cac18bc3813e9f9bc1bd488
paper_title: Continually learning new languages
publication_link: http://arxiv.org/pdf/2211.11703 
year_published: 2023 
abstract_paper:Multilingual speech recognition with neural networks is often implemented with batch-learning, when all of the languages are available before training. An ability to add new languages after the prior training sessions can be economically bene-ﬁcial, but the main challenge is catastrophic forgetting. In this work, we combine the qualities of weight factorization, transfer learning and Elastic Weight Consolidation in order to counter catastrophic forgetting and facilitate learning new languages quickly. Such combination allowed us to eliminate catastrophic forgetting while still achieving performance for the new languages comparable with having all languages at once, in experiments of learning from an initial 10 languages to achieve 27 languages.
isOpenAccess: True
TL\DR: This work combines the qualities of weight factorization, transfer learning and Elastic Weight Consolidation in order to counter catastrophic forgetting and facilitate learning new languages quickly.
================================
faculty_name: Alexander Waibel
faculty_authorid: 1724972
paper_id: d24d60719e90e69749a75c160cb760d1d9fca44a
paper_title: Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff
publication_link: https://arxiv.org/pdf/2309.11379 
year_published: 2023 
abstract_paper:Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultaneous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. However, this method maintains multiple hypotheses until the entire speech input is consumed -- this scheme cannot directly show a single \textit{incremental} translation to users. Further, this method lacks mechanisms for \textit{controlling} the quality vs. latency tradeoff. We propose a modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU improvement without changing latency or 0.8-1.4 s latency improvement without changing quality.
isOpenAccess: True
TL\DR: A modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control is proposed and applied to models trained for online or offline translation and it is demonstrated that both types can be effectively used in online mode.
================================
faculty_name: Alexander Waibel
faculty_authorid: 1724972
paper_id: f524f119afc13cc07ca15998c10b9509e9e9b0b5
paper_title: End-to-End Evaluation for Low-Latency Simultaneous Speech Translation
publication_link: https://arxiv.org/pdf/2308.03415 
year_published: 2023 
abstract_paper:The challenge of low-latency speech translation has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches. In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmentation of the audio as well as the run-time of the different components. Secondly, we compare different approaches to low-latency speech translation using this framework. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state-of-the-art cascaded as well as end-to-end systems. Finally, the framework allows to automatically evaluate the translation quality as well as latency and also provides a web interface to show the low-latency model outputs to the user.
isOpenAccess: True
TL\DR: This work proposes the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions and directly compares state-of-the-art cascaded as well as end-to-end systems.
================================
faculty_name: Alexander Waibel
faculty_authorid: 1724972
paper_id: f7e995c3cae465963ecaa8c9b4ce8b9b4323a71b
paper_title: FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN
publication_link: https://aclanthology.org/2023.iwslt-1.1.pdf 
year_published: 2023 
abstract_paper:This paper reports on the shared tasks organized by the 20th IWSLT Conference. The shared tasks address 9 scientific challenges in spoken language translation: simultaneous and offline translation, automatic subtitling and dubbing, speech-to-speech translation, multilingual, dialect and low-resource speech translation, and formality control. The shared tasks attracted a total of 38 submissions by 31 teams. The growing interest towards spoken language translation is also witnessed by the constantly increasing number of shared task organizers and contributors to the overview paper, almost evenly distributed across industry and academia.
isOpenAccess: True
TL\DR: This work proposes the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions and directly compares state-of-the-art cascaded as well as end-to-end systems.
================================
faculty_name: Alexander Waibel
faculty_authorid: 2239133117
paper_id: 807abb9c185ce233e2c8a2fcee49be851a1c968f
paper_title: Incremental Learning of Humanoid Robot Behavior from Natural Interaction and Large Language Models
publication_link: https://arxiv.org/pdf/2309.04316 
year_published: 2023 
abstract_paper:Natural-language dialog is key for intuitive human-robot interaction. It can be used not only to express humans' intents, but also to communicate instructions for improvement if a robot does not understand a command correctly. Of great importance is to endow robots with the ability to learn from such interaction experience in an incremental way to allow them to improve their behaviors or avoid mistakes in the future. In this paper, we propose a system to achieve incremental learning of complex behavior from natural interaction, and demonstrate its implementation on a humanoid robot. Building on recent advances, we present a system that deploys Large Language Models (LLMs) for high-level orchestration of the robot's behavior, based on the idea of enabling the LLM to generate Python statements in an interactive console to invoke both robot perception and action. The interaction loop is closed by feeding back human instructions, environment observations, and execution results to the LLM, thus informing the generation of the next statement. Specifically, we introduce incremental prompt learning, which enables the system to interactively learn from its mistakes. For that purpose, the LLM can call another LLM responsible for code-level improvements of the current interaction based on human feedback. The improved interaction is then saved in the robot's memory, and thus retrieved on similar requests. We integrate the system in the robot cognitive architecture of the humanoid robot ARMAR-6 and evaluate our methods both quantitatively (in simulation) and qualitatively (in simulation and real-world) by demonstrating generalized incrementally-learned knowledge.
isOpenAccess: True
TL\DR: A system that deploys Large Language Models for high-level orchestration of the robot's behavior based on the idea of enabling the LLM to generate Python statements in an interactive console to invoke both robot perception and action is presented.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 47436455
paper_id: 3fb0c9a82c0d9c01448b37600efefb780e5362fe
paper_title: Crystalline electric field and magnetic anisotropy in Dy-based icosahedral quasicrystal and approximant
publication_link: https://arxiv.org/pdf/2307.11633 
year_published: 2023 
abstract_paper:The lack of the theory of the crystalline electric field (CEF) in rare-earth based quasicrystal (QC) and approximant crystal (AC) has prevented us from understanding the electronic states. Recent success of the formulation of the CEF theory on the basis of the point charge model has made it possible to analyze the CEF microscopically. Here, by applying this formulation to the QC Au-SM-Dy (SM=Si, Ge, Al, and Ga) and AC, we theoretically analyze the CEF. In the Dy$^{3+}$ ion with $4f^9$ configuration, the CEF Hamiltonian is diagonalized by the basis set for the total angular momentum $J=15/2$. The ratio of the valences of the screened ligand ions $\alpha=Z_{\rm SM}/Z_{\rm Au}$ plays an important role in characterizing the CEF ground state. For $0\le\alpha<0.30$, the magnetic easy axis for the CEF ground state is shown to be perpendicular to the mirror plane. On the other hand, for $\alpha>0.30$, the magnetic easy axis is shown to be lying in the mirror plane and as $\alpha$ increases, the easy axis rotates to the clockwise direction in the mirror plane at the Dy site and tends to approach the pseudo 5 fold axis. Possible relevance of these results to experiments is discussed.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Shinji Watanabe
faculty_authorid: 47436455
paper_id: a2a5830e49b94349f4ff7d672fa6693888e54b82
paper_title: Magnetism and topological property in icosahedral quasicrystal
publication_link: https://iopscience.iop.org/article/10.1088/1742-6596/2461/1/012011/pdf 
year_published: 2023 
abstract_paper:Quasicrystal (QC) has no periodicity but has a unique rotational symmetry forbidden in periodic crystals. Lack of microscopic theory of the crystalline electric field (CEF) in the QC and approximant crystal (AC) has prevented us from understanding the electric property, especially the magnetism. By developing the general formulation of the CEF in the rare-earth based QC and AC, we have analyzed the CEF in the QC Au-SM-Tb and AC (SM=Si, Ge, and Ga). The magnetic anisotropy arising from the CEF plays an important role in realizing unique magnetic states on the icosahedron (IC). By constructing the minimal model with the magnetic anisotropy, we have analyzed the ground-state properties of the IC, 1/1 AC, and QC. The hedgehog state is characterized by the topological charge of one and the whirling-moment state is characterized by the topological charge of three. The uniform arrangement of the ferrimagnetic state is stabilized in the QC with the ferromagnetic (FM) interaction, which is a candidate for the magnetic structure recently observed FM long-range order in the QC Au-Ga-Tb. The uniform arrangement of the hedgehog state is stabilized in the QC with the antiferromagnetic interaction, which suggests the possibility of the topological magnetic long-range order.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Shinji Watanabe
faculty_authorid: 48947986
paper_id: 9733b69b98142d2383f72ed1ebc3bd1d54138234
paper_title: Assessment of the frequency of SARS-CoV-2 Omicron variant escape from RNA-dependent RNA polymerase inhibitors and 3C-like protease inhibitors.
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: The findings suggest that the frequency of SARS-CoV-2 mutant escape from RdRP inhibitors is lower than that from 3CLpro inhibitors, and that Delta variants were more likely to acquire amino acid substitutions associated with resistance to 3CL Pro inhibitors under the selective pressure of this drug compared with Omicron variants.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 00542e510058b11d1faf612de9b45fa0d4d3f4e5
paper_title: Saturation time of exposure interval for cross-neutralization response to SARS-CoV-2: Implications for vaccine dose interval
publication_link: http://www.cell.com/article/S258900422300771X/pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: The results highlight the importance of vaccine dosage intervals of 4 months or longer, regardless of the antigenicity of the exposed antigen, to maximize the breadth of serum cross-neutralization covering SARS-CoV-2 Omicron lineages.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 01a819f7155bb87c32f1e4c13d9439c080e6aa97
paper_title: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning
publication_link: https://arxiv.org/pdf/2309.15317 
year_published: 2023 
abstract_paper:Multilingual self-supervised learning (SSL) has often lagged behind state-of-the-art (SOTA) methods due to the expenses and complexity required to handle many languages. This further harms the reproducibility of SSL, which is already limited to few research groups due to its resource usage. We show that more powerful techniques can actually lead to more efficient pre-training, opening SSL to more research groups. We propose WavLabLM, which extends WavLM’s joint prediction and denoising to 40k hours of data across 136 languages. To build WavLabLM, we devise a novel multi-stage pre-training method, designed to address the language imbalance of multilingual data. WavLabLM achieves comparable performance to XLS-R on ML-SUPERB with less than $10 \%$ of the training data, making SSL realizable with academic compute. We show that further efficiency can be achieved with a vanilla HuBERT Base model, which can maintain $94 \%$ of XLS-R’s performance with only $3 \%$ of the data, 4 GPUs, and limited trials. We open-source all code and models in ESPnet.
isOpenAccess: True
TL\DR: This work proposes WavLabLM, which extends WavLM’s joint prediction and denoising to 40k hours of data across 136 languages, and devise a novel multi-stage pre-training method, designed to address the language imbalance of multilingual data.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 0534fd0ed04acaa60f820b730bf3c4816767fa43
paper_title: Tensor decomposition for minimization of E2E SLU model toward on-device processing
publication_link: https://arxiv.org/pdf/2306.01247 
year_published: 2023 
abstract_paper:Spoken Language Understanding (SLU) is a critical speech recognition application and is often deployed on edge devices. Consequently, on-device processing plays a significant role in the practical implementation of SLU. This paper focuses on the end-to-end (E2E) SLU model due to its small latency property, unlike a cascade system, and aims to minimize the computational cost. We reduce the model size by applying tensor decomposition to the Conformer and E-Branchformer architectures used in our E2E SLU models. We propose to apply singular value decomposition to linear layers and the Tucker decomposition to convolution layers, respectively. We also compare COMP/PARFAC decomposition and Tensor-Train decomposition to the Tucker decomposition. Since the E2E model is represented by a single neural network, our tensor decomposition can flexibly control the number of parameters without changing feature dimensions. On the STOP dataset, we achieved 70.9% exact match accuracy under the tight constraint of only 15 million parameters.
isOpenAccess: True
TL\DR: This paper aims to minimize the computational cost of the end-to-end (E2E) SLU model due to its small latency property, unlike a cascade system, and reduces the model size by applying tensor decomposition to the Conformer and E-Branchformer architectures used in the E2E SLU models.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 06353e1b7e7c8dc701ac76dcd4db5061b24468c9
paper_title: Decoder-only Architecture for Speech Recognition with CTC Prompts and Text Data Augmentation
publication_link: https://arxiv.org/pdf/2309.08876 
year_published: 2023 
abstract_paper:Collecting audio-text pairs is expensive; however, it is much easier to access text-only data. Unless using shallow fusion, end-to-end automatic speech recognition (ASR) models require architecture modifications or additional training schemes to use text-only data. Inspired by recent advances in decoder-only language models (LMs), such as GPT-3 and PaLM adopted for speech-processing tasks, we propose using a decoder-only architecture for ASR with simple text augmentation. To provide audio information, encoder features compressed by CTC prediction are used as prompts for the decoder, which can be regarded as refining CTC prediction using the decoder-only model. Because the decoder architecture is the same as an autoregressive LM, it is simple to enhance the model by leveraging external text data with LM training. An experimental comparison using LibriSpeech and Switchboard shows that our proposed models with text augmentation training reduced word error rates from ordinary CTC by 0.3% and 1.4% on LibriSpeech test-clean and testother set, respectively, and 2.9% and 5.0% on Switchboard and CallHome. The proposed model had advantage on computational efficiency compared with conventional encoder-decoder ASR models with a similar parameter setup, and outperformed them on the LibriSpeech 100h and Switchboard training scenarios.
isOpenAccess: True
TL\DR: This work proposes using a decoder-only architecture for ASR with simple text augmentation training that had advantage on computational efficiency compared with conventional encoder-decoder ASR models with a similar parameter setup, and outperformed them on the LibriSpeech 100h and Switchboard training scenarios.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 090b284b2f8fc93ac3e7a92fc9f91bf4965ba75c
paper_title: ML-SUPERB: Multilingual Speech Universal PERformance Benchmark
publication_link: https://arxiv.org/pdf/2305.10615 
year_published: 2023 
abstract_paper:Speech processing Universal PERformance Benchmark (SUPERB) is a leaderboard to benchmark the performance of Self-Supervised Learning (SSL) models on various speech processing tasks. However, SUPERB largely considers English speech in its evaluation. This paper presents multilingual SUPERB (ML-SUPERB), covering 143 languages (ranging from high-resource to endangered), and considering both automatic speech recognition and language identification. Following the concept of SUPERB, ML-SUPERB utilizes frozen SSL features and employs a simple framework for multilingual tasks by learning a shallow downstream model. Similar to the SUPERB benchmark, we find speech SSL models can significantly improve performance compared to FBANK features. Furthermore, we find that multilingual models do not always perform better than their monolingual counterparts. We will release ML-SUPERB as a challenge with organized datasets and reproducible training scripts for future multilingual representation research.
isOpenAccess: True
TL\DR: None
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 1028bf42a4c792acefd3be9da45e58f2b1620fe3
paper_title: Structured Pruning of Self-Supervised Pre-Trained Models for Speech Recognition and Understanding
publication_link: https://arxiv.org/pdf/2302.14132 
year_published: 2023 
abstract_paper:Self-supervised speech representation learning (SSL) has shown to be effective in various downstream tasks, but SSL models are usually large and slow. Model compression techniques such as pruning aim to reduce the model size and computation without degradation in accuracy. Prior studies focus on the pruning of Transformers; however, speech models not only utilize a stack of Transformer blocks, but also combine a frontend network based on multiple convolutional layers for low-level feature representation learning. This frontend has a small size but a heavy computational cost. In this work, we propose three task-specific structured pruning methods to deal with such heterogeneous networks. Experiments on LibriSpeech and SLURP show that the proposed method is more accurate than the original wav2vec2-base with 10% to 30% less computation, and is able to reduce the computation by 40% to 50% without any degradation.
isOpenAccess: True
TL\DR: This work proposes three task-specific structured pruning methods to deal with heterogeneous speech models that not only utilize a stack of Transformer blocks, but also combine a frontend network based on multiple convolutional layers for low-level feature representation learning.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 10e8dc07ea256c6a88d7043cf135417402ed38f4
paper_title: Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization
publication_link: https://arxiv.org/pdf/2305.11095 
year_published: 2023 
abstract_paper:We investigate the emergent abilities of the recently proposed web-scale speech model Whisper, by adapting it to unseen tasks with prompt engineering. We selected three tasks: audio-visual speech recognition (AVSR), code-switched speech recognition (CS-ASR), and speech translation (ST) on unseen language pairs. We design task-specific prompts, by either leveraging another large-scale model, or simply manipulating the special tokens in the default prompts. Experiments show that compared to the default prompts, our proposed prompts improve performance by 10% to 45% on the three zero-shot tasks, and even outperform SotA supervised models on some datasets. In addition, our experiments reveal many interesting properties of Whisper, including its robustness to prompts, bias on accents, and the multilingual understanding in its latent space. Code is available at https://github.com/jasonppy/PromptingWhisper
isOpenAccess: True
TL\DR: This work proposes three task-specific structured pruning methods to deal with heterogeneous speech models that not only utilize a stack of Transformer blocks, but also combine a frontend network based on multiple convolutional layers for low-level feature representation learning.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 14f5fd91d75bc10d9fff53dfe7ee73484fc4273b
paper_title: A Comparative Study on E-Branchformer vs Conformer in Speech Recognition, Translation, and Understanding Tasks
publication_link: http://arxiv.org/pdf/2305.11073 
year_published: 2023 
abstract_paper:Conformer, a convolution-augmented Transformer variant, has become the de facto encoder architecture for speech processing due to its superior performance in various tasks, including automatic speech recognition (ASR), speech translation (ST) and spoken language understanding (SLU). Recently, a new encoder called E-Branchformer has outperformed Conformer in the LibriSpeech ASR benchmark, making it promising for more general speech applications. This work compares E-Branchformer and Conformer through extensive experiments using different types of end-to-end sequence-to-sequence models. Results demonstrate that E-Branchformer achieves comparable or better performance than Conformer in almost all evaluation sets across 15 ASR, 2 ST, and 3 SLU benchmarks, while being more stable during training. We will release our training configurations and pre-trained models for reproducibility, which can benefit the speech community.
isOpenAccess: True
TL\DR: This work proposes three task-specific structured pruning methods to deal with heterogeneous speech models that not only utilize a stack of Transformer blocks, but also combine a frontend network based on multiple convolutional layers for low-level feature representation learning.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 16fbcf340648b302ad8d4e6ed34c7ab5ad346db9
paper_title: Efficient Sequence Transduction by Jointly Predicting Tokens and Durations
publication_link: http://arxiv.org/pdf/2304.06795 
year_published: 2023 
abstract_paper:This paper introduces a novel Token-and-Duration Transducer (TDT) architecture for sequence-to-sequence tasks. TDT extends conventional RNN-Transducer architectures by jointly predicting both a token and its duration, i.e. the number of input frames covered by the emitted token. This is achieved by using a joint network with two outputs which are independently normalized to generate distributions over tokens and durations. During inference, TDT models can skip input frames guided by the predicted duration output, which makes them significantly faster than conventional Transducers which process the encoder output frame by frame. TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better accuracy and up to 2.82X faster inference than conventional Transducers. TDT models for Speech Translation achieve an absolute gain of over 1 BLEU on the MUST-C test compared with conventional Transducers, and its inference is 2.27X faster. In Speech Intent Classification and Slot Filling tasks, TDT models improve the intent accuracy by up to over 1% (absolute) over conventional Transducers, while running up to 1.28X faster. Our implementation of the TDT model will be open-sourced with the NeMo (https://github.com/NVIDIA/NeMo) toolkit.
isOpenAccess: True
TL\DR: This work proposes three task-specific structured pruning methods to deal with heterogeneous speech models that not only utilize a stack of Transformer blocks, but also combine a frontend network based on multiple convolutional layers for low-level feature representation learning.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 2567a34501c1b258c102a07e737b87e556af0809
paper_title: Speech Summarization of Long Spoken Document: Improving Memory Efficiency of Speech/Text Encoders
publication_link: Not given 
year_published: 2023 
abstract_paper:Speech summarization requires processing several minute-long speech sequences to allow exploiting the whole context of a spoken document. A conventional approach is a cascade of automatic speech recognition (ASR) and text summarization (TS). However, the cascade systems are sensitive to ASR errors. Moreover, the cascade system cannot be optimized for input speech and utilize para-linguistic information. Recently, there has been an increased interest in end-to-end (E2E) approaches optimized to output summaries directly from speech. Such systems can thus mitigate the ASR errors of cascade approaches. However, E2E speech summarization requires massive computational resources because it needs to encode long speech sequences. We propose a speech summarization system that enables E2E summarization from 100 seconds, which is the limit of the conventional method, to up to 10 minutes (i.e., the duration of typical instructional videos on YouTube). However, the modeling capability of this model for minute-long speech sequences is weaker than the conventional approach. We thus exploit auxiliary text information from ASR transcriptions to improve the modeling capabilities. The resultant system consists of a dual speech/text encoder decoder-based summarization system. We perform experiments on the How2 dataset showing the proposed system improved METEOR scores by up to 2.7 points by fully exploiting the long spoken documents.
isOpenAccess: True
TL\DR: This work proposes a speech summarization system that enables E2E summarization from 100 seconds, which is the limit of the conventional method, to up to 10 minutes (i.e., the duration of typical instructional videos on YouTube), and exploits auxiliary text information from ASR transcriptions to improve the modeling capabilities.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 25c399a231364f4a77d1dc4b59927585e63f5f11
paper_title: UNSSOR: Unsupervised Neural Speech Separation by Leveraging Over-determined Training Mixtures
publication_link: http://arxiv.org/pdf/2305.20054 
year_published: 2023 
abstract_paper:In reverberant conditions with multiple concurrent speakers, each microphone acquires a mixture signal of multiple speakers at a different location. In over-determined conditions where the microphones out-number speakers, we can narrow down the solutions to speaker images and realize unsupervised speech separation by leveraging each mixture signal as a constraint (i.e., the estimated speaker images at a microphone should add up to the mixture). Equipped with this insight, we propose UNSSOR, an algorithm for $\textbf{u}$nsupervised $\textbf{n}$eural $\textbf{s}$peech $\textbf{s}$eparation by leveraging $\textbf{o}$ver-determined training mixtu$\textbf{r}$es. At each training step, we feed an input mixture to a deep neural network (DNN) to produce an intermediate estimate for each speaker, linearly filter the estimates, and optimize a loss so that, at each microphone, the filtered estimates of all the speakers can add up to the mixture to satisfy the above constraint. We show that this loss can promote unsupervised separation of speakers. The linear filters are computed in each sub-band based on the mixture and DNN estimates through the forward convolutive prediction (FCP) algorithm. To address the frequency permutation problem incurred by using sub-band FCP, a loss term based on minimizing intra-source magnitude scattering is proposed. Although UNSSOR requires over-determined training mixtures, we can train DNNs to achieve under-determined separation (e.g., unsupervised monaural speech separation). Evaluation results on two-speaker separation in reverberant conditions show the effectiveness and potential of UNSSOR.
isOpenAccess: True
TL\DR: This work proposes a speech summarization system that enables E2E summarization from 100 seconds, which is the limit of the conventional method, to up to 10 minutes (i.e., the duration of typical instructional videos on YouTube), and exploits auxiliary text information from ASR transcriptions to improve the modeling capabilities.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 331af9b7193e563b021e8e6892e7cb3030decd38
paper_title: Segment-Level Vectorized Beam Search Based on Partially Autoregressive Inference
publication_link: https://arxiv.org/pdf/2309.14922 
year_published: 2023 
abstract_paper:Attention-based encoder-decoder models with autoregressive (AR) decoding have proven to be the dominant approach for automatic speech recognition (ASR) due to their superior accuracy. However, they often suffer from slow inference. This is primarily attributed to the incremental calculation of the decoder. This work proposes a partially AR framework, which employs segment-level vectorized beam search for improving the inference speed of an ASR model based on the hybrid connectionist temporal classification (CTC) attention-based architecture. It first generates an initial hypothesis using greedy CTC decoding, identifying low-confidence tokens based on their output probabilities. We then utilize the decoder to perform segment-level vectorized beam search on these tokens, re-predicting in parallel with minimal decoder calculations. Experimental results show that our method is 12 to 13 times faster in inference on the LibriSpeech corpus over AR decoding whilst preserving high accuracy.
isOpenAccess: True
TL\DR: A partially AR framework, which employs segment-level vectorized beam search for improving the inference speed of an ASR model based on the hybrid connectionist temporal classification (CTC) attention-based architecture, which is 12 to 13 times faster in inference on the LibriSpeech corpus over AR decoding whilst preserving high accuracy.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 3b93dd5f2d2512a4b58f6c776af59f74a90764a5
paper_title: Unsupervised Data Selection for TTS: Using Arabic Broadcast News as a Case Study
publication_link: http://arxiv.org/pdf/2301.09099 
year_published: 2023 
abstract_paper:.
isOpenAccess: True
TL\DR: A partially AR framework, which employs segment-level vectorized beam search for improving the inference speed of an ASR model based on the hybrid connectionist temporal classification (CTC) attention-based architecture, which is 12 to 13 times faster in inference on the LibriSpeech corpus over AR decoding whilst preserving high accuracy.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 3bd320ddb25886417ae90011b00f13f5d558097b
paper_title: BASS: Block-wise Adaptation for Speech Summarization
publication_link: https://arxiv.org/pdf/2307.08217 
year_published: 2023 
abstract_paper:End-to-end speech summarization has been shown to improve performance over cascade baselines. However, such models are difficult to train on very large inputs (dozens of minutes or hours) owing to compute restrictions and are hence trained with truncated model inputs. Truncation leads to poorer models, and a solution to this problem rests in block-wise modeling, i.e., processing a portion of the input frames at a time. In this paper, we develop a method that allows one to train summarization models on very long sequences in an incremental manner. Speech summarization is realized as a streaming process, where hypothesis summaries are updated every block based on new acoustic information. We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.
isOpenAccess: True
TL\DR: This paper develops a method that allows one to train summarization models on very long sequences in an incremental manner and devise and test strategies to pass semantic context across the blocks.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 48c6318dbcf9908cabe0023b8817566f34d0b466
paper_title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
publication_link: https://arxiv.org/pdf/2303.07624 
year_published: 2023 
abstract_paper:Transformer-based end-to-end speech recognition has achieved great success. However, the large footprint and computational overhead make it difficult to deploy these models in some real-world applications. Model compression techniques can reduce the model size and speed up inference, but the compressed model has a fixed architecture which might be suboptimal. We propose a novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs. With a similar number of layers at inference time, I3D-based models outperform the vanilla Transformer and the static pruned model via iterative layer pruning. We also present interesting analysis on the gate probabilities and the input-dependency, which helps us better understand deep encoders.
isOpenAccess: True
TL\DR: A novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs and interesting analysis on the gate probabilities and the input-dependency, which helps to better understand deep encoders.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 4b8d3ede673ddeab9dfb5184da6b748d7a526754
paper_title: A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech
publication_link: http://arxiv.org/pdf/2302.04215 
year_published: 2023 
abstract_paper:Recent Text-to-Speech (TTS) systems trained on reading or acted corpora have achieved near human-level naturalness. The diversity of human speech, however, often goes beyond the coverage of these corpora. We believe the ability to handle such diversity is crucial for AI systems to achieve human-level communication. Our work explores the use of more abundant real-world data for building speech synthesizers. We train TTS systems using real-world speech from YouTube and podcasts. We observe the mismatch between training and inference alignments in mel-spectrogram based autoregressive models, leading to unintelligible synthesis, and demonstrate that learned discrete codes within multiple code groups effectively resolves this issue. We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality. We conduct ablation analyses to identify the efficacy of our methods. We show that MQTTS outperforms existing TTS systems in several objective and subjective measures.
isOpenAccess: True
TL\DR: A novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs and interesting analysis on the gate probabilities and the input-dependency, which helps to better understand deep encoders.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 4d35540aaf993c8fa7e1fa5fc6a990f1eb830263
paper_title: A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning
publication_link: http://arxiv.org/pdf/2305.13331 
year_published: 2023 
abstract_paper:Aphasia is a language disorder that affects the speaking ability of millions of patients. This paper presents a new benchmark for Aphasia speech recognition and detection tasks using state-of-the-art speech recognition techniques with the AphsiaBank dataset. Specifically, we introduce two multi-task learning methods based on the CTC/Attention architecture to perform both tasks simultaneously. Our system achieves state-of-the-art speaker-level detection accuracy (97.3%), and a relative WER reduction of 11% for moderate Aphasia patients. In addition, we demonstrate the generalizability of our approach by applying it to another disordered speech database, the DementiaBank Pitt corpus. We will make our all-in-one recipes and pre-trained model publicly available to facilitate reproducibility. Our standardized data preprocessing pipeline and open-source recipes enable researchers to compare results directly, promoting progress in disordered speech processing.
isOpenAccess: True
TL\DR: A novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs and interesting analysis on the gate probabilities and the input-dependency, which helps to better understand deep encoders.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 52d2c8d36c4ace01d8c440a44e1a7fdea04ec482
paper_title: Antiviral Susceptibilities of Distinct Lineages of Influenza C and D Viruses
publication_link: https://www.mdpi.com/1999-4915/15/1/244/pdf?version=1674098063 
year_published: 2023 
abstract_paper:The emergence and spread of antiviral-resistant influenza viruses are of great concern. To minimize the public health risk, it is important to monitor antiviral susceptibilities of influenza viruses. Analyses of the antiviral susceptibilities of influenza A and B viruses have been conducted globally; however, those of influenza C and D viruses are limited. Here, we determined the susceptibilities of influenza C viruses representing all six lineages (C/Taylor, C/Yamagata, C/Sao Paulo, C/Aichi, C/Kanagawa, and C/Mississippi) and influenza D viruses representing four lineages (D/OK, D/660, D/Yama2016, and D/Yama2019) to RNA polymerase inhibitors (baloxavir and favipiravir) by using a focus reduction assay. All viruses tested were susceptible to both drugs. We then performed a genetic analysis to check for amino acid substitutions associated with baloxavir and favipiravir resistance and found that none of the viruses tested possessed these substitutions. Use of the focus reduction assay with the genotypic assay has proven valuable for monitoring the antiviral susceptibilities of influenza C and D viruses as well as influenza A and B viruses. Antiviral susceptibility monitoring of all influenza virus types should continue in order to assess the public health risks posed by these viruses.
isOpenAccess: True
TL\DR: Use of the focus reduction assay with the genotypic assay has proven valuable for monitoring the antiviral susceptibilities of influenza C and D viruses as well as influenza A and B viruses.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 611f9ee6eef0936462cd78f371798d0699951c59
paper_title: Paaploss: A Phonetic-Aligned Acoustic Parameter Loss for Speech Enhancement
publication_link: https://arxiv.org/pdf/2302.08095 
year_published: 2023 
abstract_paper:Despite rapid advancement in recent years, current speech enhancement models often produce speech that differs in perceptual quality from real clean speech. We propose a learning objective that formalizes differences in perceptual quality, by using domain knowledge of acoustic-phonetics. We identify temporal acoustic parameters – such as spectral tilt, spectral flux, shimmer, etc. – that are non-differentiable, and we develop a neural network estimator that can accurately predict their time-series values across an utterance. We also model phoneme-specific weights for each feature, as the acoustic parameters are known to show different behavior in different phonemes. We can add this criterion as an auxiliary loss to any model that produces speech, to optimize speech outputs to match the values of clean speech in these features. Experimentally we show that it improves speech enhancement workflows in both time-domain and time-frequency domain, as measured by standard evaluation metrics. We also provide an analysis of phoneme-dependent improvement on acoustic parameters, demonstrating the additional interpretability that our method provides. This analysis can suggest which features are currently the bottleneck for improvement.
isOpenAccess: True
TL\DR: Use of the focus reduction assay with the genotypic assay has proven valuable for monitoring the antiviral susceptibilities of influenza C and D viruses as well as influenza A and B viruses.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 659be1ff350634f50cc066d258ee6a45e697e552
paper_title: SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing
publication_link: https://aclanthology.org/2023.sigmorphon-1.22.pdf 
year_published: 2023 
abstract_paper:In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.
isOpenAccess: True
TL\DR: Use of the focus reduction assay with the genotypic assay has proven valuable for monitoring the antiviral susceptibilities of influenza C and D viruses as well as influenza A and B viruses.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 6c33625c7b0ffc37955921a145531d9d4eaee713
paper_title: Exploring the Integration of Speech Separation and Recognition with Self-Supervised Learning Representation
publication_link: https://arxiv.org/pdf/2307.12231 
year_published: 2023 
abstract_paper:Neural speech separation has made remarkable progress and its integration with automatic speech recognition (ASR) is an important direction towards realizing multi-speaker ASR. This work provides an insightful investigation of speech separation in reverberant and noisy-reverberant scenarios as an ASR front-end. In detail, we explore multi-channel separation methods, mask-based beamforming and complex spectral mapping, as well as the best features to use in the ASR back-end model. We employ the recent self-supervised learning representation (SSLR) as a feature and improve the recognition performance from the case with filterbank features. To further improve multi-speaker recognition performance, we present a carefully designed training strategy for integrating speech separation and recognition with SSLR. The proposed integration using TF-GridNet-based complex spectral mapping and WavLM-based SSLR achieves a 2.5% word error rate in reverberant WHAMR! test set, significantly outperforming an existing mask-based MVDR beamforming and filterbank integration (28.9%).
isOpenAccess: True
TL\DR: This work provides an insightful investigation of speech separation in reverberant and noisy-reverberant scenarios as an ASR front-end, and employs the recent self-supervised learning representation (SSLR) as a feature and improves the recognition performance from the case with filterbank features.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 786294f4008732a5dac9895a8507bc4c80450075
paper_title: Dynamic-SUPERB: Towards A Dynamic, Collaborative, and Comprehensive Instruction-Tuning Benchmark for Speech
publication_link: https://arxiv.org/pdf/2309.09510 
year_published: 2023 
abstract_paper:Text language models have shown remarkable zero-shot capability in generalizing to unseen tasks when provided with well-formulated instructions. However, existing studies in speech processing primarily focus on limited or specific tasks. Moreover, the lack of standardized benchmarks hinders a fair comparison across different approaches. Thus, we present Dynamic-SUPERB, a benchmark designed for building universal speech models capable of leveraging instruction tuning to perform multiple tasks in a zero-shot fashion. To achieve comprehensive coverage of diverse speech tasks and harness instruction tuning, we invite the community to collaborate and contribute, facilitating the dynamic growth of the benchmark. To initiate, Dynamic-SUPERB features 55 evaluation instances by combining 33 tasks and 22 datasets. This spans a broad spectrum of dimensions, providing a comprehensive platform for evaluation. Additionally, we propose several approaches to establish benchmark baselines. These include the utilization of speech models, text language models, and the multimodal encoder. Evaluation results indicate that while these baselines perform reasonably on seen tasks, they struggle with unseen ones. We also conducted an ablation study to assess the robustness and seek improvements in the performance. We release all materials to the public and welcome researchers to collaborate on the project, advancing technologies in the field together.
isOpenAccess: True
TL\DR: This work presents Dynamic-SUPERB, a benchmark designed for building universal speech models capable of leveraging instruction tuning to perform multiple tasks in a zero-shot fashion, and invites the community to collaborate and contribute, facilitating the dynamic growth of the benchmark.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 7d4ad68dedff8c81e0fd9c08ea76b220a7e05d69
paper_title: Speaker-Independent Acoustic-to-Articulatory Speech Inversion
publication_link: https://arxiv.org/pdf/2302.06774 
year_published: 2023 
abstract_paper:To build speech processing methods that can handle speech as naturally as humans, researchers have explored multiple ways of building an invertible mapping from speech to an interpretable space. The articulatory space is a promising inversion target, since this space captures the mechanics of speech production. To this end, we build an acoustic-to-articulatory inversion (AAI) model that leverages autoregression, adversarial training, and self supervision to generalize to unseen speakers. Our approach obtains 0.784 correlation on an electromagnetic articulography (EMA) dataset, improving the state-of-the-art by 12.5%. Additionally, we show the interpretability of these representations through directly com-paring the behavior of estimated representations with speech production behavior. Finally, we propose a resynthesis-based AAI evaluation metric that does not rely on articulatory labels, demonstrating its efficacy with an 18-speaker dataset.
isOpenAccess: True
TL\DR: This work builds an acoustic-to-articulatory inversion (AAI) model that leverages autoregression, adversarial training, and self supervision to generalize to unseen speakers, and proposes a resynthesis-based AAI evaluation metric that does not rely on articulatory labels.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 7f995454efda9f660d2258f59f6e19a2125e688e
paper_title: Towards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-training and Multi-modal Tokens
publication_link: https://arxiv.org/pdf/2309.08531 
year_published: 2023 
abstract_paper:In this paper, we propose methods to build a powerful and efficient Image-to-Speech captioning (Im2Sp) model. To this end, we start with importing the rich knowledge related to image comprehension and language modeling from a large-scale pre-trained vision-language model into Im2Sp. We set the output of the proposed Im2Sp as discretized speech units, i.e., the quantized speech features of a self-supervised speech model. The speech units mainly contain linguistic information while suppressing other characteristics of speech. This allows us to incorporate the language modeling capability of the pre-trained vision-language model into the spoken language modeling of Im2Sp. With the vision-language pre-training strategy, we set new state-of-the-art Im2Sp performances on two widely used benchmark databases, COCO and Flickr8k. Then, we further improve the efficiency of the Im2Sp model. Similar to the speech unit case, we convert the original image into image units, which are derived through vector quantization of the raw image. With these image units, we can drastically reduce the required data storage for saving image data to just 0.8% when compared to the original image data in terms of bits. Demo page: https://ms-dot-k.github.io/Image-to-Speech-Captioning.
isOpenAccess: True
TL\DR: This work builds an acoustic-to-articulatory inversion (AAI) model that leverages autoregression, adversarial training, and self supervision to generalize to unseen speakers, and proposes a resynthesis-based AAI evaluation metric that does not rely on articulatory labels.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 8402d64fde12cafaf8a1daa60de0acd1abedbffb
paper_title: Enhancing Speech-To-Speech Translation with Multiple TTS Targets
publication_link: https://arxiv.org/pdf/2304.04618 
year_published: 2023 
abstract_paper:It has been known that direct speech-to-speech translation (S2ST) models usually suffer from the data scarcity issue because of the limited existing parallel materials for both source and target speech. Therefore to train a direct S2ST system, previous works usually utilize text-to-speech (TTS) systems to generate samples in the target language by augmenting the data from speech-to-text translation (S2TT). However, there is a limited investigation into how the synthesized target speech would affect the S2ST models. In this work, we analyze the effect of changing synthesized target speech for direct S2ST models. We find that simply combining the target speech from different TTS systems can potentially improve the S2ST performances. Following that, we also propose a multi-task framework that jointly optimizes the S2ST system with multiple targets from different TTS systems. Extensive experiments demonstrate that our proposed framework achieves consistent improvements (2.8 BLEU) over the baselines on the Fisher Spanish-English dataset.
isOpenAccess: True
TL\DR: It is found that simply combining the target speech from different TTS systems can potentially improve the S2ST performances, and a multi-task framework is proposed that jointly optimizes the S1ST system with multiple targets from differentTTS systems.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 8bc617c9139648d7a92991d70c671230bac7b2e2
paper_title: AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head
publication_link: http://arxiv.org/pdf/2304.12995 
year_published: 2023 
abstract_paper:Large language models (LLMs) have exhibited remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. Despite the recent success, current LLMs are not capable of processing complex audio information or conducting spoken conversations (like Siri or Alexa). In this work, we propose a multi-modal AI system named AudioGPT, which complements LLMs (i.e., ChatGPT) with 1) foundation models to process complex audio information and solve numerous understanding and generation tasks; and 2) the input/output interface (ASR, TTS) to support spoken dialogue. With an increasing demand to evaluate multi-modal LLMs of human intention understanding and cooperation with foundation models, we outline the principles and processes and test AudioGPT in terms of consistency, capability, and robustness. Experimental results demonstrate the capabilities of AudioGPT in solving AI tasks with speech, music, sound, and talking head understanding and generation in multi-round dialogues, which empower humans to create rich and diverse audio content with unprecedented ease. Our system is publicly available at \url{https://github.com/AIGC-Audio/AudioGPT}.
isOpenAccess: True
TL\DR: It is found that simply combining the target speech from different TTS systems can potentially improve the S2ST performances, and a multi-task framework is proposed that jointly optimizes the S1ST system with multiple targets from differentTTS systems.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 8f0a24d1678e4d0e584b0932196cd257d5c53c7d
paper_title: Improving Audio Captioning Models with Fine-grained Audio Features, Text Embedding Supervision, and LLM Mix-up Augmentation
publication_link: https://arxiv.org/pdf/2309.17352 
year_published: 2023 
abstract_paper:Automated audio captioning (AAC) aims to generate informative descriptions for various sounds from nature and/or human activities. In recent years, AAC has quickly attracted research interest, with state-of-the-art systems now relying on a sequence-to-sequence (seq2seq) backbone powered by strong models such as Transformers. Following the macro-trend of applied machine learning research, in this work, we strive to improve the performance of seq2seq AAC models by extensively leveraging pretrained models and large language models (LLMs). Specifically, we utilize BEATs to extract fine-grained audio features. Then, we employ Instructor LLM to fetch text embeddings of captions, and infuse their language-modality knowledge into BEATs audio features via an auxiliary InfoNCE loss function. Moreover, we propose a novel data augmentation method that uses ChatGPT to produce caption mix-ups (i.e., grammatical and compact combinations of two captions) which, together with the corresponding audio mixtures, increase not only the amount but also the complexity and diversity of training data. During inference, we propose to employ nucleus sampling and a hybrid reranking algorithm, which has not been explored in AAC research. Combining our efforts, our model achieves a new state-of-the-art 32.6 SPIDEr-FL score on the Clotho evaluation split, and wins the 2023 DCASE AAC challenge.
isOpenAccess: True
TL\DR: It is found that simply combining the target speech from different TTS systems can potentially improve the S2ST performances, and a multi-task framework is proposed that jointly optimizes the S1ST system with multiple targets from differentTTS systems.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 91a06713cbccbfb1b5e1b9f7b62a1fba348616c3
paper_title: Voxtlm: unified decoder-only models for consolidating speech recognition/synthesis and speech/text continuation tasks
publication_link: https://arxiv.org/pdf/2309.07937 
year_published: 2023 
abstract_paper:We propose a decoder-only language model, VoxtLM, that can perform four tasks: speech recognition, speech synthesis, text generation, and speech continuation. VoxtLM integrates text vocabulary with discrete speech tokens from self-supervised speech features and uses special tokens to enable multitask learning. Compared to a single-task model, VoxtLM exhibits a significant improvement in speech synthesis, with improvements in both speech intelligibility from 28.9 to 5.6 and objective quality from 2.68 to 3.90. VoxtLM also improves speech generation and speech recognition performance over the single-task counterpart. Further, VoxtLM is trained with publicly available data and training recipes and model checkpoints are open-sourced to make fully reproducible work.
isOpenAccess: True
TL\DR: A decoder-only language model that can perform four tasks: speech recognition, speech synthesis, text generation, and speech continuation, VoxtLM is proposed, which exhibits a significant improvement in speech synthesis and improves speech intelligibility and objective quality.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 95aac8fe824bd0c83de594af0bf9d259e2416f53
paper_title: Learning to Speak from Text: Zero-Shot Multilingual Text-to-Speech with Unsupervised Text Pretraining
publication_link: http://arxiv.org/pdf/2301.12596 
year_published: 2023 
abstract_paper:While neural text-to-speech (TTS) has achieved human-like natural synthetic speech, multilingual TTS systems are limited to resource-rich languages due to the need for paired text and studio-quality audio data. This paper proposes a method for zero-shot multilingual TTS using text-only data for the target language. The use of text-only data allows the development of TTS systems for low-resource languages for which only textual resources are available, making TTS accessible to thousands of languages. Inspired by the strong cross-lingual transferability of multilingual language models, our framework first performs masked language model pretraining with multilingual text-only data. Then we train this model with a paired data in a supervised manner, while freezing a language-aware embedding layer. This allows inference even for languages not included in the paired data but present in the text-only data. Evaluation results demonstrate highly intelligible zero-shot TTS with a character error rate of less than 12% for an unseen language.
isOpenAccess: True
TL\DR: Inspired by the strong cross-lingual transferability of multilingual language models, this framework first performs masked language model pretraining with multilingual text-only data, and trains this model with a paired data in a supervised manner, while freezing a language-aware embedding layer.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 9cbd933c04218c9b642c15a49f8470d54524d9fb
paper_title: FNeural Speech Enhancement with Very Low Algorithmic Latency and Complexity via Integrated full- and sub-band Modeling
publication_link: Not given 
year_published: 2023 
abstract_paper:We propose FSB-LSTM, a novel long short-term memory (LSTM) based architecture that integrates full- and sub-band (FSB) modeling, for single- and multi-channel speech enhancement in the short-time Fourier transform (STFT) domain. The model maintains an information highway to flow an over-complete input representation through multiple FSB-LSTM modules. Each FSB-LSTM module consists of a full-band block to model spectro-temporal patterns at all frequencies and a sub-band block to model patterns within each sub-band, where each of the two blocks takes a down-sampled representation as input and returns an up-sampled discriminative representation to be added to the block input via a residual connection. The model is designed to have a low algorithmic complexity, a small run-time buffer and a very low algorithmic latency, at the same time producing a strong enhancement performance on a noisy-reverberant speech enhancement task even if the hop size is as low as 2 ms.
isOpenAccess: True
TL\DR: The proposed FSB-LSTM model is designed to have a low algorithmic complexity, a small run-time buffer and a very lowgorithmic latency, at the same time producing a strong enhancement performance on a noisy-reverberant speech enhancement task even if the hop size is as low as 2 ms.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: 9dcfb422f6057725b1585caf820e128c91d6dbb3
paper_title: Improving Massively Multilingual ASR with Auxiliary CTC Objectives
publication_link: https://arxiv.org/pdf/2302.12829 
year_published: 2023 
abstract_paper:Multilingual Automatic Speech Recognition (ASR) models have extended the usability of speech technologies to a wide variety of languages. With how many languages these models have to handle, however, a key to understanding their imbalanced performance across different languages is to examine if the model actually knows which language it should transcribe. In this paper, we introduce our work on improving performance on FLEURS, a 102-language open ASR benchmark, by conditioning the entire model on language identity (LID). We investigate techniques inspired from recent Connectionist Temporal Classification (CTC) studies to help the model handle the large number of languages, conditioning on the LID predictions of auxiliary tasks. Our experimental results demonstrate the effectiveness of our technique over standard CTC/Attention-based hybrid models. Furthermore, our state-of-the-art systems using self-supervised models with the Conformer architecture improve over the results of prior work on FLEURS by a relative 28.4% CER. Trained models are reproducible recipes are available at https://github.com/espnet/espnet/tree/master/egs2/fleurs/asr1.
isOpenAccess: True
TL\DR: The proposed FSB-LSTM model is designed to have a low algorithmic complexity, a small run-time buffer and a very lowgorithmic latency, at the same time producing a strong enhancement performance on a noisy-reverberant speech enhancement task even if the hop size is as low as 2 ms.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: a5ab124e57d1f26436821588aacd7d75b831259c
paper_title: Toward Universal Speech Enhancement For Diverse Input Conditions
publication_link: https://arxiv.org/pdf/2309.17384 
year_published: 2023 
abstract_paper:The past decade has witnessed substantial growth of data-driven speech enhancement (SE) techniques thanks to deep learning. While existing approaches have shown impressive performance in some common datasets, most of them are designed only for a single condition (e.g., single-channel, multi-channel, or a fixed sampling frequency) or only consider a single task (e.g., denoising or dereverberation). Currently, there is no universal SE approach that can effectively handle diverse input conditions with a single model. In this paper, we make the first attempt to investigate this line of research. First, we devise a single SE model that is independent of microphone channels, signal lengths, and sampling frequencies. Second, we design a universal SE benchmark by combining existing public corpora with multiple conditions. Our experiments on a wide range of datasets show that the proposed single model can successfully handle diverse conditions with strong performance.
isOpenAccess: True
TL\DR: The proposed FSB-LSTM model is designed to have a low algorithmic complexity, a small run-time buffer and a very lowgorithmic latency, at the same time producing a strong enhancement performance on a noisy-reverberant speech enhancement task even if the hop size is as low as 2 ms.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: b4855ff933fb80846638469a1b43c1766df85d78
paper_title: The Pipeline System of ASR and NLU with MLM-based data Augmentation Toward Stop Low-Resource Challenge
publication_link: https://arxiv.org/pdf/2305.01194 
year_published: 2023 
abstract_paper:This paper describes our system for the low-resource domain adaptation track (Track 3) in Spoken Language Understanding Grand Challenge, which is a part of ICASSP Signal Processing Grand Challenge 2023. In the track, we adopt a pipeline approach of ASR and NLU. For ASR, we fine-tune Whisper for each domain with upsampling. For NLU, we fine-tune BART on all the Track3 data and then on low-resource domain data. We apply masked LM (MLM) -based data augmentation, where some of input tokens and corresponding target labels are replaced using MLM. We also apply a retrieval-based approach, where model input is augmented with similar training samples. As a result, we achieved exact match (EM) accuracy 63.3/75.0 (average: 69.15) for reminder/weather domain, and won the 1st place at the challenge.
isOpenAccess: True
TL\DR: This system for the low-resource domain adaptation track (Track 3) in Spoken Language Understanding Grand Challenge, which is a part of ICASSP Signal Processing Grand Challenge 2023, adopts a pipeline approach of ASR and NLU and applies masked LM (MLM) -based data augmentation.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: b524ec331cd9708b125fad70d95d36189fa0d7b6
paper_title: A Study on the Integration of Pipeline and E2E SLU Systems for Spoken Semantic Parsing Toward Stop Quality Challenge
publication_link: https://arxiv.org/pdf/2305.01620 
year_published: 2023 
abstract_paper:Recently there have been efforts to introduce new benchmark tasks for spoken language understanding (SLU), like semantic parsing. In this paper, we describe our proposed spoken semantic parsing system for the quality track (Track 1) in Spoken Language Understanding Grand Challenge which is part of ICASSP Signal Processing Grand Challenge 2023. We experiment with both end-to-end and pipeline systems for this task. Strong automatic speech recognition (ASR) models like Whisper and pretrained Language models (LM) like BART are utilized inside our SLU framework to boost performance. We also investigate the output level combination of various models to get an exact match accuracy of 80.8, which won the 1st place at the challenge.
isOpenAccess: True
TL\DR: This paper describes the proposed spoken semantic parsing system for the quality track (Track 1) in Spoken Language Understanding Grand Challenge which is part of ICASSP Signal Processing Grand Challenge 2023.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: b88a84fb2d35eecb5149caa3d0596942ae0a5a54
paper_title: A community cluster of influenza A(H3N2) virus infection with reduced susceptibility to baloxavir due to a PA E199G substitution in Japan, February to March 2023
publication_link: https://www.eurosurveillance.org/deliver/fulltext/eurosurveillance/28/39/eurosurv-28-39-1.pdf?itemId=%2Fcontent%2F10.2807%2F1560-7917.ES.2023.28.39.2300501&mimeType=pdf&containerItemId=content/eurosurveillance 
year_published: 2023 
abstract_paper:A community cluster of influenza A(H3N2) caused by viruses with an E199G substitution in PA was detected in Nara, Japan, between February and March 2023. The three patients with these mutant viruses had not received antiviral treatment before specimen collection but patients in the same hospital had. The sequences of the mutant viruses were closely related, suggesting clonal spread in Nara. They showed reduced susceptibility to baloxavir in vitro; however, the clinical significance of the PA E199G substitution remains unclear.
isOpenAccess: True
TL\DR: A community cluster of influenza A(H3N2) caused by viruses with an E199G substitution in PA was detected in Nara, Japan, between February and March 2023 and showed reduced susceptibility to baloxavir in vitro; however, the clinical significance remains unclear.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: bb4c59fc93d5be6b3d85dfde9d08e3dab80db9b7
paper_title: Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study
publication_link: https://arxiv.org/pdf/2309.15800 
year_published: 2023 
abstract_paper:Speech signals, typically sampled at rates in the tens of thousands per second, contain redundancies, evoking inefficiencies in sequence modeling. High-dimensional speech features such as spectrograms are often used as the input for the subsequent model. However, they can still be redundant. Recent investigations proposed the use of discrete speech units derived from self-supervised learning representations, which significantly compresses the size of speech data. Applying various methods, such as de-duplication and subword modeling, can further compress the speech sequence length. Hence, training time is significantly reduced while retaining notable performance. In this study, we undertake a comprehensive and systematic exploration into the application of discrete units within end-to-end speech processing models. Experiments on 12 automatic speech recognition, 3 speech translation, and 1 spoken language understanding corpora demonstrate that discrete units achieve reasonably good results in almost all the settings. We intend to release our configurations and trained models to foster future research efforts.
isOpenAccess: True
TL\DR: This study undertake a comprehensive and systematic exploration into the application of discrete units within end-to-end speech processing models, demonstrating that discrete units achieve reasonably good results in almost all the settings.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: bc3690edd40cc9946f8162727b357b926d1127bc
paper_title: Joint Modelling of Spoken Language Understanding Tasks with Integrated Dialog History
publication_link: https://arxiv.org/pdf/2305.00926 
year_published: 2023 
abstract_paper:Most human interactions occur in the form of spoken conversations where the semantic meaning of a given utterance depends on the context. Each utterance in spoken conversation can be represented by many semantic and speaker attributes, and there has been an interest in building Spoken Language Understanding (SLU) systems for automatically predicting these attributes. Recent work has shown that incorporating dialogue history can help advance SLU performance. However, separate models are used for each SLU task, leading to an increase in inference time and computation cost. Motivated by this, we aim to ask: can we jointly model all the SLU tasks while incorporating context to facilitate low-latency and lightweight inference? To answer this, we propose a novel model architecture that learns dialog context to jointly predict the intent, dialog act, speaker role, and emotion for the spoken utterance. Note that our joint prediction is based on an autoregressive model and we need to decide the prediction order of dialog attributes, which is not trivial. To mitigate the issue, we also propose an order agnostic training method. Our experiments show that our joint model achieves similar results to task-specific classifiers and can effectively integrate dialog context to further improve the SLU performance.1
isOpenAccess: True
TL\DR: A novel model architecture is proposed that learns dialog context to jointly predict the intent, dialog act, speaker role, and emotion for the spoken utterance and achieves similar results to task-specific classifiers and can effectively integrateDialog context to further improve the SLU performance.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: c2745e86ecc9bec372690cced53ccfdf44f407f8
paper_title: Enhancing End-to-End Conversational Speech Translation Through Target Language Context Utilization
publication_link: https://arxiv.org/pdf/2309.15686 
year_published: 2023 
abstract_paper:Incorporating longer context has been shown to benefit machine translation, but the inclusion of context in end-to-end speech translation (E2E-ST) remains under-studied. To bridge this gap, we introduce target language context in E2E-ST, enhancing coherence and overcoming memory constraints of extended audio segments. Additionally, we propose context dropout to ensure robustness to the absence of context, and further improve performance by adding speaker information. Our proposed contextual E2E-ST outperforms the isolated utterance-based E2E-ST approach. Lastly, we demonstrate that in conversational speech, contextual information primarily contributes to capturing context style, as well as resolving anaphora and named entities.
isOpenAccess: True
TL\DR: This work introduces target language context in E2E-ST, enhancing coherence and overcoming memory constraints of extended audio segments, and proposes context dropout to ensure robustness to the absence of context, and improves performance by adding speaker information.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: c6f5da5eb57457457a49256f1434bf1db23d1898
paper_title: Challenges of Corporate Alliance CLOMA toward Plastic Litter
publication_link: https://www.jstage.jst.go.jp/article/oleoscience/23/1/23_29/_pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: c823c04a6488673f936d72906130f170017288d0
paper_title: The Multimodal Information Based Speech Processing (MISP) 2023 Challenge: Audio-Visual Target Speaker Extraction
publication_link: https://arxiv.org/pdf/2309.08348 
year_published: 2023 
abstract_paper:Previous Multimodal Information based Speech Processing (MISP) challenges mainly focused on audio-visual speech recognition (AVSR) with commendable success. However, the most advanced back-end recognition systems often hit performance limits due to the complex acoustic environments. This has prompted a shift in focus towards the Audio-Visual Target Speaker Extraction (AVTSE) task for the MISP 2023 challenge in ICASSP 2024 Signal Processing Grand Challenges. Unlike existing audio-visual speech enhance-ment challenges primarily focused on simulation data, the MISP 2023 challenge uniquely explores how front-end speech processing, combined with visual clues, impacts back-end tasks in real-world scenarios. This pioneering effort aims to set the first benchmark for the AVTSE task, offering fresh insights into enhancing the ac-curacy of back-end speech recognition systems through AVTSE in challenging and real acoustic environments. This paper delivers a thorough overview of the task setting, dataset, and baseline system of the MISP 2023 challenge. It also includes an in-depth analysis of the challenges participants may encounter. The experimental results highlight the demanding nature of this task, and we look forward to the innovative solutions participants will bring forward.
isOpenAccess: True
TL\DR: A thorough overview of the task setting, dataset, and baseline system of the MISP 2023 challenge is delivered, offering fresh insights into enhancing the ac-curacy of back-end speech recognition systems through AVTSE in challenging and real acoustic environments.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: d43338451cd8676548811e1ff8f9c92ea987c5bd
paper_title: Reproducing Whisper-Style Training Using An Open-Source Toolkit And Publicly Available Data
publication_link: https://arxiv.org/pdf/2309.13876 
year_published: 2023 
abstract_paper:Pre-training speech models on large volumes of data has achieved remarkable success. OpenAI Whisper is a multilingual multitask model trained on 680k hours of supervised speech data. It generalizes well to various speech recognition and translation benchmarks even in a zero-shot setup. However, the full pipeline for developing such models (from data collection to training) is not publicly accessible, which makes it difficult for researchers to further improve its performance and address training-related issues such as efficiency, robustness, fairness, and bias. This work presents an Open Whisper-style Speech Model (OWSM), which reproduces Whisperstyle training using an open-source toolkit and publicly available data. OWSM even supports more translation directions and can be more efficient to train. We will publicly release all scripts used for data preparation, training, inference, and scoring as well as pretrained models and training logs to promote open science. 11https://github.com/espnet/espnet
isOpenAccess: True
TL\DR: This work presents an Open Whisper-style Speech Model (OWSM), which reproduces Whisperstyle training using an open-source toolkit and publicly available data and even supports more translation directions and can be more efficient to train.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: d4d5fe4a35e9de845877015075f727415e83d18f
paper_title: The CHiME-7 DASR Challenge: Distant Meeting Transcription with Multiple Devices in Diverse Scenarios
publication_link: https://arxiv.org/pdf/2306.13734 
year_published: 2023 
abstract_paper:The CHiME challenges have played a significant role in the development and evaluation of robust automatic speech recognition (ASR) systems. We introduce the CHiME-7 distant ASR (DASR) task, within the 7th CHiME challenge. This task comprises joint ASR and diarization in far-field settings with multiple, and possibly heterogeneous, recording devices. Different from previous challenges, we evaluate systems on 3 diverse scenarios: CHiME-6, DiPCo, and Mixer 6. The goal is for participants to devise a single system that can generalize across different array geometries and use cases with no a-priori information. Another departure from earlier CHiME iterations is that participants are allowed to use open-source pre-trained models and datasets. In this paper, we describe the challenge design, motivation, and fundamental research questions in detail. We also present the baseline system, which is fully array-topology agnostic and features multi-channel diarization, channel selection, guided source separation and a robust ASR model that leverages self-supervised speech representations (SSLR).
isOpenAccess: True
TL\DR: The ChiME-7 distant ASR (DASR) task, within the 7th CHiME challenge, is introduced and the baseline system is presented, which is fully array-topology agnostic and features multi-channel diarization, channel selection, guided source separation and a robust ASR model that leverages self-supervised speech representations (SSLR).
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: d8728d62b238b09630309c1df723036db84bac10
paper_title: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing
publication_link: https://arxiv.org/pdf/2309.15826 
year_published: 2023 
abstract_paper:Recent works in end-to-end speech-to-text translation (ST) have proposed multi-tasking methods with soft parameter sharing which leverage machine translation (MT) data via secondary encoders that map text inputs to an eventual cross-modal representation. In this work, we instead propose a ST/MT multi-tasking framework with hard parameter sharing in which all model parameters are shared cross-modally. Our method reduces the speech-text modality gap via a pre-processing stage which converts speech and text inputs into two discrete token sequences of similar length -- this allows models to indiscriminately process both modalities simply using a joint vocabulary. With experiments on MuST-C, we demonstrate that our multi-tasking framework improves attentional encoder-decoder, Connectionist Temporal Classification (CTC), transducer, and joint CTC/attention models by an average of +0.5 BLEU without any external MT data. Further, we show that this framework incorporates external MT data, yielding +0.8 BLEU, and also improves transfer learning from pre-trained textual models, yielding +1.8 BLEU.
isOpenAccess: True
TL\DR: This work proposes a ST/MT multi-tasking framework with hard parameter sharing in which all model parameters are shared cross-modally and reduces the speech-text modality gap via a pre-processing stage which converts speech and text inputs into two discrete token sequences of similar length.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: dab8e7dc79085774eea58bcb9ea2ed0ee20377eb
paper_title: ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit
publication_link: https://arxiv.org/pdf/2304.04596 
year_published: 2023 
abstract_paper:ESPnet-ST-v2 is a revamp of the open-source ESPnet-ST toolkit necessitated by the broadening interests of the spoken language translation community. ESPnet-ST-v2 supports 1) offline speech-to-text translation (ST), 2) simultaneous speech-to-text translation (SST), and 3) offline speech-to-speech translation (S2ST) – each task is supported with a wide variety of approaches, differentiating ESPnet-ST-v2 from other open source spoken language translation toolkits. This toolkit offers state-of-the-art architectures such as transducers, hybrid CTC/attention, multi-decoders with searchable intermediates, time-synchronous blockwise CTC/attention, Translatotron models, and direct discrete unit models. In this paper, we describe the overall design, example models for each task, and performance benchmarking behind ESPnet-ST-v2, which is publicly available at https://github.com/espnet/espnet.
isOpenAccess: True
TL\DR: The overall design, example models for each task, and performance benchmarking behind ESPnet-ST-v2 are described, which is publicly available at https://github.com/espnet/esp net.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: dd5d797b837005fac464bb19b9396bddba61c0d8
paper_title: Multi-Channel Target Speaker Extraction with Refinement: The WavLab Submission to the Second Clarity Enhancement Challenge
publication_link: http://arxiv.org/pdf/2302.07928 
year_published: 2023 
abstract_paper:This paper describes our submission to the Second Clarity Enhancement Challenge (CEC2), which consists of target speech enhancement for hearing-aid (HA) devices in noisy-reverberant environments with multiple interferers such as music and competing speakers. Our approach builds upon the powerful iterative neural/beamforming enhancement (iNeuBe) framework introduced in our recent work, and this paper extends it for target speaker extraction. We therefore name the proposed approach as iNeuBe-X, where the X stands for extraction. To address the challenges encountered in the CEC2 setting, we introduce four major novelties: (1) we extend the state-of-the-art TF-GridNet model, originally designed for monaural speaker separation, for multi-channel, causal speech enhancement, and large improvements are observed by replacing the TCNDenseNet used in iNeuBe with this new architecture; (2) we leverage a recent dual window size approach with future-frame prediction to ensure that iNueBe-X satisfies the 5 ms constraint on algorithmic latency required by CEC2; (3) we introduce a novel speaker-conditioning branch for TF-GridNet to achieve target speaker extraction; (4) we propose a fine-tuning step, where we compute an additional loss with respect to the target speaker signal compensated with the listener audiogram. Without using external data, on the official development set our best model reaches a hearing-aid speech perception index (HASPI) score of 0.942 and a scale-invariant signal-to-distortion ratio improvement (SI-SDRi) of 18.8 dB. These results are promising given the fact that the CEC2 data is extremely challenging (e.g., on the development set the mixture SI-SDR is -12.3 dB). A demo of our submitted system is available at WAVLab CEC2 demo.
isOpenAccess: True
TL\DR: The approach builds upon the powerful iterative neural/beamforming enhancement (iNeuBe) framework introduced in recent work, and this paper extends it for target speaker extraction, and is named as iNeu be-X, where the X stands for extraction.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: debb65ab30ceef2faef0e4af560a67f2abd03d14
paper_title: Fully Unsupervised Topic Clustering of Unlabelled Spoken Audio Using Self-Supervised Representation Learning and Topic Model
publication_link: Not given 
year_published: 2023 
abstract_paper:Unsupervised topic clustering of spoken audio is an important research topic for zero-resourced unwritten languages. A classical approach is to find a set of spoken terms from only the audio based on dynamic time warping or generative modeling (e.g., hidden Markov model), and apply a topic model to classify topics. The spoken term discovery is the most important and difficult part. In this paper, we propose to combine self-supervised representation learning (SSRL) methods as a component of spoken term discovery and probabilistic topic models. Most SSRL methods pre-train a model which predicts high-quality pseudo labels generated from an audio-only corpus. These pseudo labels can be used to produce a sequence of pseudo subwords by applying deduplication and a subword model. Then, we apply a topic model based on latent Dirichlet allocation for these pseudo-subword sequences in an unsupervised manner. The clustering performance is evaluated on the Fisher corpus using normalized mutual information. We confirm the improvement of the proposed method and its effectiveness compared to an existing approach using dynamic time warping and topic models although the experimental setups are not directly comparable.
isOpenAccess: True
TL\DR: This paper proposes to combine self-supervised representation learning (SSRL) methods as a component of spoken term discovery and probabilistic topic models and confirms the improvement of the proposed method and its effectiveness compared to an existing approach using dynamic time warping and topic models.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: e146e5221c124d93f69516c5ae7e1b7b1822848e
paper_title: TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement
publication_link: https://arxiv.org/pdf/2302.08088 
year_published: 2023 
abstract_paper:Speech enhancement models have greatly progressed in recent years, but still show limits in perceptual quality of their speech outputs. We propose an objective for perceptual quality based on temporal acoustic parameters. These are fundamental speech features that play an essential role in various applications, including speaker recognition and paralinguistic analysis. We provide a differentiable estimator for four categories of low-level acoustic descriptors involving: frequency-related parameters, energy or amplitude-related parameters, spectral balance parameters, and temporal features. Un-like prior work that looks at aggregated acoustic parameters or a few categories of acoustic parameters, our temporal acoustic parameter (TAP) loss enables auxiliary optimization and improvement of many fine-grained speech characteristics in enhancement workflows. We show that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility. We use data from the Deep Noise Suppression 2020 Challenge to demonstrate that both time-domain models and time-frequency domain models can benefit from our method.
isOpenAccess: True
TL\DR: This paper proposes to combine self-supervised representation learning (SSRL) methods as a component of spoken term discovery and probabilistic topic models and confirms the improvement of the proposed method and its effectiveness compared to an existing approach using dynamic time warping and topic models.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: e25f6a60211aa74ecfde8001a5939ff206102de4
paper_title: End-to-End Speech Recognition: A Survey
publication_link: https://ieeexplore.ieee.org/ielx7/6570655/6633080/10301513.pdf 
year_published: 2023 
abstract_paper:In the last decade of automatic speech recognition (ASR) research, the introduction of deep learning has brought considerable reductions in word error rate of more than 50% relative, compared to modeling without deep learning. In the wake of this transition, a number of all-neural ASR architectures have been introduced. These so-called end-to-end (E2E) models provide highly integrated, completely neural ASR models, which rely strongly on general machine learning knowledge, learn more consistently from data, with lower dependence on ASR domain-specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.
isOpenAccess: True
TL\DR: A taxonomy of E2E ASR models and corresponding improvements is provided, and their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures are discussed.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: e2826002978af39afce7529f172ffdc222342651
paper_title: The Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition
publication_link: https://repository.tudelft.nl/islandora/object/uuid%3A3e54aaa0-46f8-4411-a5ca-351a314d73ce/datastream/OBJ/download 
year_published: 2023 
abstract_paper:The Multi-modal Information based Speech Processing (MISP) challenge aims to extend the application of signal processing technology in specific scenarios by promoting the research into wake-up words, speaker diarization, speech recognition, and other technologies. The MISP2022 challenge has two tracks: 1) audio-visual speaker diarization (AVSD), aiming to solve "who spoken when" using both audio and visual data; 2) a novel audio-visual diarization and recognition (AVDR) task that focuses on addressing "who spoken what when" with audio-visual speaker diarization results. Both tracks focus on the Chinese language, and use far-field audio and video in real home-tv scenarios: 2-6 people communicating each other with TV noise in the background. This paper introduces the dataset, track settings, and baselines of the MISP2022 challenge. Our analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, and the indistinguishable speakers.
isOpenAccess: True
TL\DR: The dataset, track settings, and baselines of the MISP2022 challenge are introduced, and analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, andThe indistinguishable speakers.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: e4f2d75856ce149b994f079ae50fd33ca47245d3
paper_title: DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models
publication_link: http://arxiv.org/pdf/2305.17651 
year_published: 2023 
abstract_paper:Self-supervised learning (SSL) has achieved notable success in many speech processing tasks, but the large model size and heavy computational cost hinder the deployment. Knowledge distillation trains a small student model to mimic the behavior of a large teacher model. However, the student architecture usually needs to be manually designed and will remain fixed during training, which requires prior knowledge and can lead to suboptimal performance. Inspired by recent success of task-specific structured pruning, we propose DPHuBERT, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning. Experiments on SUPERB show that DPHuBERT outperforms pure distillation methods in almost all tasks. Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models. Our code and models will be publicly available.
isOpenAccess: True
TL\DR: DPHuBERT is proposed, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning that requires little training time and performs well with limited training data, making it suitable for resource-constrained applications.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: e64d4b29a4a6ccac3673b4cedbefa1e54e774c20
paper_title: An external quality assessment feasibility study; cross laboratory comparison of haemagglutination inhibition assay and microneutralization assay performance for seasonal influenza serology testing: A FLUCOP study
publication_link: https://www.frontiersin.org/articles/10.3389/fimmu.2023.1129765/pdf 
year_published: 2023 
abstract_paper:Introduction External Quality Assessment (EQA) schemes are designed to provide a snapshot of laboratory proficiency, identifying issues and providing feedback to improve laboratory performance and inter-laboratory agreement in testing. Currently there are no international EQA schemes for seasonal influenza serology testing. Here we present a feasibility study for conducting an EQA scheme for influenza serology methods. Methods We invited participant laboratories from industry, contract research organizations (CROs), academia and public health institutions who regularly conduct hemagglutination inhibition (HAI) and microneutralization (MN) assays and have an interest in serology standardization. In total 16 laboratories returned data including 19 data sets for HAI assays and 9 data sets for MN assays. Results Within run analysis demonstrated good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays. Between run analysis showed laboratory and strain specific issues, particularly with B strains for HAI, whilst MN testing was consistently good across labs and strains. Inter-laboratory variability was higher for MN assays than HAI, however both assays showed a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization. Discussion This study has received positive feedback from participants, highlighting the benefit such an EQA scheme would have on improving laboratory performance, reducing inter laboratory variation and raising awareness of both harmonized protocol use and the benefit of biological standards for seasonal influenza serology testing.
isOpenAccess: True
TL\DR: A feasibility study for conducting an EQA scheme for influenza serology methods showing good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays, and a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: ebb75ff5b5e55ba15e4239ed0ffa6ff2ad00b721
paper_title: Multi-Channel Speaker Extraction with Adversarial Training: The Wavlab Submission to The Clarity ICASSP 2023 Grand Challenge
publication_link: Not given 
year_published: 2023 
abstract_paper:In this work we detail our submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments. Our system builds on our previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X, which consists in an iterative neural/conventional beamforming enhancement pipeline, guided by an enrollment utterance from the target speaker. This model, which won by a large margin the CEC2, is an extension of the state-of-the-art TF-GridNet model for multi-channel, streamable target-speaker speech enhancement. Here, this approach is extended and further improved by leveraging generative adversarial training, which we show proves especially useful when the training data is limited. Using only the official 6k training scenes data, our best model achieves 0.80 hearing-aid speech perception index (HASPI) and 0.41 hearing-aid speech quality index (HASQI) scores on the synthetic evaluation set. However, our model generalized poorly on the semi-real evaluation set. This highlights the fact that our community should focus more on real-world evaluation and less on fully synthetic datasets.
isOpenAccess: True
TL\DR: This work details the submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments, and builds on the previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: ef567580e167c3e7c546345df93d644be5d4f66f
paper_title: AV-SUPERB: A Multi-Task Evaluation Benchmark for Audio-Visual Representation Models
publication_link: https://arxiv.org/pdf/2309.10787 
year_published: 2023 
abstract_paper:Audio-visual representation learning aims to develop systems with human-like perception by utilizing correlation between auditory and visual information. However, current models often focus on a limited set of tasks, and generalization abilities of learned representations are unclear. To this end, we propose the AV-SUPERB benchmark that enables general-purpose evaluation of unimodal audio/visual and bimodal fusion representations on 7 datasets covering 5 audio-visual tasks in speech and audio processing. We evaluate 5 recent self-supervised models and show that none of these models generalize to all tasks, emphasizing the need for future study on improving universal model performance. In addition, we show that representations may be improved with intermediate-task fine-tuning and audio event classification with AudioSet serves as a strong intermediate task. We release our benchmark with evaluation code and a model submission platform to encourage further research in audio-visual learning.
isOpenAccess: True
TL\DR: The AV-SUPERB benchmark is proposed that enables general-purpose evaluation of unimodal audio/visual and bimodal fusion representations on 7 datasets covering 5 audio-visual tasks in speech and audio processing and shows that representations may be improved with intermediate-task fine-tuning and audio event classification with AudioSet serves as a strong intermediate task.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: ef8b095292a8e38e9b8f56c54cbf3c67c3ed425d
paper_title: Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation
publication_link: http://arxiv.org/pdf/2305.07455 
year_published: 2023 
abstract_paper:Most of the speech translation models heavily rely on parallel data, which is hard to collect especially for low-resource languages. To tackle this issue, we propose to build a cascaded speech translation system without leveraging any kind of paired data. We use fully unpaired data to train our unsupervised systems and evaluate our results on CoVoST 2 and CVSS. The results show that our work is comparable with some other early supervised methods in some language pairs. While cascaded systems always suffer from severe error propagation problems, we proposed denoising back-translation (DBT), a novel approach to building robust unsupervised neural machine translation (UNMT). DBT successfully increases the BLEU score by 0.7--0.9 in all three translation directions. Moreover, we simplified the pipeline of our cascaded system to reduce inference latency and conducted a comprehensive analysis of every part of our work. We also demonstrate our unsupervised speech translation results on the established website.
isOpenAccess: True
TL\DR: This work proposed denoising back-translation (DBT), a novel approach to building robust unsupervised neural machine translation (UNMT), which successfully increases the BLEU score by 0.7--0.9 in all three translation directions.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: f53b6f5a85f2d74deb32022795b5dab0aa753cf4
paper_title: Deep Speech Synthesis from MRI-Based Articulatory Representations
publication_link: https://arxiv.org/pdf/2307.02471 
year_published: 2023 
abstract_paper:In this paper, we study articulatory synthesis, a speech synthesis method using human vocal tract information that offers a way to develop efficient, generalizable and interpretable synthesizers. While recent advances have enabled intelligible articulatory synthesis using electromagnetic articulography (EMA), these methods lack critical articulatory information like excitation and nasality, limiting generalization capabilities. To bridge this gap, we propose an alternative MRI-based feature set that covers a much more extensive articulatory space than EMA. We also introduce normalization and denoising procedures to enhance the generalizability of deep learning methods trained on MRI data. Moreover, we propose an MRI-to-speech model that improves both computational efficiency and speech fidelity. Finally, through a series of ablations, we show that the proposed MRI representation is more comprehensive than EMA and identify the most suitable MRI feature subset for articulatory synthesis.
isOpenAccess: True
TL\DR: This work proposed denoising back-translation (DBT), a novel approach to building robust unsupervised neural machine translation (UNMT), which successfully increases the BLEU score by 0.7--0.9 in all three translation directions.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: f7e995c3cae465963ecaa8c9b4ce8b9b4323a71b
paper_title: FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN
publication_link: https://aclanthology.org/2023.iwslt-1.1.pdf 
year_published: 2023 
abstract_paper:This paper reports on the shared tasks organized by the 20th IWSLT Conference. The shared tasks address 9 scientific challenges in spoken language translation: simultaneous and offline translation, automatic subtitling and dubbing, speech-to-speech translation, multilingual, dialect and low-resource speech translation, and formality control. The shared tasks attracted a total of 38 submissions by 31 teams. The growing interest towards spoken language translation is also witnessed by the constantly increasing number of shared task organizers and contributors to the overview paper, almost evenly distributed across industry and academia.
isOpenAccess: True
TL\DR: This work proposed denoising back-translation (DBT), a novel approach to building robust unsupervised neural machine translation (UNMT), which successfully increases the BLEU score by 0.7--0.9 in all three translation directions.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: fa5ebb425c57f6c4f1c36a7200ef1da867346e8c
paper_title: Speech collage: code-switched audio generation by collaging monolingual corpora
publication_link: https://arxiv.org/pdf/2309.15674 
year_published: 2023 
abstract_paper:Designing effective automatic speech recognition (ASR) systems for Code-Switching (CS) often depends on the availability of the transcribed CS resources. To address data scarcity, this paper introduces Speech Collage, a method that synthesizes CS data from monolingual corpora by splicing audio segments. We further improve the smoothness quality of audio generation using an overlap-add approach. We investigate the impact of generated data on speech recognition in two scenarios: using in-domain CS text and a zero-shot approach with synthesized CS text. Empirical results highlight up to 34.4% and 16.2% relative reductions in Mixed-Error Rate and Word-Error Rate for in-domain and zero-shot scenarios, respectively. Lastly, we demonstrate that CS augmentation bolsters the model's code-switching inclination and reduces its monolingual bias.
isOpenAccess: True
TL\DR: Speech Collage is introduced, a method that synthesizes CS data from monolingual corpora by splicing audio segments that improves the smoothness quality of audio generation using an overlap-add approach and demonstrates that CS augmentation bolsters the model's code-switching inclination and reduces itsmonolingual bias.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 1746678
paper_id: fa75ef55e04e3b25b8af56435478c2fd17403ce8
paper_title: Exploration on HuBERT with Multiple Resolutions
publication_link: http://arxiv.org/pdf/2306.01084 
year_published: 2023 
abstract_paper:Hidden-unit BERT (HuBERT) is a widely-used self-supervised learning (SSL) model in speech processing. However, we argue that its fixed 20ms resolution for hidden representations would not be optimal for various speech-processing tasks since their attributes (e.g., speaker characteristics and semantics) are based on different time scales. To address this limitation, we propose utilizing HuBERT representations at multiple resolutions for downstream tasks. We explore two approaches, namely the parallel and hierarchical approaches, for integrating HuBERT features with different resolutions. Through experiments, we demonstrate that HuBERT with multiple resolutions outperforms the original model. This highlights the potential of utilizing multiple resolutions in SSL models like HuBERT to capture diverse information from speech signals.
isOpenAccess: True
TL\DR: Through experiments, it is demonstrated that HuBERT with multiple resolutions outperforms the original model, highlighting the potential of utilizing multiple resolutions in SSL models like HuberT to capture diverse information from speech signals.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2187876006
paper_id: 0c7018db4a00df1792a7b3de3cb0b48aa19ca041
paper_title: Integrating Pretrained ASR and LM to Perform Sequence Generation for Spoken Language Understanding
publication_link: https://arxiv.org/pdf/2307.11005 
year_published: 2023 
abstract_paper:There has been an increased interest in the integration of pretrained speech recognition (ASR) and language models (LM) into the SLU framework. However, prior methods often struggle with a vocabulary mismatch between pretrained models, and LM cannot be directly utilized as they diverge from its NLU formulation. In this study, we propose a three-pass end-to-end (E2E) SLU system that effectively integrates ASR and LM subnetworks into the SLU formulation for sequence generation tasks. In the first pass, our architecture predicts ASR transcripts using the ASR subnetwork. This is followed by the LM subnetwork, which makes an initial SLU prediction. Finally, in the third pass, the deliberation subnetwork conditions on representations from the ASR and LM subnetworks to make the final prediction. Our proposed three-pass SLU system shows improved performance over cascaded and E2E SLU models on two benchmark SLU datasets, SLURP and SLUE, especially on acoustically challenging utterances.
isOpenAccess: True
TL\DR: Through experiments, it is demonstrated that HuBERT with multiple resolutions outperforms the original model, highlighting the potential of utilizing multiple resolutions in SSL models like HuberT to capture diverse information from speech signals.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2187876006
paper_id: 1dc2d0f43df7f7a7847817203411357eca79a5b3
paper_title: Reducing Barriers to Self-Supervised Learning: HuBERT Pre-training with Academic Compute
publication_link: http://arxiv.org/pdf/2306.06672 
year_published: 2023 
abstract_paper:Self-supervised learning (SSL) has led to great strides in speech processing. However, the resources needed to train these models has become prohibitively large as they continue to scale. Currently, only a few groups with substantial resources are capable of creating SSL models, which harms reproducibility. In this work, we optimize HuBERT SSL to fit in academic constraints. We reproduce HuBERT independently from the original implementation, with no performance loss. Our code and training optimizations make SSL feasible with only 8 GPUs, instead of the 32 used in the original work. We also explore a semi-supervised route, using an ASR model to skip the first pre-training iteration. Within one iteration of pre-training, our models improve over HuBERT on several tasks. Furthermore, our HuBERT Large variant requires only 8 GPUs, achieving similar performance to the original trained on 128. As our contribution to the community, all models, configurations, and code are made open-source in ESPnet.
isOpenAccess: True
TL\DR: Through experiments, it is demonstrated that HuBERT with multiple resolutions outperforms the original model, highlighting the potential of utilizing multiple resolutions in SSL models like HuberT to capture diverse information from speech signals.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2187876006
paper_id: 25b28a08a75ad0e6c8ed27f48c59199fba15fcbd
paper_title: FindAdaptNet: Find and Insert Adapters by Learned Layer Importance
publication_link: Not given 
year_published: 2023 
abstract_paper:Adapters are lightweight bottleneck modules introduced to assist pre-trained self-supervised learning (SSL) models to be customized to new tasks. However, searching the appropriate layers to insert adapters on large models has become difficult due to the large number of possible layers and thus a vast search space (2N possibilities for N layers). In this paper, we propose a technique that achieves automatic insertion of adapters for downstream automatic speech recognition (ASR) and spoken language understanding (SLU) tasks. Our approach is based on two-stage training. First, we train our model for a specific downstream task with additional shallow learnable layers and weight parameters to obtain the weighted summation over the output of each layer in SSL. This training method is established by the SUPERB baseline [1]. This first-stage training determines the most important layers given their respective weights. In the second stage, we proceed to insert adapters to the most important layers, retaining both performance and neural architecture search efficiency. On the CommonVoice dataset[2] we obtain 20.6% absolute improvement in Word Error Rate (WER) on the Welsh language against the conventional method, which inserts the adapter modules into the highest layers without search. In the SLURP SLU task, our method yields 4.0% intent accuracy improvement against the same conventional baseline.
isOpenAccess: True
TL\DR: Through experiments, it is demonstrated that HuBERT with multiple resolutions outperforms the original model, highlighting the potential of utilizing multiple resolutions in SSL models like HuberT to capture diverse information from speech signals.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2187876006
paper_id: 3c01b59cd923192913bb96849a892c5732c40d3d
paper_title: CMU’s IWSLT 2023 Simultaneous Speech Translation System
publication_link: https://aclanthology.org/2023.iwslt-1.20.pdf 
year_published: 2023 
abstract_paper:This paper describes CMU’s submission to the IWSLT 2023 simultaneous speech translation shared task for translating English speech to both German text and speech in a streaming fashion. We first build offline speech-to-text (ST) models using the joint CTC/attention framework. These models also use WavLM front-end features and mBART decoder initialization. We adapt our offline ST models for simultaneous speech-to-text translation (SST) by 1) incrementally encoding chunks of input speech, re-computing encoder states for each new chunk and 2) incrementally decoding output text, pruning beam search hypotheses to 1-best after processing each chunk. We then build text-to-speech (TTS) models using the VITS framework and achieve simultaneous speech-to-speech translation (SS2ST) by cascading our SST and TTS models.
isOpenAccess: True
TL\DR: CMU’s submission to the IWSLT 2023 simultaneous speech translation shared task for translating English speech to both German text and speech in a streaming fashion is described.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2187876006
paper_id: 47ba7df38e24da9bad9266d2b58abbb2b70db6e5
paper_title: Exploration of Efficient End-to-End ASR using Discretized Input from Self-Supervised Learning
publication_link: http://arxiv.org/pdf/2305.18108 
year_published: 2023 
abstract_paper:Self-supervised learning (SSL) of speech has shown impressive results in speech-related tasks, particularly in automatic speech recognition (ASR). While most methods employ the output of intermediate layers of the SSL model as real-valued features for downstream tasks, there is potential in exploring alternative approaches that use discretized token sequences. This approach offers benefits such as lower storage requirements and the ability to apply techniques from natural language processing. In this paper, we propose a new protocol that utilizes discretized token sequences in ASR tasks, which includes de-duplication and sub-word modeling to enhance the input sequence. It reduces computational cost by decreasing the length of the sequence. Our experiments on the LibriSpeech dataset demonstrate that our proposed protocol performs competitively with conventional ASR systems using continuous input features, while reducing computational and storage costs.
isOpenAccess: True
TL\DR: CMU’s submission to the IWSLT 2023 simultaneous speech translation shared task for translating English speech to both German text and speech in a streaming fashion is described.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2187876006
paper_id: 6c2b800cd03ad064922c8596a18d784ce25d47ac
paper_title: Integration of Frame- and Label-synchronous Beam Search for Streaming Encoder-decoder Speech Recognition
publication_link: https://arxiv.org/pdf/2307.12767 
year_published: 2023 
abstract_paper:Although frame-based models, such as CTC and transducers, have an affinity for streaming automatic speech recognition, their decoding uses no future knowledge, which could lead to incorrect pruning. Conversely, label-based attention encoder-decoder mitigates this issue using soft attention to the input, while it tends to overestimate labels biased towards its training domain, unlike CTC. We exploit these complementary attributes and propose to integrate the frame- and label-synchronous (F-/L-Sync) decoding alternately performed within a single beam-search scheme. F-Sync decoding leads the decoding for block-wise processing, while L-Sync decoding provides the prioritized hypotheses using look-ahead future frames within a block. We maintain the hypotheses from both decoding methods to perform effective pruning. Experiments demonstrate that the proposed search algorithm achieves lower error rates compared to the other search methods, while being robust against out-of-domain situations.
isOpenAccess: True
TL\DR: CMU’s submission to the IWSLT 2023 simultaneous speech translation shared task for translating English speech to both German text and speech in a streaming fashion is described.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2187876006
paper_id: ab84b84b4a9641a172f9874108fee07a9f92f988
paper_title: E-Branchformer-Based E2E SLU Toward Stop on-Device Challenge
publication_link: Not given 
year_published: 2023 
abstract_paper:In this paper, we report our team’s study on track 2 of the Spoken Language Understanding Grand Challenge, which is a component of the ICASSP Signal Processing Grand Challenge 2023. The task is intended for on-device processing and involves estimating semantic parse labels from speech using a model with 15 million parameters. We use E2E E-Branchformer-based spoken language understanding model, which is more parameter controllable than cascade models, and reduced the parameter size through sequential distillation and tensor decomposition techniques. On the STOP dataset, we achieved an exact match accuracy of 70.9% under the tight constraint of 15 million parameters.
isOpenAccess: True
TL\DR: E2E E-Branchformer-based spoken language understanding model is used, which is more parameter controllable than cascade models, and the parameter size is reduced through sequential distillation and tensor decomposition techniques.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2187876006
paper_id: d24d60719e90e69749a75c160cb760d1d9fca44a
paper_title: Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff
publication_link: https://arxiv.org/pdf/2309.11379 
year_published: 2023 
abstract_paper:Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultaneous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. However, this method maintains multiple hypotheses until the entire speech input is consumed -- this scheme cannot directly show a single \textit{incremental} translation to users. Further, this method lacks mechanisms for \textit{controlling} the quality vs. latency tradeoff. We propose a modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU improvement without changing latency or 0.8-1.4 s latency improvement without changing quality.
isOpenAccess: True
TL\DR: A modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control is proposed and applied to models trained for online or offline translation and it is demonstrated that both types can be effectively used in online mode.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2187876006
paper_id: d2897d70e1bceaf4799937e4b4aab0a45fc6e20c
paper_title: Bayes Risk Transducer: Transducer with Controllable Alignment Prediction
publication_link: https://arxiv.org/pdf/2308.10107 
year_published: 2023 
abstract_paper:Automatic speech recognition (ASR) based on transducers is widely used. In training, a transducer maximizes the summed posteriors of all paths. The path with the highest posterior is commonly defined as the predicted alignment between the speech and the transcription. While the vanilla transducer does not have a prior preference for any of the valid paths, this work intends to enforce the preferred paths and achieve controllable alignment prediction. Specifically, this work proposes Bayes Risk Transducer (BRT), which uses a Bayes risk function to set lower risk values to the preferred paths so that the predicted alignment is more likely to satisfy specific desired properties. We further demonstrate that these predicted alignments with intentionally designed properties can provide practical advantages over the vanilla transducer. Experimentally, the proposed BRT saves inference cost by up to 46% for non-streaming ASR and reduces overall system latency by 41% for streaming ASR.
isOpenAccess: True
TL\DR: This work proposes Bayes Risk Transducer (BRT), which uses a Bayes risk function to set lower risk values to the preferred paths so that the predicted alignment is more likely to satisfy specific desired properties.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2115592463
paper_id: 4c6bb748e22e2e599faf8fd30821ee03053579b7
paper_title: A Randomized, Double-Blind, Controlled Trial Assessing If Medium-Chain Triglycerides in Combination with Moderate-Intensity Exercise Increase Muscle Strength in Healthy Middle-Aged and Older Adults
publication_link: https://www.mdpi.com/2072-6643/15/14/3275/pdf?version=1690245983 
year_published: 2023 
abstract_paper:An adequate nutritional intake is recommended for the prevention of physical frailty and sarcopenia. In particular, medium-chain fatty acids (MCFAs) are reportedly important for muscle strength in nursing home residents. However, the effects of MCFAs on healthy adults at risk for frailty remain unknown. Hence, a randomized, placebo-controlled study was conducted to investigate the effects of 12 weeks of medium-chain triglycerides (MCTs) intake and walking on muscle mass and function in healthy, sedentary, middle-aged and older adults with a low body mass index. Three MCT intake groups with different amounts of octanoic and decanoic acid intake were compared with a control group. After 12 weeks, knee extension strength increased in all groups, with the increases in all MCT intake groups being significantly higher than those in the control group (p < 0.05). Grip strength significantly increased from baseline in the MCT 6 g/day intake group (p < 0.05). The combination of aerobic exercise and MCT intake may be effective in preventing decline in muscle strength and promoting increase in muscle strength as they can improve muscle energy production, thereby contributing to the maintenance of good health for middle-aged and older adults at high risk for frailty and sarcopenia.
isOpenAccess: True
TL\DR: This work proposes Bayes Risk Transducer (BRT), which uses a Bayes risk function to set lower risk values to the preferred paths so that the predicted alignment is more likely to satisfy specific desired properties.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2253473275
paper_id: 083cf10c0cbf75dd5755a6a2cd971f39e7da75c2
paper_title: UniverSLU: Universal Spoken Language Understanding for Diverse Classification and Sequence Generation Tasks with a Single Network
publication_link: https://arxiv.org/pdf/2310.02973 
year_published: 2023 
abstract_paper:Recent studies have demonstrated promising outcomes by employing large language models with multi-tasking capabilities. They utilize prompts to guide the model's behavior and surpass performance of task-specific models. Motivated by this, we ask: can we build a single model that jointly perform various spoken language understanding (SLU) tasks? To address this, we utilize pre-trained automatic speech recognition (ASR) models and employ various task and dataset specifiers as discrete prompts. We demonstrate efficacy of our single multi-task learning (MTL) model"UniverSLU"for 12 different speech classification and sequence generation tasks across 17 datasets and 9 languages. Results show that UniverSLU achieves competitive performance and even surpasses task-specific models. We also conduct preliminary investigations into enabling human-interpretable natural phrases instead of task specifiers as discrete prompts and test the model's generalization capabilities to new paraphrases.
isOpenAccess: True
TL\DR: This work proposes Bayes Risk Transducer (BRT), which uses a Bayes risk function to set lower risk values to the preferred paths so that the predicted alignment is more likely to satisfy specific desired properties.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2253473275
paper_id: 92b3753e56f5d85fd57a32084f52476839cc7221
paper_title: One model to rule them all ? Towards End-to-End Joint Speaker Diarization and Speech Recognition
publication_link: https://arxiv.org/pdf/2310.01688 
year_published: 2023 
abstract_paper:This paper presents a novel framework for joint speaker diarization (SD) and automatic speech recognition (ASR), named SLIDAR (sliding-window diarization-augmented recognition). SLIDAR can process arbitrary length inputs and can handle any number of speakers, effectively solving ``who spoke what, when'' concurrently. SLIDAR leverages a sliding window approach and consists of an end-to-end diarization-augmented speech transcription (E2E DAST) model which provides, locally, for each window: transcripts, diarization and speaker embeddings. The E2E DAST model is based on an encoder-decoder architecture and leverages recent techniques such as serialized output training and ``Whisper-style"prompting. The local outputs are then combined to get the final SD+ASR result by clustering the speaker embeddings to get global speaker identities. Experiments performed on monaural recordings from the AMI corpus confirm the effectiveness of the method in both close-talk and far-field speech scenarios.
isOpenAccess: True
TL\DR: SLIDAR (sliding-window diarization-augmented recognition) can process arbitrary length inputs and can handle any number of speakers, effectively solving ``who spoke what, when'' concurrently.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2254345384
paper_id: 2126b5497eb51926d0baac655a1e0f88f0d1ec00
paper_title: Antiviral efficacy against and replicative fitness of an XBB.1.9.1 clinical isolate
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: The results suggest that XBB.1.9.2.1 and X BB.1-CoV-2 have similar antigenicity and replicative ability, and that the currently available COVID-19 antivirals remain effective against XBB, even at the highest concentration used.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2256993616
paper_id: bdf9ea3a67691e1b6a362f4019bf80c9cf31cecd
paper_title: Findings of the 2023 ML-Superb Challenge: Pre-Training And Evaluation Over More Languages And Beyond
publication_link: https://arxiv.org/pdf/2310.05513 
year_published: 2023 
abstract_paper:The 2023 Multilingual Speech Universal Performance Benchmark (ML-SUPERB) Challenge expands upon the acclaimed SUPERB framework, emphasizing self-supervised models in multilingual speech recognition and language identification. The challenge comprises a research track focused on applying ML-SUPERB to specific multilingual subjects, a Challenge Track for model submissions, and a New Language Track where language resource researchers can contribute and evaluate their low-resource language data in the context of the latest progress in multilingual speech recognition. The challenge garnered 12 model submissions and 54 language corpora, resulting in a comprehensive benchmark encompassing 154 languages. The findings indicate that merely scaling models is not the definitive solution for multilingual speech tasks, and a variety of speech/voice types present significant challenges in multilingual speech processing.
isOpenAccess: True
TL\DR: The 2023 Multilingual Speech Universal Performance Benchmark (ML-SUPERB) Challenge expands upon the acclaimed SUPERB framework, emphasizing self-supervised models in multilingual speech recognition and language identification, resulting in a comprehensive benchmark encompassing 154 languages.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2237418080
paper_id: eadca5a91a755c9e8dbc1843c435b9c5ab930477
paper_title: Magnetic dynamics and nonreciprocal excitation in uniform hedgehog order in icosahedral 1/1 approximant crystal
publication_link: https://www.nature.com/articles/s41598-023-41292-1.pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: The 2023 Multilingual Speech Universal Performance Benchmark (ML-SUPERB) Challenge expands upon the acclaimed SUPERB framework, emphasizing self-supervised models in multilingual speech recognition and language identification, resulting in a comprehensive benchmark encompassing 154 languages.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2262446874
paper_id: 0b234f749c6aebf5b1ec61fa0b2ac0d348ad08ed
paper_title: TorchAudio 2.1: Advancing Speech Recognition, Self-Supervised Learning, and Audio Processing Components for Pytorch
publication_link: https://arxiv.org/pdf/2310.17864 
year_published: 2023 
abstract_paper:TorchAudio is an open-source audio and speech processing library built for PyTorch. It aims to accelerate the research and development of audio and speech technologies by providing well-designed, easy-to-use, and performant PyTorch components. Its contributors routinely engage with users to understand their needs and fulfill them by developing impactful features. Here, we survey TorchAudio’s development principles and contents and highlight key features we include in its latest version (2.1): self-supervised learning pre-trained pipelines and training recipes, high-performance CTC decoders, speech recognition models and training recipes, advanced media I/O capabilities, and tools for performing forced alignment, multi-channel speech enhancement, and reference-less speech assessment. For a selection of these features, through empirical studies, we demonstrate their efficacy and show that they achieve competitive or state-of-the-art performance.
isOpenAccess: True
TL\DR: TorchAudio’s development principles and contents are surveyed and key features included in its latest version (2.1) are highlighted: self-supervised learning pre-trained pipelines and training recipes, high-performance CTC decoders, speech recognition models and training recipes, advanced media I/O capabilities, and tools for performing forced alignment, multi-channel speech enhancement, and reference-less speech assessment.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2243132102
paper_id: f80c354908efd4d5617878e36e35446016534190
paper_title: Semi-Autoregressive Streaming ASR With Label Context
publication_link: https://arxiv.org/pdf/2309.10926 
year_published: 2023 
abstract_paper:Non-autoregressive (NAR) modeling has gained significant interest in speech processing since these models achieve dramatically lower inference time than autoregressive (AR) models while also achieving good transcription accuracy. Since NAR automatic speech recognition (ASR) models must wait for the completion of the entire utterance before processing, some works explore streaming NAR models based on blockwise attention for low-latency applications. However, streaming NAR models significantly lag in accuracy compared to streaming AR and non-streaming NAR models. To address this, we propose a streaming"semi-autoregressive"ASR model that incorporates the labels emitted in previous blocks as additional context using a Language Model (LM) subnetwork. We also introduce a novel greedy decoding algorithm that addresses insertion and deletion errors near block boundaries while not significantly increasing the inference time. Experiments show that our method outperforms the existing streaming NAR model by 19% relative on Tedlium2, 16%/8% on Librispeech-100 clean/other test sets, and 19%/8% on the Switchboard(SWB)/Callhome(CH) test sets. It also reduced the accuracy gap with streaming AR and non-streaming NAR models while achieving 2.5x lower latency. We also demonstrate that our approach can effectively utilize external text data to pre-train the LM subnetwork to further improve streaming ASR accuracy.
isOpenAccess: True
TL\DR: This work proposes a streaming"semi-autoregressive"ASR model that incorporates the labels emitted in previous blocks as additional context using a Language Model (LM) subnetwork and introduces a novel greedy decoding algorithm that addresses insertion and deletion errors near block boundaries while not significantly increasing the inference time.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2268179931
paper_id: 1ac784bfd7c64b35d4914b80d7974038e3dd092a
paper_title: Effect of medium-chain triglycerides supplements and walking on health-related quality of life in sedentary, healthy middle-aged, and older adults with low BMIs: a randomized, double-blind, placebo-controlled, parallel-group trial
publication_link: https://www.frontiersin.org/articles/10.3389/fnut.2023.1296896/pdf?isPublishedV2=False 
year_published: 2023 
abstract_paper:Introduction To extend individuals’ healthy life expectancies, the improvement of subjective health and quality of life (QOL) has been increasingly prioritized, alongside the improvement of their physical functioning. Reports have indicated that intake of medium-chain triglycerides (MCTs) benefits the physical health of older individuals requiring nursing care, and athletes, and healthy individuals. But there are few studies investigating the effects of MCTs on subjective health and QOL. The present study sought to evaluate the combined effects of 12-week MCTs supplements and moderate-intensity walking exercise on the subjective health and QOL of middle-aged and older adults aged 60–74 with low BMIs (< 24 kg/m2) and who had no exercise habits. Methods A placebo-controlled, double-blind, parallel-group trial was conducted. Three MCTs supplement groups with different doses and fatty acid compositions were compared with a control group. The study used the SF-36v2 questionnaire to assess subjective health and health-related QOL (HRQOL). Results The result showed significant improvements in the scores on subscales of the physical QOL, such as Physical functioning and General health, and summary scores on the mental QOL, compared to the control. Conclusion It is estimated that the combination of continuous intake of MCTs and walking exercise may affect HRQOL and improve subjective physical and mental health in sedentary, healthy, middle-aged and older adults. Clinical trial registration https://rctportal.niph.go.jp/s/detail/um?trial_id=UMIN000046861, UMIN000046861.
isOpenAccess: True
TL\DR: This work proposes a streaming"semi-autoregressive"ASR model that incorporates the labels emitted in previous blocks as additional context using a Language Model (LM) subnetwork and introduces a novel greedy decoding algorithm that addresses insertion and deletion errors near block boundaries while not significantly increasing the inference time.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2257350031
paper_id: 725cdb03a3d443c1698f6b98966cc78eaa53809b
paper_title: Software Design and User Interface of ESPnet-SE++: Speech Enhancement for Robust Speech Processing
publication_link: https://joss.theoj.org/papers/10.21105/joss.05403.pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2257350031
paper_id: a60faa964c4dc744938c0b7812f7f3701a1250b8
paper_title: A Single Speech Enhancement Model Unifying Dereverberation, Denoising, Speaker Counting, Separation, And Extraction
publication_link: https://arxiv.org/pdf/2310.08277 
year_published: 2023 
abstract_paper:We propose a multi-task universal speech enhancement (MUSE) model that can perform five speech enhancement (SE) tasks: dereverberation, denoising, speech separation (SS), target speaker extraction (TSE), and speaker counting. This is achieved by integrating two modules into an SE model: 1) an internal separation module that does both speaker counting and separation; and 2) a TSE module that extracts the target speech from the internal separation outputs using target speaker cues. The model is trained to perform TSE if the target speaker cue is given and SS otherwise. By training the model to remove noise and reverberation, we allow the model to tackle the five tasks mentioned above with a single model, which has not been accomplished yet. Evaluation results demonstrate that the proposed MUSE model can successfully handle multiple tasks with a single model.
isOpenAccess: True
TL\DR: Evaluation results demonstrate that the proposed MUSE model can successfully handle multiple tasks with a single model, which has not been accomplished yet.
================================
faculty_name: Shinji Watanabe
faculty_authorid: 2253473273
paper_id: 2f9860ab7979516fe2d4b503bb4b0bcdbd045bf2
paper_title: Antigenic drift and subtype interference shape A(H3N2) epidemic dynamics in the United States
publication_link: Not given 
year_published: 2023 
abstract_paper:Influenza viruses continually evolve new antigenic variants, through mutations in epitopes of their major surface proteins, hemagglutinin (HA) and neuraminidase (NA). Antigenic drift potentiates the reinfection of previously infected individuals, but the contribution of this process to variability in annual epidemics is not well understood. Here we link influenza A(H3N2) virus evolution to regional epidemic dynamics in the United States during 1997-2019. We integrate phenotypic measures of HA antigenic drift and sequence-based measures of HA and NA fitness to infer antigenic and genetic distances between viruses circulating in successive seasons. We estimate the magnitude, severity, timing, transmission rate, age-specific patterns, and subtype dominance of each regional outbreak and find that genetic distance based on broad sets of epitope sites is the strongest evolutionary predictor of A(H3N2) virus epidemiology. Increased HA and NA epitope distance between seasons correlates with larger, more intense epidemics, higher transmission, greater A(H3N2) subtype dominance, and a greater proportion of cases in adults relative to children, consistent with increased population susceptibility. Based on random forest models, A(H1N1) incidence impacts A(H3N2) epidemics to a greater extent than viral evolution, suggesting that subtype interference is a major driver of influenza A virus infection dynamics, presumably via heterosubtypic cross-immunity.
isOpenAccess: True
TL\DR: Evaluation results demonstrate that the proposed MUSE model can successfully handle multiple tasks with a single model, which has not been accomplished yet.
================================
faculty_name: Sean Welleck
faculty_authorid: 2129663
paper_id: 3aaf6a2cbad5850ad81ab5c163599cb3d523436f
paper_title: Self-Refine: Iterative Refinement with Self-Feedback
publication_link: http://arxiv.org/pdf/2303.17651 
year_published: 2023 
abstract_paper:Like humans, large language models (LLMs) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an initial output using an LLMs; then, the same LLMs provides feedback for its output and uses it to refine itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner, and feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs. Across all evaluated tasks, outputs generated with Self-Refine are preferred by humans and automatic metrics over those generated with the same LLM using conventional one-step generation, improving by ~20% absolute on average in task performance. Our work demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using our simple, standalone approach.
isOpenAccess: True
TL\DR: Self-Refine is introduced, an approach for improving initial outputs from LLMs through iterative feedback and refinement that demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using this simple, standalone approach.
================================
faculty_name: Sean Welleck
faculty_authorid: 2129663
paper_id: ca991e0283a1c30a46eb585d9eb499fc0ec8ecc2
paper_title: Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning
publication_link: http://arxiv.org/pdf/2305.15065 
year_published: 2023 
abstract_paper:While extreme-scale language models have demonstrated exceptional performance on a variety of language tasks, the degree of control over these language models through pure prompting can often be limited. Directly fine-tuning such language models can be effective for tailoring them, but it can be either extremely costly (e.g., GPT-3) or not even feasible for the broader community (e.g., GPT-4). We propose Inference-time Policy Adapters (IPA), which efficiently tailors a language model such as GPT-3 without fine-tuning it. IPA guides a large base model during decoding time through a lightweight policy adapter trained to optimize an arbitrary user objective with reinforcement learning. On five challenging text generation tasks, such as toxicity reduction and lexically constrained generation, IPA consistently brings significant improvements over off-the-shelf language models. It outperforms competitive baseline methods, sometimes even including expensive fine-tuning. In particular, tailoring GPT-2 with IPA can outperform GPT-3, while tailoring GPT-3 with IPA brings a major performance boost over GPT-3 (and sometimes even over GPT-4). Our promising results highlight the potential of IPA as a lightweight alternative to tailoring extreme-scale language models.
isOpenAccess: True
TL\DR: Inference-time Policy Adapters (IPA) is proposed, which efficiently tailors a language model such as GPT-3 without fine-tuning it, and consistently brings significant improvements over off-the-shelf language models.
================================
faculty_name: Eric P. Xing
faculty_authorid: 143977260
paper_id: 075b751201f549daeba9840f78768f4ceb507e17
paper_title: Identification of Nonlinear Latent Hierarchical Models
publication_link: http://arxiv.org/pdf/2306.07916 
year_published: 2023 
abstract_paper:Identifying latent variables and causal structures from observational data is essential to many real-world applications involving biological data, medical data, and unstructured data such as images and languages. However, this task can be highly challenging, especially when observed variables are generated by causally related latent variables and the relationships are nonlinear. In this work, we investigate the identification problem for nonlinear latent hierarchical causal models in which observed variables are generated by a set of causally related latent variables, and some latent variables may not have observed children. We show that the identifiability of causal structures and latent variables (up to invertible transformations) can be achieved under mild assumptions: on causal structures, we allow for multiple paths between any pair of variables in the graph, which relaxes latent tree assumptions in prior work; on structural functions, we permit general nonlinearity and multi-dimensional continuous variables, alleviating existing work's parametric assumptions. Specifically, we first develop an identification criterion in the form of novel identifiability guarantees for an elementary latent variable model. Leveraging this criterion, we show that both causal structures and latent variables of the hierarchical model can be identified asymptotically by explicitly constructing an estimation procedure. To the best of our knowledge, our work is the first to establish identifiability guarantees for both causal structures and latent variables in nonlinear latent hierarchical models.
isOpenAccess: True
TL\DR: Inference-time Policy Adapters (IPA) is proposed, which efficiently tailors a language model such as GPT-3 without fine-tuning it, and consistently brings significant improvements over off-the-shelf language models.
================================
faculty_name: Eric P. Xing
faculty_authorid: 143977260
paper_id: 8cc1cd002bfc36a8cba8bcbe63d32eacc656097f
paper_title: StyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields
publication_link: https://arxiv.org/pdf/2303.10598 
year_published: 2023 
abstract_paper:3D style transfer aims to render stylized novel views of a 3D scene with multiview consistency. However, most existing work suffers from a three-way dilemma over accurate geometry reconstruction, high-quality stylization, and being generalizable to arbitrary new styles. We propose StyleRF (Style Radiance Fields), an innovative 3D style transfer technique that resolves the three-way dilemma by performing style transformation within the feature space of a radiance field. StyleRF employs an explicit grid of high-level features to represent 3D scenes, with which highfidelity geometry can be reliably restored via volume rendering. In addition, it transforms the grid features according to the reference style which directly leads to high-quality zero-shot style transfer. StyleRF consists of two innovative designs. The first is sampling-invariant content transformation that makes the transformation invariant to the holistic statistics of the sampled 3D points and accordingly ensures multi-view consistency. The second is deferred style transformation of 2D feature maps which is equivalent to the transformation of 3D points but greatly reduces memory footprint without degrading multi-view consistency. Extensive experiments show that StyleRF achieves superior 3D stylization quality with precise geometry reconstruction and it can generalize to various new styles in a zero-shot manner. Project website: https://kunhao-liu.github.io/StyleRF/
isOpenAccess: True
TL\DR: StyleRF (Style Radiance Fields), an innovative 3D style transfer technique that resolves the three-way dilemma by performing style transformation within the feature space of a radiance field, achieves superior 3D stylization quality with precise geometry reconstruction and it can generalize to various new styles in a zero-shot manner.
================================
faculty_name: Eric P. Xing
faculty_authorid: 143977260
paper_id: a0a79dad89857a96f8f71b14238e5237cbfc4787
paper_title: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
publication_link: https://arxiv.org/pdf/2306.05685 
year_published: 2023 
abstract_paper:Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.
isOpenAccess: True
TL\DR: StyleRF (Style Radiance Fields), an innovative 3D style transfer technique that resolves the three-way dilemma by performing style transformation within the feature space of a radiance field, achieves superior 3D stylization quality with precise geometry reconstruction and it can generalize to various new styles in a zero-shot manner.
================================
faculty_name: Eric P. Xing
faculty_authorid: 143977260
paper_id: dcb4f2b9b0e6da0d629878d1ad0469aee3df2020
paper_title: Understanding Masked Autoencoders via Hierarchical Latent Variable Models
publication_link: https://arxiv.org/pdf/2306.04898 
year_published: 2023 
abstract_paper:Masked autoencoder (MAE), a simple and effective self-supervised learning framework based on the reconstruction of masked image regions, has recently achieved prominent success in a variety of vision tasks. Despite the emergence of intriguing empirical observations on MAE, a theoretically principled understanding is still lacking. In this work, we formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE. We formulate the underlying data-generating process as a hierarchical latent variable model, and show that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model, explaining why MAE can extract high-level information from pixels. Further, we show how key hyperparameters in MAE (the masking ratio and the patch size) determine which true latent variables to be recovered, therefore influencing the level of semantic information in the representation. Specifically, extremely large or small masking ratios inevitably lead to low-level representations. Our theory offers coherent explanations of existing empirical observations and provides insights for potential empirical improvements and fundamental limitations of the masked-reconstruction paradigm. We conduct extensive experiments to validate our theoretical insights.
isOpenAccess: True
TL\DR: This work formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE, and formulate the underlying data-generating process as a hierarchical latent variable model, and shows that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2246852356
paper_id: ab70103b8cc85fd1cd52200aa134c58c7e9c0e03
paper_title: FedNAR: Federated Optimization with Normalized Annealing Regularization
publication_link: https://arxiv.org/pdf/2310.03163 
year_published: 2023 
abstract_paper:Weight decay is a standard technique to improve generalization performance in modern deep neural network optimization, and is also widely adopted in federated learning (FL) to prevent overfitting in local clients. In this paper, we first explore the choices of weight decay and identify that weight decay value appreciably influences the convergence of existing FL algorithms. While preventing overfitting is crucial, weight decay can introduce a different optimization goal towards the global objective, which is further amplified in FL due to multiple local updates and heterogeneous data distribution. To address this challenge, we develop {\it Federated optimization with Normalized Annealing Regularization} (FedNAR), a simple yet effective and versatile algorithmic plug-in that can be seamlessly integrated into any existing FL algorithms. Essentially, we regulate the magnitude of each update by performing co-clipping of the gradient and weight decay. We provide a comprehensive theoretical analysis of FedNAR's convergence rate and conduct extensive experiments on both vision and language datasets with different backbone federated optimization algorithms. Our experimental results consistently demonstrate that incorporating FedNAR into existing FL algorithms leads to accelerated convergence and heightened model accuracy. Moreover, FedNAR exhibits resilience in the face of various hyperparameter configurations. Specifically, FedNAR has the ability to self-adjust the weight decay when the initial specification is not optimal, while the accuracy of traditional FL algorithms would markedly decline. Our codes are released at \href{https://github.com/ljb121002/fednar}{https://github.com/ljb121002/fednar}.
isOpenAccess: True
TL\DR: This work formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE, and formulate the underlying data-generating process as a hierarchical latent variable model, and shows that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2243336934
paper_id: 5e424004958853f4e366e7a86a1c3a56a76cb2a4
paper_title: LightSeq: Sequence Level Parallelism for Distributed Training of Long Context Transformers
publication_link: https://arxiv.org/pdf/2310.03294 
year_published: 2023 
abstract_paper:Increasing the context length of large language models (LLMs) unlocks fundamentally new capabilities, but also significantly increases the memory footprints of training. Previous model-parallel systems such as Megatron-LM partition and compute different attention heads in parallel, resulting in large communication volumes, so they cannot scale beyond the number of attention heads, thereby hindering its adoption. In this paper, we introduce a new approach, LightSeq, for long-context LLMs training. LightSeq has many notable advantages. First, LightSeq partitions over the sequence dimension, hence is agnostic to model architectures and readily applicable for models with varying numbers of attention heads, such as Multi-Head, Multi-Query and Grouped-Query attention. Second, LightSeq not only requires up to 4.7x less communication than Megatron-LM on popular LLMs but also overlaps the communication with computation. To further reduce the training time, LightSeq features a novel gradient checkpointing scheme to bypass an forward computation for memory-efficient attention. We evaluate LightSeq on Llama-7B and its variants with sequence lengths from 32K to 512K. Through comprehensive experiments on single and cross-node training, we show that LightSeq achieves up to 1.24-2.01x end-to-end speedup, and a 2-8x longer sequence length on models with fewer heads, compared to Megatron-LM. Codes will be available at https://github.com/RulinShao/LightSeq.
isOpenAccess: True
TL\DR: This work formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE, and formulate the underlying data-generating process as a hierarchical latent variable model, and shows that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2243336934
paper_id: 84a36e19f9394f22b34f79756fa9628a795e02ea
paper_title: LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset
publication_link: https://arxiv.org/pdf/2309.11998 
year_published: 2023 
abstract_paper:Studying how people interact with large language models (LLMs) in real-world scenarios is increasingly important due to their widespread use in various applications. In this paper, we introduce LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs. This dataset is collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot Arena website. We offer an overview of the dataset's content, including its curation process, basic statistics, and topic distribution, highlighting its diversity, originality, and scale. We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions. We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is publicly available at https://huggingface.co/datasets/lmsys/lmsys-chat-1m.
isOpenAccess: True
TL\DR: This work formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE, and formulate the underlying data-generating process as a hierarchical latent variable model, and shows that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2243234805
paper_id: 39bb5d44735c07b1e1f4341a2d4bc8d5e783f491
paper_title: SlimPajama-DC: Understanding Data Combinations for LLM Training
publication_link: https://arxiv.org/pdf/2309.10818 
year_published: 2023 
abstract_paper:This paper aims to understand the impacts of various data combinations (e.g., web text, wikipedia, github, books) on the training of large language models using SlimPajama. SlimPajama is a rigorously deduplicated, multi-source dataset, which has been refined and further deduplicated to 627B tokens from the extensive 1.2T tokens RedPajama dataset contributed by Together. We've termed our research as SlimPajama-DC, an empirical analysis designed to uncover fundamental characteristics and best practices associated with employing SlimPajama in the training of large language models. During our research with SlimPajama, two pivotal observations emerged: (1) Global deduplication vs. local deduplication. We analyze and discuss how global (across different sources of datasets) and local (within the single source of dataset) deduplications affect the performance of trained models. (2) Proportions of high-quality/highly-deduplicated multi-source datasets in the combination. To study this, we construct six configurations of SlimPajama dataset and train individual ones using 1.3B Cerebras-GPT model with Alibi and SwiGLU. Our best configuration outperforms the 1.3B model trained on RedPajama using the same number of training tokens by a significant margin. All our 1.3B models are trained on Cerebras 16$\times$ CS-2 cluster with a total of 80 PFLOP/s in bf16 mixed precision. We further extend our discoveries (such as increasing data diversity is crucial after global deduplication) on a 7B model with large batch-size training. Our models and the separate SlimPajama-DC datasets are available at: https://huggingface.co/MBZUAI-LLM and https://huggingface.co/datasets/cerebras/SlimPajama-627B.
isOpenAccess: True
TL\DR: This work formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE, and formulate the underlying data-generating process as a hierarchical latent variable model, and shows that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2243234805
paper_id: 953e415f1fd006e968aa13b49cd7523856c0c0fe
paper_title: Fusing Models with Complementary Expertise
publication_link: https://arxiv.org/pdf/2310.01542 
year_published: 2023 
abstract_paper:Training AI models that generalize across tasks and domains has long been among the open problems driving AI research. The emergence of Foundation Models made it easier to obtain expert models for a given task, but the heterogeneity of data that may be encountered at test time often means that any single expert is insufficient. We consider the Fusion of Experts (FoE) problem of fusing outputs of expert models with complementary knowledge of the data distribution and formulate it as an instance of supervised learning. Our method is applicable to both discriminative and generative tasks and leads to significant performance improvements in image and text classification, text summarization, multiple-choice QA, and automatic evaluation of generated text. We also extend our method to the"frugal"setting where it is desired to reduce the number of expert model evaluations at test time.
isOpenAccess: True
TL\DR: This work formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE, and formulate the underlying data-generating process as a hierarchical latent variable model, and shows that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2243234805
paper_id: a815c3209e7baff4466dbf6e129129511f842b7e
paper_title: Making Scalable Meta Learning Practical
publication_link: https://arxiv.org/pdf/2310.05674 
year_published: 2023 
abstract_paper:Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.
isOpenAccess: True
TL\DR: This work formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE, and formulate the underlying data-generating process as a hierarchical latent variable model, and shows that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2256681637
paper_id: 5d17963ceb279be116e7a1207542ea94f1b2a8c8
paper_title: Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning
publication_link: https://arxiv.org/pdf/2310.07918 
year_published: 2023 
abstract_paper:Interpretable policy learning seeks to estimate intelligible decision policies from observed actions; however, existing models fall short by forcing a tradeoff between accuracy and interpretability. This tradeoff limits data-driven interpretations of human decision-making process. e.g. to audit medical decisions for biases and suboptimal practices, we require models of decision processes which provide concise descriptions of complex behaviors. Fundamentally, existing approaches are burdened by this tradeoff because they represent the underlying decision process as a universal policy, when in fact human decisions are dynamic and can change drastically with contextual information. Thus, we propose Contextualized Policy Recovery (CPR), which re-frames the problem of modeling complex decision processes as a multi-task learning problem in which complex decision policies are comprised of context-specific policies. CPR models each context-specific policy as a linear observation-to-action mapping, and generates new decision models $\textit{on-demand}$ as contexts are updated with new observations. CPR is compatible with fully offline and partially observable decision environments, and can be tailored to incorporate any recurrent black-box model or interpretable decision model. We assess CPR through studies on simulated and real data, achieving state-of-the-art performance on the canonical tasks of predicting antibiotic prescription in intensive care units ($+22\%$ AUROC vs. previous SOTA) and predicting MRI prescription for Alzheimer's patients ($+7.7\%$ AUROC vs. previous SOTA). With this improvement in predictive performance, CPR closes the accuracy gap between interpretable and black-box methods for policy learning, allowing high-resolution exploration and analysis of context-specific decision models.
isOpenAccess: True
TL\DR: This work formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE, and formulate the underlying data-generating process as a hierarchical latent variable model, and shows that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2256681637
paper_id: 640e1bcc472a71d36c6b9261403b60c680d93917
paper_title: GET: a foundation model of transcription across human cell types
publication_link: https://www.biorxiv.org/content/biorxiv/early/2023/09/24/2023.09.24.559168.full.pdf 
year_published: 2023 
abstract_paper:Transcriptional regulation, involving the complex interplay between regulatory sequences and proteins, directs all biological processes. Computational models of transcriptions lack generalizability to accurately extrapolate in unseen cell types and conditions. Here, we introduce GET, an interpretable foundation model, designed to uncover regulatory grammars across 213 human fetal and adult cell types. Relying exclusively on chromatin accessibility data and sequence information, GET achieves experimental-level accuracy in predicting gene expression even in previously unseen cell types. GET showcases remarkable adaptability across new sequencing platforms and assays, enabling regulatory inference across a broad range of cell types and conditions, and uncovering universal and cell type specific transcription factor interaction networks. We evaluated its performance on prediction of regulatory activity, inference of regulatory elements and regulators, and identification of physical interactions between transcription factors. Specifically, we show GET outperforms current models in predicting lentivirus-based massive parallel reporter assay readout with reduced input data. In Fetal erythroblast, we identify distal (>1Mbp) regulatory regions that were missed by previous models. In B cell, we identified a lymphocyte-specific transcription factor-transcription factor interaction that explains the functional significance of a lymphoma-risk predisposing germline mutation. In sum, we provide a generalizable and accurate model for transcription together with catalogs of gene regulation and transcription factor interactions, all with cell type specificity.
isOpenAccess: True
TL\DR: This work formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE, and formulate the underlying data-generating process as a hierarchical latent variable model, and shows that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2256681637
paper_id: e6dbe34d154591618ef78d56d5e8a50583b5f9d1
paper_title: Contextualized Networks Reveal Heterogeneous Transcriptomic Regulation in Tumors at Sample-Specific Resolution
publication_link: https://www.biorxiv.org/content/biorxiv/early/2023/12/04/2023.12.01.569658.full.pdf 
year_published: 2023 
abstract_paper:Cancers are shaped by somatic mutations, microenvironment, and patient background, each altering gene expression and regulation in complex ways, resulting in heterogeneous cellular states and dynamics. Inferring gene regulatory network (GRN) models from expression data can help characterize this regulation-driven heterogeneity, but network inference requires many statistical samples, traditionally limiting GRNs to cluster-level analyses that ignore intra-cluster heterogeneity. We propose to move beyond cluster-based analyses by using contextualized learning, a multi-task learning paradigm which allows us to infer sample-specific models using phenotypic, molecular, and environmental information pertinent to the model, encoded as the model’s “context” to be conditioned on. We unify three network model classes (Correlation, Markov, Neighborhood) and estimate context-specific GRNs for 7997 tumors across 25 tumor types, with each network contextualized by copy number and driver mutation profiles, tumor microenvironment, and patient demographics. Contextualized GRNs provide a structured view of expression dynamics at sample-specific resolution, which reveal co-expression modules in correlation networks (CNs), as well as cliques and independent regulatory elements in Markov Networks (MNs) and Neighborhood Regression Networks (NNs). Our generative modeling approach allows us to predict GRNs for unseen tumor types based on a pan-cancer model of how somatic mutations affect gene regulation. Finally, contextualized networks enable GRN-based precision oncology, explaining known biomarkers in terms of network-mediated effects, and leading to novel subtypings for thyroid, brain, and gastrointestinal tumors that improve survival prognosis.
isOpenAccess: True
TL\DR: This work formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE, and formulate the underlying data-generating process as a hierarchical latent variable model, and shows that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2064963077
paper_id: 1262758538525835d918007d15726794e19a07b7
paper_title: Squeeze, Recover and Relabel: Dataset Condensation at ImageNet Scale From A New Perspective
publication_link: http://arxiv.org/pdf/2306.13092 
year_published: 2023 
abstract_paper:We present a new dataset condensation framework termed Squeeze, Recover and Relabel (SRe$^2$L) that decouples the bilevel optimization of model and synthetic data during training, to handle varying scales of datasets, model architectures and image resolutions for efficient dataset condensation. The proposed method demonstrates flexibility across diverse dataset scales and exhibits multiple advantages in terms of arbitrary resolutions of synthesized images, low training cost and memory consumption with high-resolution synthesis, and the ability to scale up to arbitrary evaluation network architectures. Extensive experiments are conducted on Tiny-ImageNet and full ImageNet-1K datasets. Under 50 IPC, our approach achieves the highest 42.5% and 60.8% validation accuracy on Tiny-ImageNet and ImageNet-1K, outperforming all previous state-of-the-art methods by margins of 14.5% and 32.9%, respectively. Our approach also surpasses MTT in terms of speed by approximately 52$\times$ (ConvNet-4) and 16$\times$ (ResNet-18) faster with less memory consumption of 11.6$\times$ and 6.4$\times$ during data synthesis. Our code and condensed datasets of 50, 200 IPC with 4K recovery budget are available at https://github.com/VILA-Lab/SRe2L.
isOpenAccess: True
TL\DR: The proposed dataset condensation framework demonstrates flexibility across diverse dataset scales and exhibits multiple advantages in terms of arbitrary resolutions of synthesized images, low training cost and memory consumption with high-resolution synthesis, and the ability to scale up to arbitrary evaluation network architectures.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2064963077
paper_id: 16b42fc85f4c073aa00c410cbdce965d7c6f8d4d
paper_title: One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning
publication_link: http://arxiv.org/pdf/2306.07967 
year_published: 2023 
abstract_paper:We present Generalized LoRA (GLoRA), an advanced approach for universal parameter-efficient fine-tuning tasks. Enhancing Low-Rank Adaptation (LoRA), GLoRA employs a generalized prompt module to optimize pre-trained model weights and adjust intermediate activations, providing more flexibility and capability across diverse tasks and datasets. Moreover, GLoRA facilitates efficient parameter adaptation by employing a scalable, modular, layer-wise structure search that learns individual adapter of each layer. Originating from a unified mathematical formulation, GLoRA exhibits strong transfer learning, few-shot learning and domain generalization abilities, as it adapts to new tasks through not only weights but also additional dimensions like activations. Comprehensive experiments demonstrate that GLoRA outperforms all previous methods in natural, specialized, and structured vision benchmarks, achieving superior accuracy with fewer parameters and computations. The proposed method on LLaMA-1 and LLaMA-2 also show considerable enhancements compared to the original LoRA in the language domain. Furthermore, our structural re-parameterization design ensures that GLoRA incurs no extra inference cost, rendering it a practical solution for resource-limited applications. Code and models are available at: https://github.com/Arnav0400/ViT-Slim/tree/master/GLoRA.
isOpenAccess: True
TL\DR: The proposed dataset condensation framework demonstrates flexibility across diverse dataset scales and exhibits multiple advantages in terms of arbitrary resolutions of synthesized images, low training cost and memory consumption with high-resolution synthesis, and the ability to scale up to arbitrary evaluation network architectures.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2064963077
paper_id: 1db4a8f3c35ae1d2e8f7029abf67f37b0030ea2a
paper_title: Defending Against Malicious Behaviors in Federated Learning with Blockchain
publication_link: http://arxiv.org/pdf/2307.00543 
year_published: 2023 
abstract_paper:In the era of deep learning, federated learning (FL) presents a promising approach that allows multi-institutional data owners, or clients, to collaboratively train machine learning models without compromising data privacy. However, most existing FL approaches rely on a centralized server for global model aggregation, leading to a single point of failure. This makes the system vulnerable to malicious attacks when dealing with dishonest clients. In this work, we address this problem by proposing a secure and reliable FL system based on blockchain and distributed ledger technology. Our system incorporates a peer-to-peer voting mechanism and a reward-and-slash mechanism, which are powered by on-chain smart contracts, to detect and deter malicious behaviors. Both theoretical and empirical analyses are presented to demonstrate the effectiveness of the proposed approach, showing that our framework is robust against malicious client-side behaviors.
isOpenAccess: True
TL\DR: The proposed dataset condensation framework demonstrates flexibility across diverse dataset scales and exhibits multiple advantages in terms of arbitrary resolutions of synthesized images, low training cost and memory consumption with high-resolution synthesis, and the ability to scale up to arbitrary evaluation network architectures.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2064963077
paper_id: 44772fe1c3fa422a3da7e25092db2544893d6bfb
paper_title: Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming
publication_link: http://arxiv.org/pdf/2305.03742 
year_published: 2023 
abstract_paper:Pre-trained large language models (LMs) struggle to perform logical reasoning reliably despite advances in scale and compositionality. In this work, we tackle this challenge through the lens of symbolic programming. We propose DSR-LM, a Differentiable Symbolic Reasoning framework where pre-trained LMs govern the perception of factual knowledge, and a symbolic module performs deductive reasoning. In contrast to works that rely on hand-crafted logic rules, our differentiable symbolic reasoning framework efficiently learns weighted rules and applies semantic loss to further improve LMs. DSR-LM is scalable, interpretable, and allows easy integration of prior knowledge, thereby supporting extensive symbolic programming to robustly derive a logical conclusion. The results of our experiments suggest that DSR-LM improves the logical reasoning abilities of pre-trained language models, resulting in a significant increase in accuracy of over 20% on deductive reasoning benchmarks. Furthermore, DSR-LM outperforms a variety of competitive baselines when faced with systematic changes in sequence length.
isOpenAccess: True
TL\DR: The proposed dataset condensation framework demonstrates flexibility across diverse dataset scales and exhibits multiple advantages in terms of arbitrary resolutions of synthesized images, low training cost and memory consumption with high-resolution synthesis, and the ability to scale up to arbitrary evaluation network architectures.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2064963077
paper_id: 5c577988ccebfea96de86678d04fd94fad367d2e
paper_title: Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models
publication_link: https://arxiv.org/pdf/2308.16149 
year_published: 2023 
abstract_paper:We introduce Jais and Jais-chat, new state-of-the-art Arabic-centric foundation and instruction-tuned open generative large language models (LLMs). The models are based on the GPT-3 decoder-only architecture and are pretrained on a mixture of Arabic and English texts, including source code in various programming languages. With 13 billion parameters, they demonstrate better knowledge and reasoning capabilities in Arabic than any existing open Arabic and multilingual models by a sizable margin, based on extensive evaluation. Moreover, the models are competitive in English compared to English-centric open models of similar size, despite being trained on much less English data. We provide a detailed description of the training, the tuning, the safety alignment, and the evaluation of the models. We release two open versions of the model -- the foundation Jais model, and an instruction-tuned Jais-chat variant -- with the aim of promoting research on Arabic LLMs. Available at https://huggingface.co/inception-mbzuai/jais-13b-chat
isOpenAccess: True
TL\DR: Jais and Jais-chat are introduced, new state-of-the-art Arabic-centric foundation and instruction-tuned open generative large language models (LLMs) based on the GPT-3 decoder-only architecture that demonstrate better knowledge and reasoning capabilities in Arabic than any existing open Arabic and multilingual models by a sizable margin.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2064963077
paper_id: 6721244fad7f4790272be86e8b165fccd69578ab
paper_title: KD-DLGAN: Data Limited Image Generation via Knowledge Distillation
publication_link: https://arxiv.org/pdf/2303.17158 
year_published: 2023 
abstract_paper:Generative Adversarial Networks (GANs) rely heavily on large-scale training data for training high-quality image generation models. With limited training data, the GAN discriminator often suffers from severe overfitting which directly leads to degraded generation especially in generation diversity. Inspired by the recent advances in knowledge distillation (KD), we propose KD-DLGAN, a knowledge-distillation based generation framework that introduces pre-trained vision-language models for training effective data-limited generation models. KD-DLGAN consists of two innovative designs. The first is aggregated generative KD that mitigates the discriminator overfitting by challenging the discriminator with harder learning tasks and distilling more generalizable knowledge from the pre-trained models. The second is correlated generative KD that improves the generation diversity by distilling and preserving the diverse image-text correlation within the pre-trained models. Extensive experiments over multiple benchmarks show that KD-DLGAN achieves superior image generation with limited training data. In addition, KD-DLGAN complements the state-of-the-art with consistent and substantial performance gains. Note that codes will be released.
isOpenAccess: True
TL\DR: KD-DLGAN is proposed, a knowledge-distillation based generation framework that introduces pre-trained vision-language models for training effective data-limited generation models and achieves superior image generation with limited training data.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2064963077
paper_id: 7124f495399759ce089e6637dc48e073e9d168aa
paper_title: 3D Semantic Segmentation in the Wild: Learning Generalized Models for Adverse-Condition Point Clouds
publication_link: https://arxiv.org/pdf/2304.00690 
year_published: 2023 
abstract_paper:Robust point cloud parsing under all-weather conditions is crucial to level-5 autonomy in autonomous driving. However, how to learn a universal 3D semantic segmentation (3DSS) model is largely neglected as most existing benchmarks are dominated by point clouds captured under normal weather. We introduce SemanticSTF, an adverse-weather point cloud dataset that provides dense point-level annotations and allows to study 3DSS under various adverse weather conditions. We study all-weather 3DSS modeling under two setups: 1) domain adaptive 3DSS that adapts from normal-weather data to adverse-weather data; 2) domain generalizable 3DSS that learns all-weather 3DSS models from normal-weather data. Our studies reveal the challenge while existing 3DSS methods encounter adverse-weather data, showing the great value of SemanticSTF in steering the future endeavor along this very meaningful research direction. In addition, we design a domain randomization technique that alternatively randomizes the geometry styles of point clouds and aggregates their embeddings, ultimately leading to a generalizable model that can improve 3DSS under various adverse weather effectively. The SemanticSTF and related codes are available at https://github.com/xiaoaoran/SemanticSTF.
isOpenAccess: True
TL\DR: KD-DLGAN is proposed, a knowledge-distillation based generation framework that introduces pre-trained vision-language models for training effective data-limited generation models and achieves superior image generation with limited training data.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2064963077
paper_id: a06a4a38668c4737ab2ce80badc177ea3f520456
paper_title: Cuttlefish: Low-Rank Model Training without All the Tuning
publication_link: http://arxiv.org/pdf/2305.02538 
year_published: 2023 
abstract_paper:Recent research has shown that training low-rank neural networks can effectively reduce the total number of trainable parameters without sacrificing predictive accuracy, resulting in end-to-end speedups. However, low-rank model training necessitates adjusting several additional factorization hyperparameters, such as the rank of the factorization at each layer. In this paper, we tackle this challenge by introducing Cuttlefish, an automated low-rank training approach that eliminates the need for tuning factorization hyperparameters. Cuttlefish leverages the observation that after a few epochs of full-rank training, the stable rank (i.e., an approximation of the true rank) of each layer stabilizes at a constant value. Cuttlefish switches from full-rank to low-rank training once the stable ranks of all layers have converged, setting the dimension of each factorization to its corresponding stable rank. Our results show that Cuttlefish generates models up to 5.6 times smaller than full-rank models, and attains up to a 1.2 times faster end-to-end training process while preserving comparable accuracy. Moreover, Cuttlefish outperforms state-of-the-art low-rank model training methods and other prominent baselines. The source code for our implementation can be found at: https://github.com/hwang595/Cuttlefish.
isOpenAccess: True
TL\DR: KD-DLGAN is proposed, a knowledge-distillation based generation framework that introduces pre-trained vision-language models for training effective data-limited generation models and achieves superior image generation with limited training data.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2064963077
paper_id: a1a18645ee975e8b8fa0e9f922353c0ed6da361b
paper_title: Does compressing activations help model parallel training?
publication_link: http://arxiv.org/pdf/2301.02654 
year_published: 2023 
abstract_paper:Large-scale Transformer models are known for their exceptional performance in a range of tasks, but training them can be difficult due to the requirement for communication-intensive model parallelism. One way to improve training speed is to compress the message size in communication. Previous approaches have primarily focused on compressing gradients in a data parallelism setting, but compression in a model-parallel setting is an understudied area. We have discovered that model parallelism has fundamentally different characteristics than data parallelism. In this work, we present the first empirical study on the effectiveness of compression methods for model parallelism. We implement and evaluate three common classes of compression algorithms - pruning-based, learning-based, and quantization-based - using a popular Transformer training framework. We evaluate these methods across more than 160 settings and 8 popular datasets, taking into account different hyperparameters, hardware, and both fine-tuning and pre-training stages. We also provide analysis when the model is scaled up. Finally, we provide insights for future development of model parallelism compression algorithms.
isOpenAccess: True
TL\DR: KD-DLGAN is proposed, a knowledge-distillation based generation framework that introduces pre-trained vision-language models for training effective data-limited generation models and achieves superior image generation with limited training data.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2064963077
paper_id: aca66f06cc3f988ebfc0420b3f969466a6984fef
paper_title: Federated Learning as Variational Inference: A Scalable Expectation Propagation Approach
publication_link: http://arxiv.org/pdf/2302.04228 
year_published: 2023 
abstract_paper:The canonical formulation of federated learning treats it as a distributed optimization problem where the model parameters are optimized against a global loss function that decomposes across client loss functions. A recent alternative formulation instead treats federated learning as a distributed inference problem, where the goal is to infer a global posterior from partitioned client data (Al-Shedivat et al., 2021). This paper extends the inference view and describes a variational inference formulation of federated learning where the goal is to find a global variational posterior that well-approximates the true posterior. This naturally motivates an expectation propagation approach to federated learning (FedEP), where approximations to the global posterior are iteratively refined through probabilistic message-passing between the central server and the clients. We conduct an extensive empirical study across various algorithmic considerations and describe practical strategies for scaling up expectation propagation to the modern federated setting. We apply FedEP on standard federated learning benchmarks and find that it outperforms strong baselines in terms of both convergence speed and accuracy.
isOpenAccess: True
TL\DR: An extensive empirical study across various algorithmic considerations and describes practical strategies for scaling up expectation propagation to the modern federated setting and applies FedEP on standard federated learning benchmarks and finds that it outperforms strong baselines in terms of both convergence speed and accuracy.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2064963077
paper_id: fdf9f4c09451e847e0bd1b251621ca56e0eb491b
paper_title: Memory-adaptive Depth-wise Heterogenous Federated Learning
publication_link: http://arxiv.org/pdf/2303.04887 
year_published: 2023 
abstract_paper:Federated learning is a promising paradigm that allows multiple clients to collaboratively train a model without sharing the local data. However, the presence of heterogeneous devices in federated learning, such as mobile phones and IoT devices with varying memory capabilities, would limit the scale and hence the performance of the model could be trained. The mainstream approaches to address memory limitations focus on width-slimming techniques, where different clients train subnetworks with reduced widths locally and then the server aggregates the subnetworks. The global model produced from these methods suffers from performance degradation due to the negative impact of the actions taken to handle the varying subnetwork widths in the aggregation phase. In this paper, we introduce a memory-adaptive depth-wise learning solution in FL called FeDepth, which adaptively decomposes the full model into blocks according to the memory budgets of each client and trains blocks sequentially to obtain a full inference model. Our method outperforms state-of-the-art approaches, achieving 5% and more than 10% improvements in top-1 accuracy on CIFAR-10 and CIFAR-100, respectively. We also demonstrate the effectiveness of depth-wise fine-tuning on ViT. Our findings highlight the importance of memory-aware techniques for federated learning with heterogeneous devices and the success of depth-wise training strategy in improving the global model's performance.
isOpenAccess: True
TL\DR: An extensive empirical study across various algorithmic considerations and describes practical strategies for scaling up expectation propagation to the modern federated setting and applies FedEP on standard federated learning benchmarks and finds that it outperforms strong baselines in terms of both convergence speed and accuracy.
================================
faculty_name: Eric P. Xing
faculty_authorid: 2238075244
paper_id: 1250676d646a9b48cf3bab66f13dc3c628ff68af
paper_title: 3D Open-vocabulary Segmentation with Foundation Models
publication_link: https://arxiv.org/pdf/2305.14093 
year_published: 2023 
abstract_paper:Open-vocabulary segmentation of 3D scenes is a fundamental function of human perception and thus a crucial objective in computer vision research. However, this task is heavily impeded by the lack of large-scale and diverse 3D open-vocabulary segmentation datasets for training robust and generalizable models. Distilling knowledge from pre-trained 2D open-vocabulary segmentation models helps but it compromises the open-vocabulary feature significantly as the 2D models are mostly finetuned with close-vocabulary datasets. We tackle the challenges in 3D open-vocabulary segmentation by exploiting the open-vocabulary multimodal knowledge and object reasoning capability of pre-trained foundation models CLIP and DINO, without necessitating any fine-tuning. Specifically, we distill open-vocabulary visual and textual knowledge from CLIP into a neural radiance field (NeRF) which effectively lifts 2D features into view-consistent 3D segmentation. Furthermore, we introduce the Relevancy-Distribution Alignment loss and Feature-Distribution Alignment loss to respectively mitigate the ambiguities of CLIP features and distill precise object boundaries from DINO features, eliminating the need for segmentation annotations during training. Extensive experiments show that our method even outperforms fully supervised models trained with segmentation annotations, suggesting that 3D open-vocabulary segmentation can be effectively learned from 2D images and text-image pairs.
isOpenAccess: True
TL\DR: This work distill open-vocabulary visual and textual knowledge from CLIP into a neural radiance field (NeRF) which effectively lifts 2D features into view-consistent 3D segmentation, suggesting that 3D open- Vocabulary segmentation can be effectively learned from 2D images and text-image pairs.
================================
faculty_name: Chenyan Xiong
faculty_authorid: 144628574
paper_id: 159100c8323fc558e4073a3a006f3f243aca3a60
paper_title: Text Matching Improves Sequential Recommendation by Reducing Popularity Biases
publication_link: https://arxiv.org/pdf/2308.14029 
year_published: 2023 
abstract_paper:This paper proposes Text mAtching based SequenTial rEcommenda-tion model (TASTE), which maps items and users in an embedding space and recommends items by matching their text representations. TASTE verbalizes items and user-item interactions using identifiers and attributes of items. To better characterize user behaviors, TASTE additionally proposes an attention sparsity method, which enables TASTE to model longer user-item interactions by reducing the self-attention computations during encoding. Our experiments show that TASTE outperforms the state-of-the-art methods on widely used sequential recommendation datasets. TASTE alleviates the cold start problem by representing long-tail items using full-text modeling and bringing the benefits of pretrained language models to recommendation systems. Our further analyses illustrate that TASTE significantly improves the recommendation accuracy by reducing the popularity bias of previous item id based recommendation models and returning more appropriate and text-relevant items to satisfy users. All codes are available at https://github.com/OpenMatch/TASTE.
isOpenAccess: True
TL\DR: This work distill open-vocabulary visual and textual knowledge from CLIP into a neural radiance field (NeRF) which effectively lifts 2D features into view-consistent 3D segmentation, suggesting that 3D open- Vocabulary segmentation can be effectively learned from 2D images and text-image pairs.
================================
faculty_name: Chenyan Xiong
faculty_authorid: 144628574
paper_id: 275da3802142fc42f6fab2ce2104223b2e0ef40d
paper_title: Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval
publication_link: http://arxiv.org/pdf/2305.14685 
year_published: 2023 
abstract_paper:Common IR pipelines are typically cascade systems that may involve multiple rankers and/or fusion models to integrate different information step-by-step. In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document information into a single unified model using templated-based input and global attention. Experiments on passage ranking benchmarks MS MARCO and TREC DL show that FiT5 significantly improves ranking performance over prior pipelines. Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detection of subtle nuances between them. Our code will be open-sourced.
isOpenAccess: True
TL\DR: A novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document information into a single unified model using templated-based input and global attention, is proposed.
================================
faculty_name: Chenyan Xiong
faculty_authorid: 144628574
paper_id: cdfd0926ad26c3c95a02db2ae891b7d4a457429c
paper_title: OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit
publication_link: https://dl.acm.org/doi/pdf/10.1145/3539618.3591813 
year_published: 2023 
abstract_paper:Pre-trained language models (PLMs) have emerged as the foundation of the most advanced Information Retrieval (IR) models. Powered by PLMs, the latest IR research has proposed novel models, new domain adaptation algorithms as well as enlarged datasets. In this paper, we present a Python-based IR toolkit OpenMatch-v2. As a full upgrade of OpenMatch proposed in 2021, OpenMatch-v2 incorporates the most recent advancements of PLM-based IR research, providing support for new, cross-modality models and enhanced domain adaptation techniques with a streamlined, optimized infrastructure. The code of OpenMatch is publicly available at https://github.com/OpenMatch/OpenMatch.
isOpenAccess: True
TL\DR: As a full upgrade of OpenMatch proposed in 2021, OpenMatch-v2 incorporates the most recent advancements of PLM-based IR research, providing support for new, cross-modality models and enhanced domain adaptation techniques with a streamlined, optimized infrastructure.
================================
faculty_name: Chenyan Xiong
faculty_authorid: 2273679850
paper_id: bfa7f7bec1c4553c6c382ec2dbf4f889d7fa6e4f
paper_title: CompleQA: Benchmarking the Impacts of Knowledge Graph Completion Methods on Question Answering
publication_link: https://aclanthology.org/2023.findings-emnlp.849.pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Chenyan Xiong
faculty_authorid: 2139787803
paper_id: 105759bdb5e3bddc1d3244df2eff2d5c997a1d84
paper_title: Improving Multitask Retrieval by Promoting Task Specialization
publication_link: https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00597/2159628/tacl_a_00597.pdf 
year_published: 2023 
abstract_paper:Abstract In multitask retrieval, a single retriever is trained to retrieve relevant contexts for multiple tasks. Despite its practical appeal, naive multitask retrieval lags behind task-specific retrieval, in which a separate retriever is trained for each task. We show that it is possible to train a multitask retriever that outperforms task-specific retrievers by promoting task specialization. The main ingredients are: (1) a better choice of pretrained model—one that is explicitly optimized for multitasking—along with compatible prompting, and (2) a novel adaptive learning method that encourages each parameter to specialize in a particular task. The resulting multitask retriever is highly performant on the KILT benchmark. Upon analysis, we find that the model indeed learns parameters that are more task-specialized compared to naive multitasking without prompting or adaptive learning.1
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Chenyan Xiong
faculty_authorid: 2139787803
paper_id: 1fe3a802efdc4f1a3e5c8187547f38a3ec65750b
paper_title: Unsupervised Dense Retrieval Training with Web Anchors
publication_link: https://dl.acm.org/doi/pdf/10.1145/3539618.3592080 
year_published: 2023 
abstract_paper:In this work, we present an unsupervised retrieval method with contrastive learning on web anchors. The anchor text describes the content that is referenced from the linked page. This shows similarities to search queries that aim to retrieve pertinent information from relevant documents. Based on their commonalities, we train an unsupervised dense retriever, Anchor-DR, with a contrastive learning task that matches the anchor text and the linked document. To filter out uninformative anchors (such as "homepage" or other functional anchors), we present a novel filtering technique to only select anchors that contain similar types of information as search queries. Experiments show that Anchor-DR outperforms state-of-the-art methods on unsupervised dense retrieval by a large margin (e.g., by 5.3% NDCG@10 on MSMARCO). The gain of our method is especially significant for search and question answering tasks. Our analysis further reveals that the pattern of anchor-document pairs is similar to that of search query-document pairs. Code available at https://github.com/Veronicium/AnchorDR.
isOpenAccess: True
TL\DR: This work trains an unsupervised dense retriever, Anchor-DR, with a contrastive learning task that matches the anchor text and the linked document, and presents a novel filtering technique to only select anchors that contain similar types of information as search queries.
================================
faculty_name: Chenyan Xiong
faculty_authorid: 2139787803
paper_id: 24811cadf16519910f643b6084107164e6ca4219
paper_title: Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In
publication_link: http://arxiv.org/pdf/2305.17331 
year_published: 2023 
abstract_paper:Retrieval augmentation can aid language models (LMs) in knowledge-intensive tasks by supplying them with external information. Prior works on retrieval augmentation usually jointly fine-tune the retriever and the LM, making them closely coupled. In this paper, we explore the scheme of generic retrieval plug-in: the retriever is to assist target LMs that may not be known beforehand or are unable to be fine-tuned together. To retrieve useful documents for unseen target LMs, we propose augmentation-adapted retriever (AAR), which learns LM’s preferences obtained from a known source LM. Experiments on the MMLU and PopQA datasets demonstrate that our AAR trained with a small source LM is able to significantly improve the zero-shot generalization of larger target LMs ranging from 250M Flan-T5 to 175B InstructGPT. Further analysis indicates that the preferences of different LMs overlap, enabling AAR trained with a single source LM to serve as a generic plug-in for various target LMs. Our code is open-sourced at https://github.com/OpenMatch/Augmentation-Adapted-Retriever.
isOpenAccess: True
TL\DR: This paper proposes augmentation-adapted retriever (AAR), which learns LM’s preferences obtained from a known source LM to assist target LMs that may not be known beforehand or are unable to be fine-tuned together in a generic retrieval plug-in.
================================
faculty_name: Chenyan Xiong
faculty_authorid: 2139787803
paper_id: 38aaf8a29df6deeff0bf64cc835d242a25b10337
paper_title: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers
publication_link: https://aclanthology.org/2023.acl-long.724.pdf 
year_published: 2023 
abstract_paper:This paper explores the effectiveness of model-generated signals in improving zero-shot generalization of text-to-text Transformers such as T5. We study various designs to pretrain T5 using an auxiliary model to construct more challenging token replacements for the main model to denoise. Key aspects under study include the decoding target, the location of the RTD head, and the masking pattern. Based on these studies, we develop a new model, METRO-T0, which is pretrained using the redesigned ELECTRA-Style pretraining strategies and then prompt-finetuned on a mixture of NLP tasks. METRO-T0 outperforms all similar-sized baselines on prompted NLP benchmarks, such as _T0 Eval_ and MMLU, and rivals the state-of-the-art T0-11B model with only **8%** of its parameters. Our analysis on model’s neural activation and parameter sensitivity reveals that the effectiveness of METRO-T0 stems from more balanced contribution of parameters and better utilization of their capacity. The code and model checkpoints are available at [https://github.com/gonglinyuan/metro_t0](https://github.com/gonglinyuan/metro_t0).
isOpenAccess: True
TL\DR: A new model, METRO-T0 is developed, which is pretrained using the redesigned ELECTRA-Style pretraining strategies and then prompt-finetuned on a mixture of NLP tasks and rivals the state-of-the-art T0-11B model with only **8%** of its parameters.
================================
faculty_name: Chenyan Xiong
faculty_authorid: 2139787803
paper_id: a57b90cfc2eab46b773e65240d4ff910f05f989e
paper_title: Structure-Aware Language Model Pretraining Improves Dense Retrieval on Structured Data
publication_link: http://arxiv.org/pdf/2305.19912 
year_published: 2023 
abstract_paper:This paper presents Structure Aware Dense Retrieval (SANTA) model, which encodes user queries and structured data in one universal embedding space for retrieving structured data. SANTA proposes two pretraining methods to make language models structure-aware and learn effective representations for structured data: 1) Structured Data Alignment, which utilizes the natural alignment relations between structured data and unstructured data for structure-aware pretraining. It contrastively trains language models to represent multi-modal text data and teaches models to distinguish matched structured data for unstructured texts. 2) Masked Entity Prediction, which designs an entity-oriented mask strategy and asks language models to fill in the masked entities. Our experiments show that SANTA achieves state-of-the-art on code search and product search and conducts convincing results in the zero-shot setting. SANTA learns tailored representations for multi-modal text data by aligning structured and unstructured data pairs and capturing structural semantics by masking and predicting entities in the structured data. All codes are available at https://github.com/OpenMatch/OpenMatch.
isOpenAccess: True
TL\DR: A new model, METRO-T0 is developed, which is pretrained using the redesigned ELECTRA-Style pretraining strategies and then prompt-finetuned on a mixture of NLP tasks and rivals the state-of-the-art T0-11B model with only **8%** of its parameters.
================================
faculty_name: Chenyan Xiong
faculty_authorid: 2139787803
paper_id: b9e8b62bcc019f47a0a015568f70039b3b7c1196
paper_title: Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model
publication_link: https://arxiv.org/pdf/2310.05155 
year_published: 2023 
abstract_paper:Large Language Models (LLMs) have demonstrated remarkable progress in utilizing tools, but their closed-source nature and high inference costs pose limitations on their adaptability, necessitating a valid method that leverages smaller, open-sourced models. In this paper, we introduce Toolink, a comprehensive framework that performs task-solving by first creating a toolkit and then integrating the planning and calling of tools through a chain-of-solving (CoS) approach. We first validate the efficacy of Toolink in harnessing the model's creativity and CoS ability on ChatGPT. Subsequently, we curate CoS-GPT, a chain-of-solving dataset designed for tool-using, and finetune the LLaMA-7B model. It results in LLaMA-CoS, a powerful open-source model with advanced tool-planning and tool-calling capabilities. Evaluation on diverse tasks from BIG-bench demonstrates its CoS ability matches that of ChatGPT while its performance surpasses the chain-of-thought approach. Further studies highlight the generalization of LLaMA-CoS to unseen tasks and showcase its capability in using toolkits not explicitly tailored for the target task, affirming its robustness in real-world scenarios. All codes and data are released.
isOpenAccess: True
TL\DR: This paper introduces Toolink, a comprehensive framework that performs task-solving by first creating a toolkit and then integrating the planning and calling of tools through a chain-of-s solving (CoS) approach, and results in LLaMA-CoS, a powerful open-source model with advanced tool-planning and tool-calling capabilities.
================================
faculty_name: Chenyan Xiong
faculty_authorid: 2139787803
paper_id: e0401ca2d4fd6d0ed55130a4a24b33ed90111479
paper_title: Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories
publication_link: http://arxiv.org/pdf/2302.03754 
year_published: 2023 
abstract_paper:In this paper we improve the zero-shot generalization ability of language models via Mixture-Of-Memory Augmentation (MoMA), a mechanism that retrieves augmentation documents from multiple information corpora ("external memories"), with the option to"plug in"new memory at inference time. We develop a joint learning mechanism that trains the augmentation component with latent labels derived from the end retrieval task, paired with hard negatives from the memory mixture. We instantiate the model in a zero-shot dense retrieval setting by augmenting a strong T5-based retriever with MoMA. Our model, MoMA, obtains strong zero-shot retrieval accuracy on the eighteen tasks included in the standard BEIR benchmark. It outperforms systems that seek generalization from increased model parameters and computation steps. Our analysis further illustrates the necessity of augmenting with mixture-of-memory for robust generalization, the benefits of augmentation learning, and how MoMA utilizes the plug-in memory at inference time without changing its parameters. We plan to open source our code.
isOpenAccess: True
TL\DR: None
================================
faculty_name: Yiming Yang
faculty_authorid: 2108777093
paper_id: aab67be24b412216ee3a048b20af146459d3c406
paper_title: Functional targeted therapy for glioma based on platelet membrane-coated nanogels
publication_link: https://cancer-nano.biomedcentral.com/counter/pdf/10.1186/s12645-023-00167-w 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: None
================================
faculty_name: Yiming Yang
faculty_authorid: 2108777093
paper_id: bde44227630b017525a9b39aa2643d86090cb9d6
paper_title: Dual Responsive Magnetic Drug Delivery Nanomicelles with Tumor Targeting for Enhanced Cancer Chemo/Magnetothermal Synergistic Therapy
publication_link: https://www.dovepress.com/getfile.php?fileID=95273 
year_published: 2023 
abstract_paper:Introduction Stimulus-responsive nanocarrier systems are promising in cancer treatment. They improve drug stability and facilitate controlled drug release. However, single-responsive nanocarriers still face insufficient tumor targeting and low efficacy. Methods In this study, we synthesized folate-modified DSPE-PEOz nanomicelles with PEG chains and loaded them with magnetic iron particles and doxorubicin (DOX). Folic acid (FA) was employed as a ligand to target cancer cells actively. The nanomicelles are biocompatible and acid-sensitive drug carriers. Magnetic field-responsive nanoparticles enable moderately controlled magnetothermal therapy of tumors regardless of tumor location. The pH/magnetic field dual-responsive nanomicelles shed their PEG layer in response to tumor tissue acidity and react to magnetic fields through magnetothermal effects. Results In vitro and in vivo experiments demonstrated that the nanomicelles could efficiently target cancer cells, release drugs in response to pH changes, and enhance drug uptake through magnetothermal effects. Discussion The dual-responsive magnetic nanomicelles are expected to enhance the anti-cancer efficacy of chemo/magnetothermal synergistic therapy.
isOpenAccess: True
TL\DR: In vitro and in vivo experiments demonstrated that the dual-responsive magnetic nanomicelles could efficiently target cancer cells, release drugs in response to pH changes, and enhance drug uptake through magnetothermal effects.
================================
faculty_name: Yiming Yang
faculty_authorid: 49307703
paper_id: 3040fcdfec29d63f9c25663ac1d58a8b5fec34db
paper_title: Expression of ALCAM in Clinical Colon Cancer and Relationship With Patients’ Treatment Responses
publication_link: https://iv.iiarjournals.org/content/invivo/37/3/1117.full.pdf 
year_published: 2023 
abstract_paper:Background/Aim: Activated leukocyte cell adhesion molecule (ALCAM) plays an important role in cancer via its homotypical and heterotypical interactions with ALCAM or other proteins and can also mediate cell-cell interactions. The present study investigated the expression of ALCAM in relation to epithelial–to–mesenchymal transition (EMT) markers and its downstream signal proteins including Ezrin-Moesin-Radixin (ERM), in clinical colon cancer and in the progression of the disease. Materials and Methods: Expression of ALCAM was determined in a clinical colon cancer cohort and assessed against the clinical pathological factors and outcome, together with the expression patterns of the ERM family and EMT markers. ALCAM protein was detected using immunohistochemistry. Cell line models, with ALCAM knock-down and over-expression, were established and used to test cells’ responses to drugs. Results: Tumours from patients who had distant metastasis and died of colon cancer had low levels of ALCAM. Dukes B and C tumours also had lower ALCAM expression than Dukes A tumours. Patients with high levels of ALCAM had a significantly longer overall and disease-free survival than those with lower ALCAM levels (p=0.040 and p=0.044). ALCAM is not only significantly correlated with SNAI1 and TWIST, also positively correlated with SNAI2. ALCAM enhanced the adhesiveness of colorectal cancer, an effect inhibited by both sALCAM and SRC inhibitors. Finally, high ALCAM expression rendered cells resistant, especially to 5-fluorouracil. Conclusion: Reduced expression of ALCAM in colon cancer is an indicator of disease progression and a poor prognostic indicator for patient’s survival. However, ALCAM can enhance the adhesion ability of cancer cells and render them resistant to chemotherapy drugs.
isOpenAccess: True
TL\DR: In vitro and in vivo experiments demonstrated that the dual-responsive magnetic nanomicelles could efficiently target cancer cells, release drugs in response to pH changes, and enhance drug uptake through magnetothermal effects.
================================
faculty_name: Yiming Yang
faculty_authorid: 49307703
paper_id: ca5d6ee5ce52d039c109fe44b0c68b1fe1f0198a
paper_title: Claudin-10 in the Blood Brain Barrier Function of Cerebral Endothelial Cells and Transendothelial Invasion of Breast Cancer Cells
publication_link: https://ar.iiarjournals.org/content/anticanres/43/9/3923.full.pdf 
year_published: 2023 
abstract_paper:Background/Aim: Claudin-10 (CLDN10) is a membrane integral protein. It is one of the widely expressed tight junctional claudins with functions not well defined. In the present study, the expression profile and its role in cerebral endothelial cells and in the interaction between breast cancer and endothelial cells were investigated. Materials and Methods: CLDN10 expression was examined in a wide range of cell types. Brain endothelial cell models with or without CLDN10 expression were generated using the hCMEC/D3 cell line and used to test the barrier and permeability functions. Transendothelial drug delivery and invasion were also evaluated. Results: hCMEC/D3 cells express high levels of CLDN10, compared with peripheral endothelial cells, mesothelial cells, fibroblasts, and breast cancer cells, which were either negative or expressed low levels of CLDN10. Knockdown of CLDN10 in hCMEC/D3 cells resulted in impaired tight junctions as seen by reduced transendothelial electric resistance and paracellular permeability. It also accelerated invasion of breast cancer cells through the endothelial cell layer. CLDN10 knockdown in hCMEC/D3 cells led to an increase in transendothelial chemodrug delivery. Furthermore, the SRC kinase inhibitor (AZM475271) was able to decrease the impedance and increase the paracellular permeability in cerebral endothelial cells. Conclusion: Cerebral endothelial cells express high levels of CLDN10, a protein regulating barrier function and thereby drug permeability and cancer invasiveness in brain endothelial cells, suggesting that it is a novel therapeutic target for the treatment of brain metastasis-related diseases.
isOpenAccess: True
TL\DR: In vitro and in vivo experiments demonstrated that the dual-responsive magnetic nanomicelles could efficiently target cancer cells, release drugs in response to pH changes, and enhance drug uptake through magnetothermal effects.
================================
faculty_name: Yiming Yang
faculty_authorid: 35729970
paper_id: 08a23cb1ae7b0748407146520c0630d7f2b51c4c
paper_title: Accelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation
publication_link: https://arxiv.org/pdf/2308.06644 
year_published: 2023 
abstract_paper:Graph-based diffusion models have shown promising results in terms of generating high-quality solutions to NP-complete (NPC) combinatorial optimization (CO) problems. However, those models are often inefficient in inference, due to the iterative evaluation nature of the denoising diffusion process. This paper proposes to use progressive distillation to speed up the inference by taking fewer steps (e.g., forecasting two steps ahead within a single step) during the denoising process. Our experimental results show that the progressively distilled model can perform inference 16 times faster with only 0.019% degradation in performance on the TSP-50 dataset.
isOpenAccess: True
TL\DR: Progressive distillation is proposed to use progressive distillation to speed up the inference by taking fewer steps (e.g., forecasting two steps ahead within a single step) during the denoising process.
================================
faculty_name: Yiming Yang
faculty_authorid: 35729970
paper_id: 0a187bee2436f4a2e98dd94d3c2f18b83281efdb
paper_title: Automatic synchrotron tomographic alignment schemes based on genetic algorithms and human-in-the-loop software
publication_link: https://journals.iucr.org/s/issues/2023/01/00/tv5039/tv5039.pdf 
year_published: 2023 
abstract_paper:A highly automatic alignment scheme is proposed to address the pressing challenge in tomographic alignment of future scanning tomography experiments. The results show that the proposed method exhibits excellent sub-pixel alignment accuracy and high time efficiency.
isOpenAccess: True
TL\DR: The results show that the proposed method exhibits excellent sub-pixel alignment accuracy and high time efficiency.
================================
faculty_name: Yiming Yang
faculty_authorid: 35729970
paper_id: 16db1c1c00ac219984c28480cb60fd09b1897bf6
paper_title: High CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma
publication_link: https://www.frontiersin.org/articles/10.3389/fimmu.2023.1228004/pdf?isPublishedV2=False 
year_published: 2023 
abstract_paper:Background Exhaustion of CD8+ tumor-infiltrating lymphocytes (TILs), characterized by the overexpression of immune checkpoints (IC), is a major impediment to anti-tumor immunity. However, the exhaustion status of CD8+TILs in angioimmunoblastic T cell lymphoma (AITL) remains unclear. Therefore, we aimed to elucidate the exhaustion status of CD8+TILs in AITL and its influence on prognosis. Methods The correlation between CD8+TILs and IC expression in AITL was analyzed using single-cell RNA sequencing (n = 2), flow cytometry (n = 20), and RNA sequencing (n = 20). Biological changes related to CD8+TILs exhaustion at different cytotoxic T lymphocyte (CTL) levels (mean expression levels of CD8A, CD8B, GZMA, GZMB, and PRF1) in AITL were evaluated using RNA sequencing (n = 20) and further validated using the GEO dataset (n = 51). The impact of CD8 protein expression and CTL levels on patient prognosis was analyzed using flow cytometry and RNA sequencing, respectively. Results Our findings demonstrated that the higher the infiltration of CD8+TILs, the higher was the proportion of exhausted CD8+TILs characterized by the overexpression of multiple IC. This was accompanied by extensive exhaustion-related biological changes, which suggested severe exhaustion in CD8+TILs and may be one of the main reasons for the poor prognosis of patients with high CD8+TILs and CTL. Conclusion Our study comprehensively reveals the exhaustion status of CD8+TILs and their potential negative impact on AITL prognosis, which facilitates further mechanistic studies and is valuable for guiding immunotherapy strategies.
isOpenAccess: True
TL\DR: The study comprehensively reveals the exhaustion status of CD8+TILs and their potential negative impact on AITL prognosis, which facilitates further mechanistic studies and is valuable for guiding immunotherapy strategies.
================================
faculty_name: Yiming Yang
faculty_authorid: 35729970
paper_id: 2bfa8ac40c1ff8e45c298115fcadae062526310e
paper_title: Numerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel
publication_link: https://www.mdpi.com/2075-4701/13/8/1496/pdf?version=1692605146 
year_published: 2023 
abstract_paper:The fatigue crack propagation behaviour of Q550E high-performance steel (HPS) is studied in this paper. Static tensile testing and fatigue crack propagation testing were carried out, and the results were compared with those of Q235. Finite element models were developed and verified against the experimental results. The impacts of the initial crack angle, crack depth ratio, stress ratio, thickness, and corrosion pitting on the fatigue crack propagation behaviour of the HPS were analysed. The results show that the fatigue life of Q550 was reduced by 18% due to the corrosion pitting, but it did not change the crack propagation path. When the stress intensity factor is higher than a certain value, the fatigue performance of Q235 is better than that of Q550E. The initial crack angle of 52.5° is the critical angle of the crack stress intensity factor. The steel tends to fracture as the crack depth ratio increases, and more attention should be paid to the effective crack length in engineering practice. An increasing stress ratio leads to a smaller stress intensity factor, and the thickness affects the stress intensity factor in the later stage. The crack stress intensity factor around the corrosion pits gradually decreases along the thickness direction, and the crack tips around the corrosion pits tend to reach the yield state initially, accelerating the fatigue fracture of the specimen and ultimately leading to a decrease in fatigue life.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Yiming Yang
faculty_authorid: 35729970
paper_id: 48bd660e0841ca990178cfafec01163ba2bb07ee
paper_title: Association between albumin-to-globulin ratio and the risk of overall survival in advanced non-small cell lung cancer patients with anlotinib treatment: a retrospective cohort study
publication_link: https://bmcpulmmed.biomedcentral.com/counter/pdf/10.1186/s12890-023-02574-6 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Yiming Yang
faculty_authorid: 35729970
paper_id: 535047a5e5845b3a05fb566d9733091448410d75
paper_title: Analysis of Volatile Components in Dried Fruits and Branch Exudates of Schisandra chinensis with Different Fruit Colors Using GC-IMS Technology
publication_link: https://www.mdpi.com/1420-3049/28/19/6865/pdf?version=1695977171 
year_published: 2023 
abstract_paper:To investigate the volatile components of Schisandra chinensis (Turcz.) Bail (commonly known as northern Schisandra) of different colors and to explore their similarities and differences, to identify the main flavor substances in the volatile components of the branch exudates of northern schisandra, and finally to establish a fingerprint map of the volatile components of the dried fruits and branch exudates of northern Schisandra of different colors, we used GC-IMS technology to analyze the volatile components of the dried fruits and branch exudates of three different colors of northern Schisandra and established a fingerprint spectra. The results showed that a total of 60 different volatile chemical components were identified in the branch exudates and dried fruits of Schisandra. The components of germplasm resources with different fruit colors were significantly different. The ion mobility spectrum and OPLS-DA results showed that white and yellow fruits were more similar compared to red fruits. The volatile components in dried fruits were significantly higher than those in branch exudates. After VIP (variable importance in projection) screening, 41 key volatile substances in dried fruits and 30 key volatile substances in branch exudates were obtained. After screening by odor activity value (OAV), there were 24 volatile components greater than 1 in both dried fruits and branch exudates. The most important contributing volatile substance was 3-methyl-butanal, and the most important contributing volatile substance in white fruit was (E)-2-hexenal.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Yiming Yang
faculty_authorid: 35729970
paper_id: 5921cc9349dfc43acfefbddc4c9b81a4b6a0b1f9
paper_title: Secreted endogenous macrosomes reduce Aβ burden and ameliorate Alzheimer’s disease
publication_link: https://www.science.org/doi/pdf/10.1126/sciadv.ade0293?download=true 
year_published: 2023 
abstract_paper:Innovative therapeutic strategies are urgently needed for Alzheimer’s disease (AD) due to the increasing size of the aging population and the lack of effective drug treatment. Here, we report the therapeutic effects of extracellular vesicles (EVs) secreted by microglia, including macrosomes and small EVs, on AD-associated pathology. Macrosomes strongly inhibited β-amyloid (Aβ) aggregation and rescued cells from Aβ misfolding–induced cytotoxicity. Furthermore, macrosome administration reduced Aβ plaques and ameliorated cognitive impairment in mice with AD. In contrast, small EVs slightly promoted Aβ aggregation and did not improve AD pathology. Proteomic analysis of small EVs and macrosomes revealed that macrosomes harbor several important neuroprotective proteins that inhibit Aβ misfolding. In particular, the small integral membrane protein 10–like protein 2B in macrosomes has been shown to inhibit Aβ aggregation. Our observations provide an alternative therapeutic strategy for the treatment of AD over conventional ineffective drug treatments.
isOpenAccess: True
TL\DR: The therapeutic effects of extracellular vesicles secreted by microglia, including macrosomes and small EVs, on AD-associated pathology are reported and macrosomes strongly inhibited β-amyloid aggregation and rescued cells from Aβ misfolding–induced cytotoxicity.
================================
faculty_name: Yiming Yang
faculty_authorid: 35729970
paper_id: 5f90d43e6ece5c6ee6e8186e4b57d46c85377713
paper_title: DIFUSCO: Graph-based Diffusion Solvers for Combinatorial Optimization
publication_link: http://arxiv.org/pdf/2302.08224 
year_published: 2023 
abstract_paper:Neural network-based Combinatorial Optimization (CO) methods have shown promising results in solving various NP-complete (NPC) problems without relying on hand-crafted domain knowledge. This paper broadens the current scope of neural solvers for NPC problems by introducing a new graph-based diffusion framework, namely DIFUSCO. Our framework casts NPC problems as discrete {0, 1}-vector optimization problems and leverages graph-based denoising diffusion models to generate high-quality solutions. We investigate two types of diffusion models with Gaussian and Bernoulli noise, respectively, and devise an effective inference schedule to enhance the solution quality. We evaluate our methods on two well-studied NPC combinatorial optimization problems: Traveling Salesman Problem (TSP) and Maximal Independent Set (MIS). Experimental results show that DIFUSCO strongly outperforms the previous state-of-the-art neural solvers, improving the performance gap between ground-truth and neural solvers from 1.76% to 0.46% on TSP-500, from 2.46% to 1.17% on TSP-1000, and from 3.19% to 2.58% on TSP10000. For the MIS problem, DIFUSCO outperforms the previous state-of-the-art neural solver on the challenging SATLIB benchmark.
isOpenAccess: True
TL\DR: DIFUSCO is introduced, a new graph-based diffusion framework for NPC combinatorial optimization that outperforms the previous state-of-the-art neural solvers on the challenging SATLIB benchmark and investigates two types of diffusion models with Gaussian and Bernoulli noise, respectively.
================================
faculty_name: Yiming Yang
faculty_authorid: 35729970
paper_id: 6a42f6362afa3a1a0936f7a6a8927d04a2285cc5
paper_title: Balancing Exploration and Exploitation in Hierarchical Reinforcement Learning via Latent Landmark Graphs
publication_link: https://arxiv.org/pdf/2307.12063 
year_published: 2023 
abstract_paper:Goal-Conditioned Hierarchical Reinforcement Learning (GCHRL) is a promising paradigm to address the exploration-exploitation dilemma in reinforcement learning. It decomposes the source task into sub goal conditional subtasks and conducts exploration and exploitation in the subgoal space. The effectiveness of GCHRL heavily relies on sub goal representation functions and sub goal selection strategy. However, existing works often overlook the temporal coherence in GCHRL when learning latent sub goal representations and lack an efficient sub goal selection strategy that balances exploration and exploitation. This paper proposes HIerarchical reinforcement learning via dynamically building Latent Landmark graphs (HILL) to overcome these limitations. HILL learns latent subgoal representations that satisfy temporal coherence using a contrastive representation learning objective. Based on these representations, HILL dynamically builds latent landmark graphs and employs a novelty measure on nodes and a utility measure on edges. Finally, HILL develops a subgoal selection strategy that balances exploration and exploitation by jointly considering both measures. Experimental results demonstrate that HILL outperforms state-of-the-art baselines on continuous control tasks with sparse rewards in sample efficiency and asymptotic performance. Our code is available at https://github.com/papercode2022/HILL.
isOpenAccess: True
TL\DR: This paper proposes HIerarchical reinforcement learning via dynamically building Latent Landmark graphs (HILL) to overcome limitations in GCHRL and develops a subgoal selection strategy that balances exploration and exploitation by jointly considering both measures.
================================
faculty_name: Yiming Yang
faculty_authorid: 35729970
paper_id: 844bb298d49ef4a07b5d4929dfdfd170f6a1d5f5
paper_title: Aligning Large Multimodal Models with Factually Augmented RLHF
publication_link: https://arxiv.org/pdf/2309.14525 
year_published: 2023 
abstract_paper:Large Multimodal Models (LMM) are built across modalities and the misalignment between two modalities can result in"hallucination", generating textual outputs that are not grounded by the multimodal information in context. To address the multimodal misalignment issue, we adapt the Reinforcement Learning from Human Feedback (RLHF) from the text domain to the task of vision-language alignment, where human annotators are asked to compare two responses and pinpoint the more hallucinated one, and the vision-language model is trained to maximize the simulated human rewards. We propose a new alignment algorithm called Factually Augmented RLHF that augments the reward model with additional factual information such as image captions and ground-truth multi-choice options, which alleviates the reward hacking phenomenon in RLHF and further improves the performance. We also enhance the GPT-4-generated training data (for vision instruction tuning) with previously available human-written image-text pairs to improve the general capabilities of our model. To evaluate the proposed approach in real-world scenarios, we develop a new evaluation benchmark MMHAL-BENCH with a special focus on penalizing hallucinations. As the first LMM trained with RLHF, our approach achieves remarkable improvement on the LLaVA-Bench dataset with the 94% performance level of the text-only GPT-4 (while previous best methods can only achieve the 87% level), and an improvement by 60% on MMHAL-BENCH over other baselines. We opensource our code, model, data at https://llava-rlhf.github.io.
isOpenAccess: True
TL\DR: This paper proposes HIerarchical reinforcement learning via dynamically building Latent Landmark graphs (HILL) to overcome limitations in GCHRL and develops a subgoal selection strategy that balances exploration and exploitation by jointly considering both measures.
================================
faculty_name: Yiming Yang
faculty_authorid: 35729970
paper_id: b946ca9514be9920e5d1eff11f597facb8f7c6b7
paper_title: An Experimental Study on Secondary Transfer Performances of Prestress after Anchoring Failure of Steel Wire Strands
publication_link: https://www.mdpi.com/2075-4701/13/8/1489/pdf?version=1692363837 
year_published: 2023 
abstract_paper:To understand the secondary transfer performances of residual prestress after the anchoring failure of end-anchored steel wire strands due to corrosion fracture, six steel wire strand components of post-tensioning prestress were designed and fabricated. One-side fast corrosion was applied to the steel wire strand components using the electrochemical method until anchoring failure was reached. The sphere of influence, stress changes, and the retraction and swelling effect of broken beams after failure were investigated. The influences of factors such as concrete strength, stirrup area, and the length of the component on the secondary transfer length of residual prestress were discussed. Based on the deformation relationship between prestressed steel wire strands and concrete in the stress transfer zone, a stress equation was established and solved through a bond constitutive model. A prediction model of the effective stress transfer length of prestressed steel wire strand after failure was proposed. The results demonstrated that residual prestress can have a secondary transfer after the corrosion fracture of end-anchored steel wire strands, but some effective prestress may be lost. Moreover, the loss of prestress is inversely proportional to concrete compressive strength. When the specimens are relatively short, the prestress loss increases significantly. Concrete strength has significant influences on the length of secondary transfer. The proposed simplified calculation method of the secondary transfer length of residual prestress has a relatively high accuracy, with an average error of 2.9% and a maximum error of 5.2%.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Yiming Yang
faculty_authorid: 35729970
paper_id: f1a75a847c99ab399454c911235f0d5f7854c5a4
paper_title: MRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity
publication_link: https://www.dovepress.com/getfile.php?fileID=93036 
year_published: 2023 
abstract_paper:Purpose To identify MRI features of hepatocellular carcinoma (HCC) that predict microvascular invasion (MVI) and postoperative intrahepatic recurrence in patients without peritumoral hepatobiliary phase (HBP) hypointensity. Patients and Methods One hundred and thirty patients with HCC who underwent preoperative gadoxetate-enhanced MRI and curative hepatic resection were retrospectively reviewed. Two radiologists reviewed all preoperative MR images and assessed the radiological features of HCCs. The ability of peritumoral HBP hypointensity to identify MVI and intrahepatic recurrence was analyzed. We then assessed the MRI features of HCC that predicted the MVI and intrahepatic recurrence-free survival (RFS) in the subgroup without peritumoral HBP hypointensity. Finally, a two-step flowchart was constructed to assist in clinical decision-making. Results Peritumoral HBP hypointensity (odds ratio, 3.019; 95% confidence interval: 1.071–8.512; P=0.037) was an independent predictor of MVI. The sensitivity, specificity, positive predictive value, negative predictive value, and AUROC of peritumoral HBP hypointensity in predicting MVI were 23.80%, 91.04%, 71.23%, 55.96%, and 0.574, respectively. Intrahepatic RFS was significantly shorter in patients with peritumoral HBP hypointensity (P<0.001). In patients without peritumoral HBP hypointensity, the only significant difference between MVI-positive and MVI-negative HCCs was the presence of a radiological capsule (P=0.038). Satellite nodule was an independent risk factor for intrahepatic RFS (hazard ratio,3.324; 95% CI: 1.733–6.378; P<0.001). The high-risk HCC detection rate was significantly higher when using the two-step flowchart that incorporated peritumoral HBP hypointensity and satellite nodule than when using peritumoral HBP hypointensity alone (P<0.001). Conclusion In patients without peritumoral HBP hypointensity, a radiological capsule is useful for identifying MVI and satellite nodule is an independent risk factor for intrahepatic RFS.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Yiming Yang
faculty_authorid: 35729970
paper_id: ff4bd0966db6a5f30fe41c8479765e9d9702a8c0
paper_title: Impact of local governments’ construction land allocation strategies on innovation-driven development of China
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Yiming Yang
faculty_authorid: 2260433687
paper_id: 661ef7301c3c399130d3d8673098dd27f5696130
paper_title: Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs
publication_link: http://arxiv.org/pdf/2305.11860 
year_published: 2023 
abstract_paper:A popular approach for improving the correctness of output from large language models (LLMs) is Self-Consistency – poll the LLM multiple times and output the most frequent so-lution. Existing Self-Consistency techniques always draw a constant number of samples per question, where a better approach will be to non-uniformly distribute the available bud-get based on the amount of agreement in the samples drawn so far. In response, we introduce Adaptive-Consistency, a cost-efﬁcient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion. Our experiments over 13 datasets and two LLMs demonstrate that Adaptive-Consistency reduces sample budget by up to 6.0 times with an average accuracy drop of less than 0.1%. 1
isOpenAccess: True
TL\DR: Adaptive-Consistency is introduced, a cost-efﬁcient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion that reduces sample budget by up to 6.0 times with an average accuracy drop of less than 01%.
================================
faculty_name: Yiming Yang
faculty_authorid: 2108776965
paper_id: 225086c2d9411cd20b62181bfe9d0b2883374652
paper_title: 16p11.2 CNV gene Doc2α functions in neurodevelopment and social behaviors through interaction with Secretagogin.
publication_link: http://www.cell.com/article/S2211124723007027/pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: Adaptive-Consistency is introduced, a cost-efﬁcient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion that reduces sample budget by up to 6.0 times with an average accuracy drop of less than 01%.
================================
faculty_name: Yiming Yang
faculty_authorid: 2108776965
paper_id: 915fef14d53ac91df037f7749e922d7ce568d91f
paper_title: Chinese EFL learners different from English natives in cataphora resolution: Evidence from eye-tracking studies
publication_link: https://www.frontiersin.org/articles/10.3389/fpsyg.2023.1126673/pdf 
year_published: 2023 
abstract_paper:Previous studies on English natives have shown that encountering an English cataphoric pronoun triggers an active search for its antecedent and this searching process is modulated by syntactic constraints. It remains unknown whether the conclusion is universal to EFL (English as a Foreign Language) learners, particularly those with distinct L1 like Chinese in linguistic typology. Therefore, this study used two eye-tracking experiments to investigate how Chinese EFL learners resolve English cataphora. The experiments adopted the gender-mismatch paradigm. Experiment 1 investigated whether Chinese EFL learners with different proficiency would adopt the similar processing pattern to English natives and found that gender congruency elicited longer reading times than gender incongruency between the first potential antecedent and the cataphoric pronoun, the effect early observed in high-proficiency relative to low-proficiency learners. Experiment 2 explored whether the cataphora resolution process was modulated by Binding Principle B and revealed that longer first fixation durations and first pass reading times were observed in gender-mismatch than in gender-match conditions no matter the antecedents are binding-accessible or not while longer regression path durations occurred in gender-mismatch than in gender-match conditions only as the antecedents are binding-accessible. Taken together, these results indicate that Chinese EFL learners also adopt an active search mechanism to resolve cataphoric pronouns, yet along a processing path distinct from English natives’. Specifically, Chinese EFL learners predictively link a cataphoric pronoun to the first potential antecedent in the sentence but only a gender-matching antecedent can prompt them to engage in deep processing of the antecedent. Moreover, the processing time varies with the learners’ English proficiency. Furthermore, unlike native English speakers’ early application of syntactic constraints in their cataphora resolution, Chinese EFL learners try to establish co-reference relations between cataphoric pronouns and antecedents regardless of following or flouting Binding Principle B in early processing stages whereas they exclusively link the cataphoric pronouns to the binding-accessible antecedents in late processing stages. This study adds evidence to the Shallow Structure Hypothesis whereby L2 learners resort to lexical prior to syntactic cues to process sentences in general, which is just opposite to the fashion adopted by the natives.
isOpenAccess: True
TL\DR: Adaptive-Consistency is introduced, a cost-efﬁcient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion that reduces sample budget by up to 6.0 times with an average accuracy drop of less than 01%.
================================
faculty_name: Yiming Yang
faculty_authorid: 2275284034
paper_id: 35f6015045c2fe38c8a063c3787fc516f9babfaa
paper_title: Strain-driven Kovacs-like memory effect in glasses
publication_link: https://www.nature.com/articles/s41467-023-44187-x.pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: Adaptive-Consistency is introduced, a cost-efﬁcient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion that reduces sample budget by up to 6.0 times with an average accuracy drop of less than 01%.
================================
faculty_name: Yiming Yang
faculty_authorid: 2229493454
paper_id: e27978b8c3ca83ccc42f2cac11771b14cf910104
paper_title: Synergistic Interface Engineering of RuO2/Co3O4 Heterostructures for Enhanced Overall Water Splitting in Acidic Media
publication_link: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/aesr.202300057 
year_published: 2023 
abstract_paper:Designing nanocomposites with heterointerface as bifunctional electrocatalysts is a potential strategy to overcome the intrinsic activity limitation of electrocatalytic water splitting in acidic media, but it remains challenging. Herein, the highly efficient RuO2/Co3O4 electrocatalyst with a uniform nanoflower structure is prepared by hydrothermal growth combined with interface engineering. Benefiting from the unique nanostructure, the migration of electrons and intermediates is optimized by the sufficient exposure of abundant micropores and defects. Moreover, the formation of strong electronic interaction at the RuO2/Co3O4 heterointerfaces boosts the electrochemical active surface area and accelerates the reaction kinetics, which effectively improve the catalytic activity and stability of the catalyst. Based on enhanced intrinsic activity and electron transfer, the as‐synthesized RuO2/Co3O4 displays impressive hydrogen evolution reaction and oxygen evolution reaction activity, which respectively require low overpotentials of 240 and 100 mV to achieve a current density of 10 mA cm−2 in 0.5 m H2SO4. As a bifunctional electrode, RuO2/Co3O4 exhibits a low operating voltage of 1.58 V at 10 mA cm−2 for overall electrochemical water splitting. This study demonstrates the importance of heterostructure engineering in providing an avenue to achieve acid‐stable bifunctional electrocatalysts for energy conversion applications.
isOpenAccess: True
TL\DR: Adaptive-Consistency is introduced, a cost-efﬁcient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion that reduces sample budget by up to 6.0 times with an average accuracy drop of less than 01%.
================================
faculty_name: Yiming Yang
faculty_authorid: 2240045371
paper_id: 6b8072d781414a33730939ef0b1b4fd0a2291d86
paper_title: Numerical Analysis on the Influence of Joint Density on the Stability of Complex Jointed Roadway Surrounding Rock
publication_link: https://www.mdpi.com/2071-1050/15/18/13561/pdf?version=1694427133 
year_published: 2023 
abstract_paper:The random distribution of a complex joint network within a coal–rock mass has a significant weakening effect on its bearing capacity, making the surrounding rock of the roadway highly susceptible to instability and failure under the influence of in situ stress and mining-induced stress. This poses challenges in controlling the surrounding rock and seriously affects the normal production of mines. Consequently, it is imperative to conduct stability analysis on complex jointed roadway surrounding rock. Therefore, taking the transport roadway of Panel 11030 in the Zhaogu No. 2 Coal Mine as a case study, the microscopic contact parameters of particles and joint surfaces in each rock layer were calibrated through uniaxial compression and shear simulation tests using the particle flow simulation software PFC2D 5.0. Based on the calibrated microscopic contact parameters, a multilayered roadway surrounding rock model containing complex joints was established, and the joint density was quantified to analyze its effects on the displacement field, stress field, force chain field, and energy field of the roadway surrounding rock. The research findings indicate that as the distance to the sidewall decreases, the impact of joint density on the deformation of the surrounding rock of the roadway increases. The displacement of the roadway roof, floor, and sidewalls is affected differently by the joint density, predominantly contingent upon the properties of the rock mass. During the process of stress redistribution in the surrounding rock, the vertical stress of the roof and floor is released more intensively compared to the horizontal stress, while the horizontal stress of the sidewalls is released more intensively compared to the vertical stress. The increase in joint density leads to an increasing release rate of the surrounding rock stress, causing the load-bearing rock mass to transfer towards the deeper part. As the joint density increases, the force chain network gradually transitions from dense to sparse, resulting in a decrease in strong force chains and a decline in the bearing capacity of the surrounding rock, accompanied by an expansion in the range of force chain failure and deformation. With the continuous increase in joint density, the values of maximum released kinetic energy and residual released kinetic energy become larger. Once the joint density reaches a certain threshold, the kinetic energy stability zone consistently maintains a high energy level, indicating extreme instability in the roadway and sustained deformation. The results provide a valuable insight for analyzing the failure mechanism of complex jointed roadway surrounding rock and implementing corresponding support measures.
isOpenAccess: True
TL\DR: Adaptive-Consistency is introduced, a cost-efﬁcient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion that reduces sample budget by up to 6.0 times with an average accuracy drop of less than 01%.
================================
faculty_name: Yiming Yang
faculty_authorid: 2269119242
paper_id: 2206b7efd166ca0276ee8d169f4b76d8fa05af5c
paper_title: Experimental Study on Secondary Anchorage Bond Performance of Residual Stress after Corrosion Fracture at Ends of Prestressed Steel Strands
publication_link: https://www.mdpi.com/1996-1944/16/23/7441/pdf?version=1701314170 
year_published: 2023 
abstract_paper:In order to explore the secondary bond anchorage performance between prestressed tendons and concrete after the fracture of steel strands in post-tensioned, prestressed concrete (PPC) beams, a total of seven post-tensioned, prestressed concrete specimens with a size of 3 × 7ϕ15.2 mm were constructed firstly, and the steel strands at the anchorage end were subjected to corrosion fracture. Then, the pull-out test of the specimens was conducted to explore the secondary anchorage bond mechanism of the residual stress of prestressed tendons experiencing local fracture. Moreover, the influences of factors such as the embedded length, release-tensioning speed, concrete strength, and stirrup configuration on anchorage bond performance were analyzed. Finally, the test results were further verified via finite element analysis. The results show that the failure of pull-out specimens under different parameters can be divided into two types: bond anchorage failure induced by the entire pull-out of steel strands and material failure triggered by the rupture of steel strands. The bond anchorage failure mechanism between steel strands and the concrete was revealed by combining the failure characteristics and pull-out load–slippage relation curves. The bond strength between prestressed steel strands and concrete can be enhanced by increasing the embedded length of steel strands, elevating the concrete strength grade, and enlarging the diameter of stirrups so that the specimens are turned from bond anchorage failure into material failure.
isOpenAccess: True
TL\DR: Adaptive-Consistency is introduced, a cost-efﬁcient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion that reduces sample budget by up to 6.0 times with an average accuracy drop of less than 01%.
================================
faculty_name: Yiming Yang
faculty_authorid: 2273535961
paper_id: 402e8ae2a2b11aac5464d9fb5a31e15b4c0596ca
paper_title: Genome- and transcriptome-wide identification of trehalose-6-phosphate phosphatases (TPP) gene family and their expression patterns under abiotic stress and exogenous trehalose in soybean
publication_link: https://bmcplantbiol.biomedcentral.com/counter/pdf/10.1186/s12870-023-04652-7 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: Adaptive-Consistency is introduced, a cost-efﬁcient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion that reduces sample budget by up to 6.0 times with an average accuracy drop of less than 01%.
================================
faculty_name: Yiming Yang
faculty_authorid: 2144133701
paper_id: 7e7ab2af26025d1aa2a6a90fab7713139a9327f7
paper_title: Inference of single cell profiles from histology stains with the Single-Cell omics from Histology Analysis Framework (SCHAF)
publication_link: https://www.biorxiv.org/content/biorxiv/early/2023/03/23/2023.03.21.533680.full.pdf 
year_published: 2023 
abstract_paper:Tissue biology involves an intricate balance between cell-intrinsic processes and interactions between cells organized in specific spatial patterns, which can be respectively captured by single-cell profiling methods, such as single-cell RNA-seq (scRNA-seq), and histology imaging data, such as Hematoxylin-and-Eosin (H&E) stains. While single-cell profiles provide rich molecular information, they can be challenging to collect routinely and do not have spatial resolution. Conversely, histological H&E assays have been a cornerstone of tissue pathology for decades, but do not directly report on molecular details, although the observed structure they capture arises from molecules and cells. Here, we leverage adversarial machine learning to develop SCHAF (Single-Cell omics from Histology Analysis Framework), to generate a tissue sample’s spatially-resolved single-cell omics dataset from its H&E histology image. We demonstrate SCHAF on two types of human tumors—from lung and metastatic breast cancer—training with matched samples analyzed by both sc/snRNA-seq and by H&E staining. SCHAF generated appropriate single-cell profiles from histology images in test data, related them spatially, and compared well to ground-truth scRNA-Seq, expert pathologist annotations, or direct MERFISH measurements. SCHAF opens the way to next-generation H&E2.0 analyses and an integrated understanding of cell and tissue biology in health and disease.
isOpenAccess: True
TL\DR: Adaptive-Consistency is introduced, a cost-efﬁcient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion that reduces sample budget by up to 6.0 times with an average accuracy drop of less than 01%.
================================
faculty_name: Yiming Yang
faculty_authorid: 51285945
paper_id: 9a40b3eb8cd454c72dfb4340a595d9aec1c9b8c1
paper_title: Recent Advances in the Ecology of Bloom-Forming Raphidiopsis (Cylindrospermopsis) raciborskii: Expansion in China, Intraspecific Heterogeneity and Critical Factors for Invasion
publication_link: https://www.mdpi.com/1660-4601/20/3/1984/pdf?version=1674288049 
year_published: 2023 
abstract_paper:Water blooms caused by the invasive cyanobacterium Raphidiopsis raciborskii occur in many reservoirs in the tropical and subtropical regions of China. In recent decades, this species has spread rapidly to temperate regions. Phenotypic plasticity and climate warming are thought to promote the worldwide dispersion of R. raciborskii. However, investigations into the genetic and phenotypic diversities of this species have revealed significant intraspecific heterogeneity. In particular, competition between R. raciborskii and Microcystis aeruginosa was highly strain dependent. Although the concept of an ecotype was proposed to explain the heterogeneity of R. raciborskii strains with different geographic origins, microevolution is more reasonable for understanding the coexistence of different phenotypes and genotypes in the same environment. It has been suggested that intraspecific heterogeneity derived from microevolution is a strong driving force for the expansion of R. raciborskii. Additionally, temperature, nutrient fluctuations, and grazer disturbance are critical environmental factors that affect the population establishment of R. raciborskii in new environments. The present review provides new insights into the ecological mechanisms underlying the invasion of R. raciborskii in Chinese freshwater ecosystems.
isOpenAccess: True
TL\DR: Adaptive-Consistency is introduced, a cost-efﬁcient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion that reduces sample budget by up to 6.0 times with an average accuracy drop of less than 01%.
================================
faculty_name: Yiming Yang
faculty_authorid: 1668469345
paper_id: 3bfe260eeb37141206adf719ce02ba40e9cb606a
paper_title: An Ultra-Low-Power Analog Multiplier–Divider Compatible with Digital Code for RRAM-Based Computing-in-Memory Macros
publication_link: https://www.mdpi.com/2072-666X/14/7/1482/pdf?version=1690201887 
year_published: 2023 
abstract_paper:This manuscript presents an ultra-low-power analog multiplier–divider compatible with digital code words, which is applicable to the integrated structure of resistive random-access memory (RRAM)-based computing-in-memory (CIM) macros. Current multiplication and division are accomplished by a current-mirror-based structure. Compared with digital dividers to achieve higher precision and operation speed, analog dividers present the advantages of a reduced power consumption and a simple circuit structure in lower precision operations, thus improving the energy efficiency. Designed and fabricated in a 55 nm CMOS process, the proposed work is capable of achieving 8-bit precision for analog current multiplication and division operations. Measurement results show that the signal delay is 1 μs when performing 8-bit operation, with a bandwidth of 1.4 MHz. The power consumption is less than 6.15 μW with a 1.2 V supply voltage. The proposed multiplier–divider can increase the operation capacity by dividing the input current and digital code while reducing the power consumption and complexity required by division, which can be further utilized in real-time operation of edge computing devices.
isOpenAccess: True
TL\DR: Adaptive-Consistency is introduced, a cost-efﬁcient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion that reduces sample budget by up to 6.0 times with an average accuracy drop of less than 01%.
================================
faculty_name: Yiming Yang
faculty_authorid: 2279157473
paper_id: 2445df274c402c8d6b07c2e81210e5b3b7b8e2f8
paper_title: Extension of Pt–Ag cluster units by incorporating silver salts
publication_link: https://academic.oup.com/chemlett/advance-article-pdf/doi/10.1093/chemle/upad004/54025599/upad004.pdf 
year_published: 2023 
abstract_paper:
 A sterically controlled Z-shaped Pt2Ag2 complex showed a metalation reaction with a Ag ion via the formation of the thermodynamically unfavorable Pt2Ag2 complex with U-shaped configuration. Multiple dative bond formation between Pt and an additional Ag ion endowed enough thermodynamic stability on the Pt2Ag3 cluster to overcome the unfavorable steric effect from bulky substituents on the ligands in the U-shaped structure. A single crystal X-ray structural analysis revealed dimerized structure of the cationic Pt2Ag3 complex units bridged by [Ag2(OTf)4]2− (OTf− = triflate anion) via strong Ag–π coordination with pyrazole moiety in the solid state. The heteropolynuclear complexes showed photoluminescence properties depending on the structure of the Pt–Ag clusters.
isOpenAccess: True
TL\DR: Adaptive-Consistency is introduced, a cost-efﬁcient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion that reduces sample budget by up to 6.0 times with an average accuracy drop of less than 01%.
================================
faculty_name: Yiming Yang
faculty_authorid: 2266988117
paper_id: aa066313c58d9fa64a94d3f88e36cbc778916d76
paper_title: Optimization of Critical Factors Affecting Dynamic Membrane Formation in a Gravity-Driven Self-Forming Dynamic Membrane Bioreactor towards Low-Cost and Low-Maintenance Wastewater Treatment
publication_link: https://www.mdpi.com/2073-4441/15/22/3963/pdf?version=1700030050 
year_published: 2023 
abstract_paper:Self-forming dynamic membrane (SFDM) formation is affected by a variety of operating conditions. However, previous studies have only focused on individual influencing factors and a systematic analysis of important factors is lacking. In this study, an aerobic self-forming dynamic membrane bioreactor (SFDMBR) was developed for the treatment of domestic wastewater with the critical factors that affect the effective formation of SFDM optimized, and the operational performances under optimized formation conditions confirmed. The results indicated that SFDM could be formed within 5 min using 48 μm stainless-steel mesh as the supporting material at a sludge concentration of 5–6 g/L and a gravity waterhead of 15 cm. And the SFDM formed could maintain a stable flux of 30–50 LMH, and the removals of COD, SCOD, and NH4+-N were 93.28%, 82.85%, and 95.46%, respectively. Furthermore, the cake layer resistance (reversible fouling) contributed to 95.93% of the total filtration resistance, thus a simple physical cleaning can effectively restore the flux indicating a low-maintenance requirement. This study provides valuable insights into the optimization and application of the SFDMBR process.
isOpenAccess: True
TL\DR: Adaptive-Consistency is introduced, a cost-efﬁcient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion that reduces sample budget by up to 6.0 times with an average accuracy drop of less than 01%.
================================
faculty_name: Yiming Yang
faculty_authorid: 2108776816
paper_id: 70a6d974580a272e724936b6bc9cd27064098604
paper_title: Imaging Field‐Driven Melting of a Molecular Solid at the Atomic Scale
publication_link: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/adma.202300542 
year_published: 2023 
abstract_paper:Solid–liquid phase transitions are basic physical processes, but atomically resolved microscopy has yet to capture their full dynamics. A new technique is developed for controlling the melting and freezing of self‐assembled molecular structures on a graphene field‐effect transistor (FET) that allows phase‐transition behavior to be imaged using atomically resolved scanning tunneling microscopy. This is achieved by applying electric fields to 2,3,5,6‐tetrafluoro‐7,7,8,8‐tetracyanoquinodimethane‐decorated FETs to induce reversible transitions between molecular solid and liquid phases at the FET surface. Nonequilibrium melting dynamics are visualized by rapidly heating the graphene substrate with an electrical current and imaging the resulting evolution toward new 2D equilibrium states. An analytical model is developed that explains observed mixed‐state phases based on spectroscopic measurement of solid and liquid molecular energy levels. The observed nonequilibrium melting dynamics are consistent with Monte Carlo simulations.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Yiming Yang
faculty_authorid: 2132052069
paper_id: 0c00dd3f3c1111a09933b30d305a03ab00e866bc
paper_title: A Wideband Reconfigurable Intelligent Surface for 5G Millimeter-Wave Applications
publication_link: http://arxiv.org/pdf/2304.11572 
year_published: 2023 
abstract_paper:Despite the growing interest in reconfigurable intelligent surfaces (RISs) for millimeter-wave (mm-wave) bands, and the considerable theoretical work reported by the communication community, there is a limited number of published works demonstrating practical implementations and experimental results. To the authors' knowledge, no published literature has reported experimental results for RISs covering the n257 and n258 mm-wave bands. In this work, we propose a novel wideband RIS design that covers the entire mm-wave 5G n257 and n258 bands. In simulations, the unit cell can maintain a phase difference of 180{\deg} +- 20{\deg} and a reflection magnitude greater than -2.8 dB within 22.7 to 30.5 GHz (29.3% bandwidth) using one-bit PIN switches. The proposed unit cell design with four circular cutouts and long vias could realize wideband performance by exciting two adjacent high-order resonances (2.5f and 3.5f). The periodic unit cells can maintain an angular stability of 30{\deg}. Based on the proposed unit cell, a 20 by 20 RIS array is designed and fabricated with a size of 7.1{\lambda} by 7.1{\lambda}. The measurement results demonstrate that the proposed RIS could maintain a 3 dB peak gain variation bandwidth among various array configurations within 22.5 to 29.5 GHz (26.9%) and with a beam scanning capability of 50{\deg}, making this design a good candidate for 5G mm-wave applications.
isOpenAccess: True
TL\DR: This work proposes a novel wideband RIS design that covers the entire mm-wave 5G n257 and n258 bands and demonstrates that the proposed RIS could maintain a 3 dB peak gain variation bandwidth among various array configurations within 22.5 to 29.5 GHz.
================================
faculty_name: Yiming Yang
faculty_authorid: 2132052069
paper_id: 8635b9f82f6d0af1c24e837502be4e7de9bfddde
paper_title: A Via-Less Fully Screen-Printed Reconfigurable Intelligent Surface for 5G Millimeter Wave Communication
publication_link: https://arxiv.org/pdf/2302.03424 
year_published: 2023 
abstract_paper:In this paper, we propose a via-less fully screen-printed reconfigurable intelligent surface which can establish a second line-of-sight communication from 23.5GHz to 29.5GHz. By serially connecting the H shaped resonator along the H field of the incident wave, we minimize the effect of the biasing lines and make a via-less design, which reduces the fabrication difficulty and cost. The unit-cell simulation of the array with screen-printed VO2 switches shows a 215° to 160° phase shift difference between the ON and OFF states within bandwidth. During the field testing of the ideal arrays, we verify that the array can redirect the 45° incident wave to 0° reflection with a signal enhancement of at least 10 dB as compared to the array which has all unit cells in the OFF condition.
isOpenAccess: True
TL\DR: A via-less fully screen-printed reconfigurable intelligent surface which can establish a second line-of-sight communication and can redirect the 45° incident wave to 0° reflection with a signal enhancement of at least 10 dB as compared to the array which has all unit cells in the OFF condition.
================================
faculty_name: Yiming Yang
faculty_authorid: 2257099254
paper_id: 24df244bf7a6e8c93c5f183d3f62d39c0f773c68
paper_title: SALMON: Self-Alignment with Principle-Following Reward Models
publication_link: https://arxiv.org/pdf/2310.05910 
year_published: 2023 
abstract_paper:Supervised Fine-Tuning (SFT) on response demonstrations combined with Reinforcement Learning from Human Feedback (RLHF) constitutes a powerful paradigm for aligning LLM-based AI agents. However, a significant limitation of such an approach is its dependency on high-quality human annotations, making its application to intricate tasks challenging due to difficulties in obtaining consistent response demonstrations and in-distribution response preferences. This paper presents a novel approach, namely SALMON (Self-ALignMent with principle-fOllowiNg reward models), to align base language models with minimal human supervision, using only a small set of human-defined principles, yet achieving superior performance. Central to our approach is a principle-following reward model. Trained on synthetic preference data, this model can generate reward scores based on arbitrary human-defined principles. By merely adjusting these principles during the RL training phase, we gain full control over the preferences with the reward model, subsequently influencing the behavior of the RL-trained policies, and eliminating the reliance on the collection of online human preferences. Applying our method to the LLaMA-2-70b base language model, we developed an AI assistant named Dromedary-2. With only 6 exemplars for in-context learning and 31 human-defined principles, Dromedary-2 significantly surpasses the performance of several state-of-the-art AI systems, including LLaMA-2-Chat-70b, on various benchmark datasets. We have open-sourced the code and model weights to encourage further research into aligning LLM-based AI agents with enhanced supervision efficiency, improved controllability, and scalable oversight.
isOpenAccess: True
TL\DR: A via-less fully screen-printed reconfigurable intelligent surface which can establish a second line-of-sight communication and can redirect the 45° incident wave to 0° reflection with a signal enhancement of at least 10 dB as compared to the array which has all unit cells in the OFF condition.
================================
faculty_name: Yiming Yang
faculty_authorid: 2144133401
paper_id: 9ad3bf432b4c71a7324d85c7d970e15d7681dbe0
paper_title: Widely Targeted Metabolomics Was Used to Reveal the Differences between Non-Volatile Compounds in Different Wines and Their Associations with Sensory Properties
publication_link: https://www.mdpi.com/2304-8158/12/2/290/pdf?version=1673357313 
year_published: 2023 
abstract_paper:In this study, metabolites from six varieties of wines, including ‘Haasan’ (A1), ‘Zuoshaner’ (A2), ‘Beibinghong’ (A3), ‘Shuanghong’ (A4), ‘Zijingganlu’ (A5), and ‘Cabernet Sauvignon’ (A6), were identified and quantified using widely targeted metabolomics analysis techniques. Based on the test results, 1172 metabolites were detected and classified into 18 categories. These include 62 amino acids, 178 alkaloids, 189 flavonoids, 106 phenols, 148 terpenoids, etc. Comparing the differential metabolites between the comparison groups of each variety, differences between varieties based on P-values and VIP values were shown. Among these differential metabolites, Trimethoprim and Crotonoside were screened out as core differential metabolites. Multiple comparisons also screened the biomarkers for each species. We used widely targeted metabolomics to reveal the differences between non-volatile compounds in different wines and their associations with sensory properties. We also used the simultaneous weighted gene co-expression network analysis (WGCNA) to correlate metabolites with sensory traits, including color difference values and taste characteristics. Two of the six key modules were screened by WGCNA for relevance to sensory traits (brown module and turquoise module). This study provides a high-throughput method for linking compounds to various sensory characteristics of food, opening up new avenues for explaining differences in different varieties of wine.
isOpenAccess: True
TL\DR: A via-less fully screen-printed reconfigurable intelligent surface which can establish a second line-of-sight communication and can redirect the 45° incident wave to 0° reflection with a signal enhancement of at least 10 dB as compared to the array which has all unit cells in the OFF condition.
================================
faculty_name: Yiming Yang
faculty_authorid: 2259993111
paper_id: f41fd54d122d7de833e2d5b2a57444c301ca99eb
paper_title: Cardsformer: Grounding Language to Learn a Generalizable Policy in Hearthstone
publication_link: https://ebooks.iospress.nl/pdf/doi/10.3233/FAIA230581 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: A via-less fully screen-printed reconfigurable intelligent surface which can establish a second line-of-sight communication and can redirect the 45° incident wave to 0° reflection with a signal enhancement of at least 10 dB as compared to the array which has all unit cells in the OFF condition.
================================
faculty_name: Yiming Yang
faculty_authorid: 2273004176
paper_id: 15705015ad838324e7db6f585f9b527327994803
paper_title: Approximation and interpolation with neural network
publication_link: https://tns.ewapublishing.org/media/7dded6c00f864c09af32ac8ef21e76c8.marked.pdf 
year_published: 2023 
abstract_paper:In this paper we show that multilayer feedforward networks with one single hidden layer.and certain types of activation functions can approximate univariant continuous functions defined on a compact set. arbitrarily well. In particular, our results contain some usual activation functions such as sigmoidal functions, RELU functions and threshold functions. Besides, since interpolation problems are highly related to approximation problem, we demonstrate that a wide range of functions have the ability to interpolate and generalize our results to functions which are not polynomial on R. Compared to existing results by numerous work, our methods are more intuitive and less technical. Lastly, the paper discusses the possibility of combining interpolation property and approximating property together, and demonstrates that given any Riemann integrable functions on a compact set in R, with several points on its graph, the finite combination of monotone sigmoidal functions can pass through these points and approximate the given function arbitrarily well with respect to L^1 (dx) (in the sense of Riemann integral) when the number of points getting large.
isOpenAccess: True
TL\DR: A via-less fully screen-printed reconfigurable intelligent surface which can establish a second line-of-sight communication and can redirect the 45° incident wave to 0° reflection with a signal enhancement of at least 10 dB as compared to the array which has all unit cells in the OFF condition.
================================
faculty_name: Yiming Yang
faculty_authorid: 2277151152
paper_id: 92e48a081c080d2a5b6fe17ea9e1cb9d218e3505
paper_title: A Graphene Geometric Diode with the Highest Asymmetry Ratio and Three States Gate‐Tunable Rectification Ability
publication_link: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/aelm.202300695 
year_published: 2023 
abstract_paper:Graphene geometric diodes, with applications in THz detection, energy harvesting, and high‐speed rectification, have been previously constrained by graphene quality and geometry feature size. This study presents significant advancements in graphene geometric diodes by employing the h‐BN/monolayer graphene/h‐BN heterojunction and extremely precise electron beam lithography. Two distinct designs of graphene geometric diodes with neck widths of 23 and 26 nm are fabricated, the superior of which demonstrated an asymmetry ratio of 1.97, a zero bias current responsivity of 0.6 A W−1, and a voltage responsivity of 12,000 V W−1, setting new benchmarks for such devices. Integrating this device into a rectification circuit, the experimentally validate that the rectified DC output voltage can be dynamically modulated and even inverted through adjustments to the diode's gate voltage. This behavior aligns seamlessly with graphene's intrinsic tunability of charge carriers, implying promising prospects for the device's application in advanced logic circuits, bidirectional switches, and signal modulation/demodulation techniques.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Yiming Yang
faculty_authorid: 2258421175
paper_id: cfc9f23631c9dcb0935af6cf43d23854959a35c8
paper_title: De novo assembling a high-quality genome sequence of Amur grape (Vitis amurensis Rupr.) gives insight into Vitis divergence and sex determination
publication_link: https://www.biorxiv.org/content/biorxiv/early/2023/10/10/2023.10.09.561595.full.pdf 
year_published: 2023 
abstract_paper:To date, there is no high-quality sequence for genomes of the East Asian grape species, hindering biological and breeding research efforts to improve grape cultivars. This study presents a ∼522 Mb of the Vitis amurensis (Va) genome sequence containing 27,635 coding genes. Phylogenetic analysis indicated that V. riparia (Vr) may firstly split from the other two species, Va, V. Vinifera (Vv; Pinot Noir: PN40024 and Cabernet Sauvignon). Much divergent gene reservation among three grape duplicated gene sets suggests that the core eudicot common hexaploidy (ECH), 130 million years ago (Mya), has still played a non-negligible role in grape species divergence and biological innovation. Prominent accumulation of sequence variants might have improved cold resistance in Va, resulting in a more robust cold resistance gene regulatory network than those in Vv and Vr. In contrast, Va preserved much fewer NBS disease resistance genes than the other grapes. Notably, multi-omics analysis identified one trans-cinnamate 4-monooxygenase gene positively correlated to the resveratrol accumulated during Va berry development. A selective sweep analysis revealed a hypothetical Va sex-determination region (SDR). Besides, a PPR-containing protein-coding gene in the hypothetical SDR may be related with sex determination in Va. The content and arrangement order of genes in the putative SDR of female Va were similar to the SDR of female Vv. However, the putative SDR of female Va lost one Flavin-containing monooxygenases (FMO) and contained one extra uncharacterized protein-coding gene. These findings will improve the understanding of Vitis biology and contribute to the improvement of grape breeding.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Yiming Yang
faculty_authorid: 2142828680
paper_id: e55d2e5eaabf1ecef8a4d27c669413deb51690e9
paper_title: The Relationship between the Serum NLRP1 Level and Coronary Lesions in Patients with Coronary Artery Disease
publication_link: https://downloads.hindawi.com/journals/ijclp/2023/2250055.pdf 
year_published: 2023 
abstract_paper:Background The pathogenesis of coronary artery disease is complex, and inflammation is one of the regulatory factors. The nucleotide-binding oligomerization domain (NOD)-like receptor protein 1 (NLRP1) plays an important role in the cellular inflammatory response, cell apoptosis, cell death, and autoimmune diseases. Whether the level of NLRP1 is related to the severity of coronary artery stenosis in patients with coronary artery disease (CAD) has not been reported. Objective To test the serum level of NLRP1 in unstable angina (UA) patients and investigate the effect of NLRP1 on coronary stenosis severity of the coronary artery disease (CAD). Methods 307 patients hospitalized in the Department of Cardiology of the Affiliated Hospital of Xuzhou Medical University for coronary angiography from January 1, 2021, to December 31, 2022 were included. We detect the level of NLRP1 in the serum of the included patients. Patients were divided into UA group and control group according to coronary angiography results and other clinical data. We use logistic regression to screen the influencing factors of UA. Then, subgroups were divided according to the Gensini score and the number of coronary artery lesions, and the difference of serum NLRP1 level between the groups was compared. Spearman correlation analysis was used to explore the correlation between the serum NLRP1 level and Gensini score. We analyze the diagnostic value of NLRP1 for UA by drawing ROC curve. Results The median level of serum NLRP1 in patients with UA (n = 257) was 49.71 pg/ml, IQR 30.15, 80.21, and that in patients without UA (n = 50) was 24.75 pg/ml, IQR 13.49, 41.95. Serum NLRP1 levels were significantly different among different subgroups. The patient's Gensini score was correlated with the patient's serum NLRP1 level. Conclusion The serum NLRP1 level is increased in patients with UA, which is increased with the increasing severity of coronary lesions.
isOpenAccess: True
TL\DR: The serumNLRP1 level is increased in patients with UA, which is increased with the increasing severity of coronary lesions, and the diagnostic value of NLRP1 for UA is analyzed by drawing ROC curve.
================================
faculty_name: Yiming Yang
faculty_authorid: 2264359415
paper_id: 5886281fe8f522b2f82a5957d8ef53d44578b3e6
paper_title: Matrine induces ferroptosis in cervical cancer through activation of piezo1 channel.
publication_link: Not given 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: The serumNLRP1 level is increased in patients with UA, which is increased with the increasing severity of coronary lesions, and the diagnostic value of NLRP1 for UA is analyzed by drawing ROC curve.
================================
faculty_name: Yiming Yang
faculty_authorid: 46286308
paper_id: 02ce4d3f93902a94ec2b57630b77696b7f18c84a
paper_title: PESCO: Prompt-enhanced Self Contrastive Learning for Zero-shot Text Classification
publication_link: http://arxiv.org/pdf/2305.14963 
year_published: 2023 
abstract_paper:We present PESCO, a novel contrastive learning framework that substantially improves the performance of zero-shot text classification. We formulate text classification as a neural text retrieval problem where each document is treated as a query, and the system learns the mapping from each query to the relevant class labels by (1) adding prompts to enhance label retrieval, and (2) using retrieved labels to enrich the training set in a self-training loop of contrastive learning. PESCO achieves state-of-the-art performance on four benchmark text classification datasets. On DBpedia, we achieve 98.5% accuracy without any labeled data, which is close to the fully-supervised result. Extensive experiments and analyses show all the components of PESCO are necessary for improving the performance of zero-shot text classification.
isOpenAccess: True
TL\DR: The serumNLRP1 level is increased in patients with UA, which is increased with the increasing severity of coronary lesions, and the diagnostic value of NLRP1 for UA is analyzed by drawing ROC curve.
================================
faculty_name: Yiming Yang
faculty_authorid: 46286308
paper_id: 1786a2f9140ed7211b21302977de64e948b92308
paper_title: Learning Performance-Improving Code Edits
publication_link: http://arxiv.org/pdf/2302.07867 
year_published: 2023 
abstract_paper:The waning of Moore's Law has shifted the focus of the tech industry towards alternative methods for continued performance gains. While optimizing compilers are a standard tool to help increase program efficiency, programmers continue to shoulder much responsibility in crafting and refactoring code with better performance characteristics. In this paper, we investigate the ability of large language models (LLMs) to suggest functionally correct, performance improving code edits. We hypothesize that language models can suggest such edits in ways that would be impractical for static analysis alone. We investigate these questions by curating a large-scale dataset of Performance-Improving Edits, PIE. PIE contains trajectories of programs, where a programmer begins with an initial, slower version and iteratively makes changes to improve the program's performance. We use PIE to evaluate and improve the capacity of large language models. Specifically, use examples from PIE to fine-tune multiple variants of CODEGEN, a billion-scale Transformer-decoder model. Additionally, we use examples from PIE to prompt OpenAI's CODEX using a few-shot prompting. By leveraging PIE, we find that both CODEX and CODEGEN can generate performance-improving edits, with speedups of more than 2.5x for over 25% of the programs, for C++ and Python, even after the C++ programs were compiled using the O3 optimization level. Crucially, we show that PIE allows CODEGEN, an open-sourced and 10x smaller model than CODEX, to match the performance of CODEX on this challenging task. Overall, this work opens new doors for creating systems and methods that can help programmers write efficient code.
isOpenAccess: True
TL\DR: The serumNLRP1 level is increased in patients with UA, which is increased with the increasing severity of coronary lesions, and the diagnostic value of NLRP1 for UA is analyzed by drawing ROC curve.
================================
faculty_name: Yiming Yang
faculty_authorid: 46286308
paper_id: 1804dc14b1cf7bbae96bf3215997e9f14425d622
paper_title: Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-tuned GPT
publication_link: http://arxiv.org/pdf/2304.11872 
year_published: 2023 
abstract_paper:Moreover, GPT-based zero-shot classification models tend to make independent predictions over test instances, which can be sub-optimal as the instance correlations and the decision boundaries in the target space are ignored. To address these difficulties and limitations, we propose a new approach to zero-shot text classification, namely \ourmodelshort, which leverages the strong generative power of GPT to assist in training a smaller, more adaptable, and efficient sentence encoder classifier with contrastive self-training. Specifically, GenCo applies GPT in two ways: firstly, it generates multiple augmented texts for each input instance to enhance the semantic embedding of the instance and improve the mapping to relevant labels; secondly, it generates augmented texts conditioned on the predicted label during self-training, which makes the generative process tailored to the decision boundaries in the target space. In our experiments, GenCo outperforms previous state-of-the-art methods on multiple benchmark datasets, even when only limited in-domain text data is available.
isOpenAccess: True
TL\DR: The serumNLRP1 level is increased in patients with UA, which is increased with the increasing severity of coronary lesions, and the diagnostic value of NLRP1 for UA is analyzed by drawing ROC curve.
================================
faculty_name: Yiming Yang
faculty_authorid: 46286308
paper_id: 3aaf6a2cbad5850ad81ab5c163599cb3d523436f
paper_title: Self-Refine: Iterative Refinement with Self-Feedback
publication_link: http://arxiv.org/pdf/2303.17651 
year_published: 2023 
abstract_paper:Like humans, large language models (LLMs) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an initial output using an LLMs; then, the same LLMs provides feedback for its output and uses it to refine itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner, and feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs. Across all evaluated tasks, outputs generated with Self-Refine are preferred by humans and automatic metrics over those generated with the same LLM using conventional one-step generation, improving by ~20% absolute on average in task performance. Our work demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using our simple, standalone approach.
isOpenAccess: True
TL\DR: The serumNLRP1 level is increased in patients with UA, which is increased with the increasing severity of coronary lesions, and the diagnostic value of NLRP1 for UA is analyzed by drawing ROC curve.
================================
faculty_name: Yiming Yang
faculty_authorid: 46286308
paper_id: 3c92fd24ea2a49aeba4b368abe3ef13cbce40987
paper_title: Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions
publication_link: https://aclanthology.org/2023.findings-eacl.81.pdf 
year_published: 2023 
abstract_paper:Extreme Multi-label Text Classification (XMTC) has been a tough challenge in machine learning research and applications due to the sheer sizes of the label spaces and the severe data scarcity problem associated with the long tail of rare labels in highly skewed distributions. This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents (as queries) to relevant label descriptions. To further enhance the quality of label descriptions, we propose to generate pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions.The proposed approach achieves the state-of-the-art (SOTA) performance of overall label prediction on XMTC benchmark datasets and especially outperforms the SOTA models in the tail label prediction. We also provide a theoretical analysis for relating the BoW and neural models w.r.t. performance lower bound.
isOpenAccess: True
TL\DR: This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents to relevant label descriptions and generates pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions.
================================
faculty_name: Yiming Yang
faculty_authorid: 46286308
paper_id: 4ce987d4f8ae0f4680808c318980d42a82b9aa89
paper_title: Learning a Fourier Transform for Linear Relative Positional Encodings in Transformers
publication_link: http://arxiv.org/pdf/2302.01925 
year_published: 2023 
abstract_paper:We propose a new class of linear Transformers called FourierLearner-Transformers (FLTs), which incorporate a wide range of relative positional encoding mechanisms (RPEs). These include regular RPE techniques applied for nongeometric data, as well as novel RPEs operating on the sequences of tokens embedded in higher-dimensional Euclidean spaces (e.g. point clouds). FLTs construct the optimal RPE mechanism implicitly by learning its spectral representation. As opposed to other architectures combining efficient low-rank linear attention with RPEs, FLTs remain practical in terms of their memory usage and do not require additional assumptions about the structure of the RPE-mask. FLTs allow also for applying certain structural inductive bias techniques to specify masking strategies, e.g. they provide a way to learn the so-called local RPEs introduced in this paper and providing accuracy gains as compared with several other linear Transformers for language modeling. We also thoroughly tested FLTs on other data modalities and tasks, such as: image classification and 3D molecular modeling. For 3D-data FLTs are, to the best of our knowledge, the first Transformers architectures providing RPE-enhanced linear attention.
isOpenAccess: True
TL\DR: This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents to relevant label descriptions and generates pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions.
================================
faculty_name: Yiming Yang
faculty_authorid: 46286308
paper_id: 846f60ef3b98590c7ad1d84727c66a08cc2258c8
paper_title: Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation
publication_link: https://arxiv.org/pdf/2308.03725 
year_published: 2023 
abstract_paper:Temporal Sentence Grounding in Videos (TSGV) aims to detect the event timestamps described by the natural language query from untrimmed videos. This paper discusses the challenge of achieving efficient computation in TSGV models while maintaining high performance. Most existing approaches exquisitely design complex architectures to improve accuracy with extra layers and loss, suffering from inefficiency and heaviness. Although some works have noticed that, they only make an issue of feature fusion layers, which can hardly enjoy the highspeed merit in the whole clunky network. To tackle this problem, we propose a novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks. Specifically, We first unify different outputs of the heterogeneous models into one single form. Next, a Knowledge Aggregation Unit (KAU) is built to acquire high-quality integrated soft labels from multiple teachers. After that, the KAU module leverages the multi-scale video and global query information to adaptively determine the weights of different teachers. A Shared Encoder strategy is then proposed to solve the problem that the student shallow layers hardly benefit from teachers, in which an isomorphic teacher is collaboratively trained with the student to align their hidden states. Extensive experimental results on three popular TSGV benchmarks demonstrate that our method is both effective and efficient without bells and whistles.
isOpenAccess: True
TL\DR: A novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks is proposed, which is both effective and efficient without bells and whistles.
================================
faculty_name: Yiming Yang
faculty_authorid: 46286308
paper_id: 88884b8806262a4095036041e3567d450dba39f7
paper_title: Active Retrieval Augmented Generation
publication_link: http://arxiv.org/pdf/2305.06983 
year_published: 2023 
abstract_paper:Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. Code and datasets are available at https://github.com/jzbjyb/FLARE.
isOpenAccess: True
TL\DR: A novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks is proposed, which is both effective and efficient without bells and whistles.
================================
faculty_name: Yiming Yang
faculty_authorid: 46286308
paper_id: 938d2951ba3aa26f3752d489c3c044ae67d5e809
paper_title: Retrieval-Enhanced Generative Model for Large-Scale Knowledge Graph Completion
publication_link: https://dl.acm.org/doi/pdf/10.1145/3539618.3592052 
year_published: 2023 
abstract_paper:The task of knowledge graph completion (KGC) is of great importance. To achieve scalability when dealing with large-scale knowledge graphs, recent works formulate KGC as a sequence-to-sequence process, where the incomplete triplet (input) and the missing entity (output) are both verbalized as text sequences. However, inference with these methods relies solely on the model parameters for implicit reasoning and neglects the use of KG itself, which limits the performance since the model lacks the capacity to memorize a vast number of triplets. To tackle this issue, we introduce ReSKGC, a Retrieval-enhanced Seq2seq KGC model, which selects semantically relevant triplets from the KG and uses them as evidence to guide output generation with explicit reasoning. Our method has demonstrated state-of-the-art performance on benchmark datasets Wikidata5M and WikiKG90Mv2, which contain about 5M and 90M entities, respectively.
isOpenAccess: True
TL\DR: A novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks is proposed, which is both effective and efficient without bells and whistles.
================================
faculty_name: Yiming Yang
faculty_authorid: 46286308
paper_id: b4a6c010724f0459c9791018e34a982cf96987cf
paper_title: Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning and Coding with LLMs
publication_link: https://aclanthology.org/2023.emnlp-main.761.pdf 
year_published: 2023 
abstract_paper:A popular approach for improving the correctness of output from large language models (LLMs) is Self-Consistency - poll the LLM multiple times and output the most frequent solution. Existing Self-Consistency techniques always generate a constant number of samples per question, where a better approach will be to non-uniformly distribute the available budget based on the amount of agreement in the samples generated so far. In response, we introduce Adaptive-Consistency, a cost-efficient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion. Our experiments over 17 reasoning and code generation datasets and three LLMs demonstrate that Adaptive-Consistency reduces sample budget by up to 7.9 times with an average accuracy drop of less than 0.1%. Our code and data are available at https://www.sample-step-by-step.info
isOpenAccess: True
TL\DR: A novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks is proposed, which is both effective and efficient without bells and whistles.
================================
faculty_name: Yiming Yang
faculty_authorid: 46286308
paper_id: e01515c6138bc525f7aec30fc85f2adf028d4156
paper_title: Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision
publication_link: http://arxiv.org/pdf/2305.03047 
year_published: 2023 
abstract_paper:Recent AI-assistant agents, such as ChatGPT, predominantly rely on supervised fine-tuning (SFT) with human annotations and reinforcement learning from human feedback (RLHF) to align the output of large language models (LLMs) with human intentions, ensuring they are helpful, ethical, and reliable. However, this dependence can significantly constrain the true potential of AI-assistant agents due to the high cost of obtaining human supervision and the related issues on quality, reliability, diversity, self-consistency, and undesirable biases. To address these challenges, we propose a novel approach called SELF-ALIGN, which combines principle-driven reasoning and the generative power of LLMs for the self-alignment of AI agents with minimal human supervision. Our approach encompasses four stages: first, we use an LLM to generate synthetic prompts, and a topic-guided method to augment the prompt diversity; second, we use a small set of human-written principles for AI models to follow, and guide the LLM through in-context learning from demonstrations (of principles application) to produce helpful, ethical, and reliable responses to user's queries; third, we fine-tune the original LLM with the high-quality self-aligned responses so that the resulting model can generate desirable responses for each query directly without the principle set and the demonstrations anymore; and finally, we offer a refinement step to address the issues of overly-brief or indirect responses. Applying SELF-ALIGN to the LLaMA-65b base language model, we develop an AI assistant named Dromedary. With fewer than 300 lines of human annotations (including<200 seed prompts, 16 generic principles, and 5 exemplars for in-context learning). Dromedary significantly surpasses the performance of several state-of-the-art AI systems, including Text-Davinci-003 and Alpaca, on benchmark datasets with various settings.
isOpenAccess: True
TL\DR: A novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks is proposed, which is both effective and efficient without bells and whistles.
================================
faculty_name: Yiming Yang
faculty_authorid: 46286308
paper_id: fe9fe9f15f24fbbb19b62bcd9a3418511a699b84
paper_title: Policy Representation via Diffusion Probability Model for Reinforcement Learning
publication_link: http://arxiv.org/pdf/2305.13122 
year_published: 2023 
abstract_paper:Popular reinforcement learning (RL) algorithms tend to produce a unimodal policy distribution, which weakens the expressiveness of complicated policy and decays the ability of exploration. The diffusion probability model is powerful to learn complicated multimodal distributions, which has shown promising and potential applications to RL. In this paper, we formally build a theoretical foundation of policy representation via the diffusion probability model and provide practical implementations of diffusion policy for online model-free RL. Concretely, we character diffusion policy as a stochastic process, which is a new approach to representing a policy. Then we present a convergence guarantee for diffusion policy, which provides a theory to understand the multimodality of diffusion policy. Furthermore, we propose the DIPO which is an implementation for model-free online RL with DIffusion POlicy. To the best of our knowledge, DIPO is the first algorithm to solve model-free online RL problems with the diffusion model. Finally, extensive empirical results show the effectiveness and superiority of DIPO on the standard continuous control Mujoco benchmark.
isOpenAccess: True
TL\DR: A novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks is proposed, which is both effective and efficient without bells and whistles.
================================
faculty_name: Yiming Yang
faculty_authorid: 2144133523
paper_id: ab352439202d719acde8b9b005bba357c60401f6
paper_title: A Neural PDE Solver with Temporal Stencil Modeling
publication_link: http://arxiv.org/pdf/2302.08105 
year_published: 2023 
abstract_paper:Numerical simulation of non-linear partial differential equations plays a crucial role in modeling physical science and engineering phenomena, such as weather, climate, and aerodynamics. Recent Machine Learning (ML) models trained on low-resolution spatio-temporal signals have shown new promises in capturing important dynamics in high-resolution signals, under the condition that the models can effectively recover the missing details. However, this study shows that significant information is often lost in the low-resolution down-sampled features. To address such issues, we propose a new approach, namely Temporal Stencil Modeling (TSM), which combines the strengths of advanced time-series sequence modeling (with the HiPPO features) and state-of-the-art neural PDE solvers (with learnable stencil modeling). TSM aims to recover the lost information from the PDE trajectories and can be regarded as a temporal generalization of classic finite volume methods such as WENO. Our experimental results show that TSM achieves the new state-of-the-art simulation accuracy for 2-D incompressible Navier-Stokes turbulent flows: it significantly outperforms the previously reported best results by 19.9% in terms of the highly-correlated duration time and reduces the inference latency into 80%. We also show a strong generalization ability of the proposed method to various out-of-distribution turbulent flow settings. Our code is available at"https://github.com/Edward-Sun/TSM-PDE".
isOpenAccess: True
TL\DR: Temporal Stencil Modeling is proposed, which combines the strengths of advanced time-series sequence modeling and state-of-the-art neural PDE solvers (with learnable stencil modeling), and aims to recover the lost information from the PDE trajectories.
================================
faculty_name: Yiming Yang
faculty_authorid: 2144133674
paper_id: 492289db63324fa7eab53df3bcfdc753ce7d8953
paper_title: Research on Comprehensive Performance Optimization Method of Explosives and Propellants Oriented to the Whole Process
publication_link: https://drpress.org/ojs/index.php/HSET/article/download/6014/5823 
year_published: 2023 
abstract_paper:Explosives and propellants are common basic energy for weapons and equipment to achieve delivery, damage, and control, and are an important manifestation of national defense power. However, due to the wide variety of products and complex performance, the traditional serial design optimization mode can no longer meet the requirements of product diversification and rapid development. In this paper, the design process of explosives is deeply studied, and a method for optimizing the comprehensive performance of explosives and propellants oriented to the whole process is proposed. The method uses a comprehensive performance optimization engine to numerically model different design links in a unified parameter space, connects different links horizontally, and adopts a multi-objective optimization algorithm to comprehensively consider the optimization objectives of different links, realizing the automatic execution of the optimization process according to the design process. In order to verify the effectiveness of the method, this paper optimizes the formula of explosives and propellants based on two different types of explosives, gun propellant and rocket propellant. Experimental results show that this method improves the design efficiency and improves product quality under the premise of ensuring safety and manufacturability.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Yiming Yang
faculty_authorid: 2191604907
paper_id: c3520d7e09c4a184d6dc5d189c7deccc8f21116d
paper_title: Comparative effectiveness of various physical exercise interventions on executive functions and related symptoms in children and adolescents with attention deficit hyperactivity disorder: A systematic review and network meta-analysis
publication_link: https://www.frontiersin.org/articles/10.3389/fpubh.2023.1133727/pdf 
year_published: 2023 
abstract_paper:Background Physical exercise has been recommended as an important nonpharmacological therapeutic strategy for managing attention deficit hyperactivity disorder (ADHD). We conducted a network meta-analysis (NMA) to assess the comparative impact of different physical exercise modalities on enhancing executive functions (EFs) and alleviating symptoms in children and adolescents with ADHD. Methods We searched Web of Science, PubMed, Embase, Cochrane Central Register of Controlled Trials, SPORTDiscus, PsycINFO, CNKI, and clinical trials databases from inception to October 20, 2022. Randomized controlled trials (RCTs) and quasi-experimental studies investigating physical exercise for ADHD-related symptoms of hyperactivity/impulsivity and inattention, and executive functions were included. The frequentist random-effect NMA method was applied to pool the results. Results A total of 59 studies (including 39 RCTs, 5 quasi-RCTs, and 15 self-controlled trials) published between 1983 and 2022 were incorporated into the systematic review, of which 44 studies with 1757 participants were eligible for meta-analysis. All types of physical exercise were effective in improving EFs (SMD = 1.15, 95% CI: 0.83 to 1.46), and open-skill activities which require participants to react in a dynamically changing and externally paced environment induced the most incredible benefits for executive functions (SUCRA = 98.0%, SMD = 1.96, and 95% CI: 1.15 to 2.77). Subgroup analyses for EFs revealed varied findings that open-skill activities were the most promising physical exercise type for improving inhibitory control (SUCRA = 99.1%, SMD = 1.94, and 95% CI: 1.24 to 2.64), and closed-skill activities dominated by aerobic exercises had a slightly higher probability of being the most promising physical exercise intervention for working memory (SUCRA = 75.9%, SMD = 1.21, and 95% CI: −0.22 to 2.65), and multicomponent physical exercise tended to be the most effective in cognitive flexibility (SUCRA = 70.3%, SMD = 1.44, and 95% CI: −0.19 to 3.07). Regarding ADHD-related symptoms, closed-skill activities dominated by aerobic exercises might be more advantageous for hyperactivity/impulsivity (SUCRA = 72.5%, SMD = -1.60, and 95% CI: −3.02 to −0.19) and inattention (SUCRA = 96.3%, SMD = -1.51, and 95% CI: −2.33 to −0.69) improvement. Conclusion Physical exercise can significantly help to alleviate the symptoms of ADHD and improve executive functions in children and adolescents with ADHD. Most of all, to promote adherence to treatment, they should be encouraged to perform the physical exercises that they enjoy most.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Yiming Yang
faculty_authorid: 2191604907
paper_id: f9031873a318e8a3f911f916d8af5b6744641c6d
paper_title: The association between physical activity and sleep in adult ADHD patients with stimulant medication use
publication_link: https://www.frontiersin.org/articles/10.3389/fpsyt.2023.1236636/pdf?isPublishedV2=False 
year_published: 2023 
abstract_paper:Background Adults with attention-deficit/hyperactivity disorder (ADHD) may experience sleep problems doubly suffering from the disease and side effects of stimulant medications. Physical activity (PA) is known to produce numerous beneficial effects in adults. However, it was not well-characterized whether PA would still be effective in this situation. The main objective of the current study was to examine the relationship between PA and sleep among adult ADHD patients who were using stimulant medications and quantify the form of this association. Methods Adult ADHD participants with stimulant medications use condition from the National Health and Nutrition Examination Survey (NHANES) database between January 1, 2013, and March 2020 (prepandemic) were included in the cross-sectional analysis. Weighted logistic regression was performed to assess the relationship between PA level and sleep. A restricted cubic spline model was used to relax the linear relationship assumptions and investigate the associations between the risk of trouble sleeping and time spent engaging in moderate-to-vigorous PA per week. Results A total of 162 eligible adult ADHD participants who reported using stimulant medicines were included. Participants who adhered to the general recommendation of guidelines in the US of 150 min per week of moderate-to-vigorous PA had a significant lower risk of complaining of trouble sleeping (OR: 0.26, 95% CI: 0.10–0.67, p = 0.006), and this association was seen in men (OR: 0.23, 95% CI: 0.09–0.56, p = 0.002), but was not seen in women (OR: 0.71, 95% CI: 0.27–1.88, p = 0.500). Restricted cubic spline analysis showed that the incidence of trouble sleeping gradually decreased after at least 105 min of moderate-intensity PA per week in participants (OR: 1.02, 95% CI: 0.92–1.14). A significant difference appeared after 341 min (OR: 0.87, 95% CI: 0.76–0.99), and the curve leveled after 1,250 min (OR: 0.60, 95% CI: 0.46–0.79). Conclusion Our findings observed associations between PA and sleep condition in the adult ADHD patients with stimulant medication use population. Moderate-to-vigorous PA may be beneficial to sleep in adults with ADHD who were using stimulants and thus should be recommended as part of a healthy lifestyle. Gender difference should be considered as an important factor for further studies to examine these associations and explore potential mechanisms.
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
faculty_name: Yiming Yang
faculty_authorid: 2273909270
paper_id: bfa7f7bec1c4553c6c382ec2dbf4f889d7fa6e4f
paper_title: CompleQA: Benchmarking the Impacts of Knowledge Graph Completion Methods on Question Answering
publication_link: https://aclanthology.org/2023.findings-emnlp.849.pdf 
year_published: 2023 
abstract_paper:None
isOpenAccess: True
TL\DR: tldr not available for this paper
================================
