JOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. 00, NO. 0, MONTH 2020
1
Defending Against Malicious Behaviors in
Federated Learning with Blockchain
Nanqing Dong, Zhipeng Wang, Jiahao Sun, Michael Kampffmeyer, Yizhe Wen, Shuoying Zhang,
William Knottenbelt, and Eric Xing, Fellow, IEEE
Abstract—In the era of deep learning, federated learning (FL)
presents a promising approach that allows multi-institutional
data owners, or clients, to collaboratively train machine learn-
ing models without compromising data privacy. However, most
existing FL approaches rely on a centralized server for global
model aggregation, leading to a single point of failure. This
makes the system vulnerable to malicious attacks when dealing
with dishonest clients. In this work, we address this problem by
proposing a secure and reliable FL system based on blockchain
and distributed ledger technology. Our system incorporates a
peer-to-peer voting mechanism and a reward-and-slash mecha-
nism, which are powered by on-chain smart contracts, to detect
and deter malicious behaviors. Both theoretical and empirical
analyses are presented to demonstrate the effectiveness of the
proposed approach, showing that our framework is robust against
malicious client-side behaviors.
Impact Statement—Federated learning has been a promising
solution to utilize multi-site data while preserving users’ privacy.
Despite the success of integrating blockchain with federated
learning to decentralize global model aggregation, the protection
of this integration from clients with malicious intent in federated
scenarios remains unclear. This paper presents the first formu-
lation of this problem and the proposed stake-based aggregation
mechanism shows robustness in detecting malicious behaviors.
The results in this work not only pose a new research direction
in federated learning, but can also benefit a wide variety of
applications such as finance and healthcare.
Index Terms—Blockchain, Deep Learning, Federated Learn-
ing, Trustworthy Machine Learning
I. INTRODUCTION
N
OWADAYS, machine learning (ML), or more specifi-
cally, deep learning, has transformed a broad spectrum
of industries, ranging from finance to healthcare. In current
ML paradigms, training data are first collected and curated,
The first two authors contributed equally to this work. This work was
supported in part by FLock.io under the FLock Research Grant.
N. Dong is with the Department of Computer Science, University of Oxford,
Oxford, OX1 3QD, UK. (email: nanqing.dong@cs.ox.ac.uk)
Z.
Wang
and
W.
Knottenbelt
are
with
the
Department
of
Com-
puting,
Imperial
College
London,
London,
SW7
2AZ,
UK.
(emails:
zhipeng.wang20@imperial.ac.uk, w.knottenbelt@imperial.ac.uk)
J. Sun is with the Data Science Institute, Imperial College London,
SW7 2AZ, UK; and also with FLock.io, London, WC2H 9JQ, UK. (email:
jiahao.sun@imperial.ac.uk)
M. Kampffmeyer is with the Department of Physics and Technology
at UiT The Arctic University of Norway, 9019 Tromsø, Norway. (email:
michael.c.kampffmeyer@uit.no)
Y. Wen and S. Zhang are with FLock.io, London, WC2H 9JQ, UK. (emails:
yizhe@flock.io, shuoying@flock.io)
E. Xing is with the Machine Learning Department, School of Computer
Science, Carnegie Mellon University, Pittsburgh, PA 15213, USA; and also
with Mohamed bin Zayed University of Artificial Intelligence, Masdar City,
Abu Dhabi, UAE (email: epxing@cs.cmu.edu)
 Reward 
or Slash
Upload
blocki-1
blocki+2
blocki+1
blocki
Stake
Stake
Download
Assets Redistribution
Vote
Proposers
Voters
Local 
Model 
Updates
Global
Model 
Aggregation
Global 
Model 
Evaluation
Global 
Model 
Finalizaion
Blockchain
Assets
Token
Fig. 1.
A stake-based aggregation mechanism for FL with blockchain. In
each round, the proposers are randomly selected from the participating clients
to perform local training and upload local updates to the blockchain. Then,
voters download the aggregated local updates from the blockchain, perform
local validation, and vote for acceptance or rejection. If the majority of voters
vote for accepting the global aggregation, the global model will be updated,
and the proposers and the voters who vote for acceptance will be rewarded.
Conversely, if the majority of voters vote for rejection, the global model will
not be updated, and the proposers and the voters who vote for acceptance will
be slashed.
and then ML models are optimized by minimizing certain loss
criteria on the training data. A common underlying assumption
in the learning environment is that the training data can be
instantly accessed or easily distributed across computing nodes
without communication constraints, i.e. data are centralized.
However, in a system with multiple clients (i.e. data hold-
ers), to ensure data centralization, clients have to upload local
data to a centralized device (e.g. a central server) to conduct
the centralized training described above. Despite the success of
centralized training in various deep learning applications [1],
[2], [3], there is growing concern about data privacy and
security, especially when the local data held by the clients
are private or contain sensitive information. Especially, to
ensure data governance, strict data regulations have been
established [4], [5].
To address the aforementioned concern, federated learn-
ing (FL) has been proposed [6]. In a typical FL system,
a central server [7] is responsible for aggregating and syn-
chronizing model weights, while a set of clients manipulate
multi-site data. This facilitates data governance, as clients only
exchange model weights or gradients with a central server
arXiv:2307.00543v1  [cs.LG]  2 Jul 2023
2
JOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. 00, NO. 0, MONTH 2020
instead of uploading local data to the central server, and has
led to FL becoming a standardized solution to utilize multi-site
data while preserving privacy.
Though FL perfectly implements data decentralization, a
trustworthy central server is required in the system. In such
a system design, the central server in fact has privileges over
clients, as the central server determines the global aggregation
and synchronization. If the central server is compromised or
manipulated by a malicious party, the clients are vulnerable if
the central server intentionally distributes problematic model
updates. This can potentially increase the cost of system
management and maintenance. Towards avoiding this single
point of failure, many efforts have been made to decentralize
the central server, and one particularly promising solution is
to use a blockchain as decentralized storage [8].
Originally proposed for cryptocurrencies, a blockchain is a
distributed ledger that can record the state transition informa-
tion among multiple parties [9], [10], without relying on a cen-
tralized server. Blockchain technology has gained widespread
attention for its potential to revolutionize a variety of indus-
tries, such as finance [9], healthcare [11], and supply chain
management [12]. By leveraging the decentralized nature of
the blockchain, FL can benefit from increased security, privacy,
and efficiency, as well as reduced reliance on centralized
servers [13]. Concretely, in FL with blockchain, each client
participating in the learning process uploads their local model
updates to the blockchain, where they are stored in blocks,
the metadata of a blockchain system. These blocks are then
used to aggregate the local model updates into a global model,
which can be downloaded by the clients. The use of blockchain
smart contracts [9], which are computer programs triggered by
blockchain events, ensures that the global aggregation process
is performed automatically and transparently, without the need
for human intervention or centralized control.
Though integrating blockchain with existing FL systems can
partially solve the threat to the central server, FL systems are
still vulnerable to client-side malicious attacks [14]. In this
work, we define malicious behaviors as actions that inten-
tionally decrease the learning performance (e.g. accuracy and
convergence) of the global model. The attackers can sabotage
the FL systems via attacks such as data poisoning [15] or
model poisoning [14]. This work focuses on defending against
client-side malicious attacks.
We propose a generic framework that can integrate an FL
system with a blockchain system and can defend against
malicious attacks. The proposed defense mechanism is mo-
tivated by proof-of-stake (PoS) [16], a consensus mechanism
in blockchain, and The Resistance [17], a role-playing board
game. PoS has an incentive mechanism that encourages honest
behaviors by rewarding it and punishes dishonest behaviors
via slashing. The Resistance, on the other hand, has two
mismatched competing parties, where the party with a larger
size is denoted as the resistance force and the other party
is denoted as the spies. In The Resistance, there is a voting
mechanism where, in each round, each player conducts inde-
pendent reasoning and votes for a player, and the player with
the highest votes will be deemed as a “spy” and kicked out of
the game. The goal of the resistance force is to vote out all the
spies while the spies aim to impersonate the resistance force
and survive until the end. Based on these two concepts, this
work proposes a novel majority-voting mechanism for global
aggregation where each participating client independently val-
idates the quality of aggregated local updates and votes for
acceptance of the global update. The aggregation mechanism is
stake-based where participating clients stake assets1 or tokens
(a quantitative measurement of the asset, which can be used
to indicate the trustworthiness of the client in our system) for
their own actions. There are two types of actions, proposing
(uploading local updates) and voting. If the majority vote is to
accept the global aggregation, a proposer will be refunded with
its staked tokens and a voter who votes for acceptance will not
only be refunded but also be rewarded with the staked tokens
from the voters who vote for rejection, and vice versa. The
overall procedure of the stake-based aggregation mechanism
is illustrated in Fig. 1.
We evaluate the proposed framework on a practical financial
problem, namely loan default prediction. We simulate the FL
and blockchain environment for the Lending Club Kaggle
challenge dataset to conduct experiments in a controllable
setting and to provide insights into the problem of interest.
We empirically show that an FL system can maintain robust
performance under malicious attacks by introducing the pro-
posed stake-based aggregation mechanism.
The contributions of this work are summarized as follows:
1) We formulate the problem of decentralized federated
learning with blockchain in the presence of malicious
attacks.
2) We propose a stake-based aggregation mechanism for
federated learning systems that can defend against ma-
licious attacks.
3) We evaluate the robustness of the proposed framework
in a simulated environment and provide initial empirical
insights into the problem.
II. RELATED WORK
A. Federated Learning
The concept of FL comes from the necessity of on-device
training, where the training data have to remain on the de-
vice [6]. The clients of FL are distributed at different physical
locations that are connected to the internet, which exposes a
few security risks compared with distributed learning. First,
as the local dataset belongs to the client, FL has to take
the users’ privacy into consideration. This can be addressed
by integrating privacy-preserving techniques into FL, such as
differential privacy [18]. Second, FL can be manipulated via
internet access, e.g. the central server can be compromised
by a third party. Third, a new client could participate in the
federated training at any time if it meets the required criteria.
This means that clients with malicious intentions can also join
the federated systems while meeting the initial criteria. This
work focuses on the third risk as the second risk is mitigated
by replacing the central server with a blockchain. Traditional
FL methods can only detect and defend the malicious clients
1In practice, the staked assets can be linked with cryptocurrency or real
currency to increase the financial cost of malicious attacks.
FIRST A. AUTHOR et al.: BARE DEMO OF IEEETAI.CLS FOR IEEE JOURNALS OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE
3
Sender
Recipient
Transaction
Blockchain
include 
on-chain
Miner
Miner
Miner
Miner
Miner
P2P 
Network
Legend
Confirmed 
Transaction
Unconfirmed 
Transaction
Fig. 2.
Blockchain workflow overview. The sender broadcasts the issued
transaction to the P2P network, which will be confirmed by the miners. The
confirmed transaction will be stored on a public blockchain and can be read
by the recipient. Blockchain miners typically adopt a consensus mechanism
to achieve an agreement on the state of the blockchain.
via assigning small weights to malicious clients during global
aggregation based on the divergence of learned parameters [19]
or using unsupervised learning methods (e.g. anomaly detec-
tion [20] and clustering [21]) to get rid of malicious clients.
However, none of these methods tackles the second challenge
and these methods do not consider the third challenge. The
proposed framework utilizes the blockchain to ensure the
security of global aggregation and defends the client-side
malicious behaviors with a novel majority-voting mechanism.
B. Blockchain
Blockchains refer to distributed ledgers that operate on a
global peer-to-peer (P2P) network, as exemplified by popular
cryptocurrencies such as Bitcoin [22] and Ethereum [9]. One
of the defining characteristics of blockchain technology is the
ability for users to freely join or leave the network, without
a central authority in place to ensure common agreement
on the distributed ledgers. Instead, users rely on consensus
protocols [16], [23], such as proof-of-work (PoW) or PoS, to
achieve agreement in a distributed setting.
As shown in Fig. 2, in a blockchain system, a transaction
typically involves a sender who wishes to transfer a digital
asset, such as a cryptocurrency, to a recipient. The sender
initiates the transaction by creating a digital signature that
includes the transaction details and the sender’s private key,
which is used to verify the sender’s identity and authorize
the transfer. The transaction is then broadcasted over a P2P
network to miners, who are participants in the network re-
sponsible for verifying and adding new blocks of transactions
to the blockchain. Miners validate and confirm the transaction
using consensus protocols, to ensure that the transaction is
legitimate and not a duplicate or fraudulent transaction. Once
confirmed, the transaction is added to a block, which is then
cryptographically linked to the previous block using hash
functions [24], forming a chain of blocks (i.e., blockchain).
The block is then propagated to all the participants in the
network, creating a decentralized, immutable record of the
transaction. Finally, the recipient can access the digital asset
by using their private key to authenticate their identity and
claim ownership of the asset. The use of cryptography and
consensus protocols ensures the security, transparency, and
decentralization of the transaction process, making blockchain
technology a promising solution for a variety of applications
beyond cryptocurrency, e.g., insurance [25], healthcare [11],
supply chain management [12], energy [26], and Internet of
Things (IoT) [27].
Another key feature of blockchain technology is the use of
smart contracts [9], which are quasi-Turing-complete programs
that can be executed within a virtual machine. When a transac-
tion is initiated, a smart contract is typically used to encode the
terms and conditions of the transaction, such as the amount,
currency, and time of transfer. The smart contract is then
stored on the blockchain network and executed automatically
when the predefined conditions are met. The execution of the
smart contract verifies the transaction, ensuring that it meets
the agreed-upon terms and conditions, and then automatically
transfers the digital asset or currency to the recipient. Smart
contracts can be leveraged to build a wide range of decen-
tralized applications (DApps), such as decentralized finance
(DeFi) services [28].
C. Federated Learning with Blockchain
Traditional FL faces challenges [29], such as privacy and
security concerns, unreliable communication, and difficulty in
reaching a consensus among the parties. Blockchain, on the
other hand, provides a decentralized, secure, and transparent
platform for data storage and sharing. This makes the use of
blockchain for FL a promising direction to potentially address
privacy and security concerns by allowing parties to keep their
data private while still contributing to the training process.
Additionally, blockchain can provide a secure communication
channel for FL participants and ensure the integrity of the FL
process.
Current blockchain-based FL designs [30], [8], [31], [32]
have been broadly used in diverse fields, including mobile
edge computing [33], IoT [34] and distributed machine learn-
ing [35]. Despite the potential benefits of combining FL with
blockchain, several challenges remain. For instance, FL sys-
tems are still vulnerable to client-side malicious attacks [14]
and lack incentive-compatible mechanisms to motivate FL
participants to behave honestly during the training process.
Multiple reputation-based incentive mechanisms [36], [37]
have recently been proposed to encourage participants and
enhance model accuracy in blockchain-based FL. However,
it remains unclear how to effectively utilize the blockchain
infrastructure and leverage its inherent incentive mechanism
(i.e., cryptocurrencies) to incentivize trustworthy FL behaviors
and penalize malicious clients.
III. PROBLEM FORMULATION
This section introduces the problem of interest, the defini-
tion of the malicious behaviors considered, and the underlying
assumptions in this work.
4
JOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. 00, NO. 0, MONTH 2020
A. Setup
There are K
> 1 clients in a federated system. Let
K = {1, 2, · · · , K} denote the set of all clients. Let Dk denote
the local data stored in client k, we have Dk∩Dl = ∅ for k ̸= l
and k, l ∈ K. Each local dataset Dk can be randomly split into
a training set and a test set, which are both private to client
k. In addition to K clients, a blockchain plays the role of
a parameter server [7] for global aggregation. Let fθ be the
model of interest. In the parameter server, the parameter set
θ0
0 is randomly initialized at round 0 and K clients download
θ0
0 from the blockchain as K local copies {θ0
k}K
k=1 for full
synchronization. During the federated optimization phase, a
set of Kt
p clients is randomly selected for round t. For each
k ∈ Kt
p, the client k updates θt−1
k
by training on the training
set of Dk independently for a number of local epochs. Then,
the blockchain aggregates updated {θt
k}k∈K collected from
all the K clients to update θt
0. The K clients then synchro-
nize with the parameter server, i.e. θt
k ← θt
0. To facilitate
data governance, as required in among others the medical
domain [5], [4], we assume that the patient’s data (either
raw data or encoded data) in a client can not be uploaded to
the blockchain or other clients, i.e. only parameters {θk}K
k=0
and metadata (e.g. the statistics of data) [38], [39] can be
exchanged between the blockchain and the clients. It is worth
mentioning that this work focuses on the interactions between
FL and blockchain, where blockchain computing (or mining,
in a more fashionable sense) and the application of additional
privacy-preserving techniques [18] are considered orthogonal
research directions and thus beyond the scope of this work.
B. Malicious Behaviors
The definition of malicious behavior in this work is an
action that intentionally decreases the global model perfor-
mance. There are two types of actions for each client that
interact with the federated system, i.e. a client can propose
(i.e. be a proposer) and vote (i.e. be a voter). Proposing is
to upload local model or gradient updates to the parameter
server, while voting is a peer-review process to validate the
“virtually” aggregated model updates. The technical details
of the two actions are described in Sec. IV. There are thus
two corresponding malicious behaviors. The first malicious
behavior is to propose harmful local model updates and the
second one is to vote dishonestly. More specifically, in the
second case, a client votes for approval when it is aware
that the proposed model updates are poisoned and votes for
rejection when there is no evidence that indicates that the
proposed model updates are poisoned. It is worth mentioning
that the clients themselves might not intentionally attack the
FL system as they can be compromised by attackers. For
simplicity, we define the clients that have malicious behaviors
as malicious clients in this work, denoted as Km. We use
η to denote the ratio of malicious clients among all clients,
i.e. η = |Km|
K , where | · | is the cardinality of a set.
C. Assumptions
There are six important assumptions in this work.
• A1: The goal of malicious behaviors is to decrease
the global model performance. This is also reflected in
Sec. III-B. Under these assumptions, behaviors that are
harmful to the system but do not influence the global
model performance are beyond the scope of discussion
in this work. An example is eavesdropping, i.e. cloning
the model specifications.
• A2: All clients are rational. This means that both honest
and malicious clients expect to maximize their gain or
minimize their loss while achieving their goals.
• A3: Following previous studies on blockchain [13], we
assume that η is strictly smaller than 50%. This means
there are always more honest clients than malicious
clients in a federated system.
• A4: There is no collusion among malicious clients. That
is to say, each malicious client acts independently. In the
application scenarios of this work (e.g. Sec. V), there is
a minimal bar for a client to participate in the system,
e.g. basic qualifications or industry standards for clinical
or financial institutes. Meanwhile, it is difficult to com-
promise multiple clients with independent cybersecurity
systems simultaneously. Thus, we deem that it is almost
impossible to launch large-scale multi-agent attacks in
the application scenarios of interest. As an exploratory
study, this work considers the single-agent scenario. (See
Sec. IV-E for the discussion on a multi-agent scenario.)
• A5: There is no capacity constraint on the hardware,
including computing, communication, and storage, allow-
ing us to solely focus on the algorithmic side of the
problem.
• A6: The underlying blockchain of the FL system of
interest is running securely with a consensus protocol
that ensures the validity and integrity of transactions and
blocks. While the security of the blockchain is crucial
for the overall security of the FL system, addressing the
malicious miners falls outside the scope of this study.
IV. METHOD
A. Federated Aggregation
In this work, we illustrate the proposed framework in the
context of the seminal FL method, FedAVG [6]. At the
end of round t, the local models {θt
k}K
k=1 are uploaded and
aggregated as a weighted average:
θt
0 =
K
X
k=1
akθt−1
k
,
(1)
where ak = nk
N . The metadata nk = |Dk| is the number of
local training examples stored in client k and N = PK
k=1 nk
is the total number of training examples in the K clients.
B. Local Validation
In contrast to standard FL algorithms, the aggregated global
model is not recorded in a block directly. Instead, ˜θt
0, a copy
of θt
0 is downloaded by a randomly selected set of clients,
denoted as voters, Kt
v. A voter k runs a local inference with
˜θt
0 on its local test set and outputs a local validation score.
FIRST A. AUTHOR et al.: BARE DEMO OF IEEETAI.CLS FOR IEEE JOURNALS OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE
5
2
Proposers
Voters
Reward
Finalization
5
Finalization 
and Reward
4
Voting
Scores
Miners
Voters
Evaluate
Read
Aggregate 
voting  scores
Evaluate
Evaluate
Evaluate
Global Voting 
and Approval
Proposers
Voters
2
Participants 
Selection
Proposers
Train
Train
Train
Train
local 
model 
updates
Miners
global model 
update 
candidates
3 Local Training
4
Voting
Scores
Miners
Voters
Evaluate
Read
Aggregate 
voting  scores
Evaluate
Evaluate
Evaluate
Global Voting 
and Refusal
Proposers
Voters
2
Participants 
Selection
Proposers
Train
Train
Train
Train
local 
model 
updates
Miners
global model 
update 
candidates
3 Local Training
Proposers
Voters
Slash
Revert
5
Revert and 
Slash
Proposers
Stake
Assets
Voters
Miners
1 Setup
Multiple Rounds
Proposers
Voters
6 Malicious Clients 
Elimination
Remove
Fig. 3.
A round-based training process. In the initial state (indexed as ①), both honest (black) and malicious (red) clients exist in an FL system. In the
final state (indexed as ⑥), all malicious clients are expected to be removed from the system. To reach the final state from the initial state, multiple rounds
of training are required. Here are two possible scenarios, the proposed aggregation is either approved (the upper branch) or denied (the lower branch) by
the voters. In each round (within the dotted orange line), a subset of clients are randomly selected as proposers, and another subset of clients are randomly
selected as voters. The proposers and voters interact with the blockchain following the order of orange arrows (from ② to ⑤).
The local validation score st
k is a scalar, which can be linked
with common metrics of ML tasks2. If st
k is not lower than a
threshold, the voter votes for accepting this aggregated model;
otherwise, the voter votes against it. The threshold can be
based on a validation score st−1
k
acquired in the previous
round. In the training of ML tasks, the scores can be volatile
due to the characteristics of the tasks. Thus, a hyperparameter
ϵ ∈ (0, 1) is introduced to control the tolerance of performance
decrease in a single round. Mathematically, Voter k has the
following score.
vt
k =
(
1,
st
k ≥ (1 − ϵ)st−1
k
−1,
st
k < (1 − ϵ)st−1
k
(2)
It is worth mentioning that it is almost impossible for the
attackers to manipulate scores by fooling all the randomly
selected voters (e.g. via adversarial attacks [40]). According
to A5, the majority of voters are honest. It is thus difficult to
attack (either via data poisoning or model poisoning) as the
validation set of each client is private.
C. Majority Voting
The majority voting process for whether to apply the global
aggregation operation at round t can be described below. Here,
we use a binary variable at to denote the decision.
at =
(
1,
P
k∈Kv vk > 0
−1,
P
k∈Kv vk ≤ 0
(3)
2For example, common evaluation metrics include accuracy for classifica-
tion, mean Intersection over Union (mIOU) for semantic segmentation, and
mean average precision (mAP) for object detection.
If at = 1, the global aggregation will be finalized and
recorded in the block; otherwise, the global aggregation will
be discarded.
D. Asset Redistribution
As there are two independent actions, there are two par-
allel reward-and-slash designs for proposing and voting. For
both actions, the randomly selected proposers and voters are
required to stake a fixed sum of tokens before they act. If
some of these actors fail to stake (they do not have enough
tokens left), they lose their access to the blockchain and are
removed from the FL system permanently. Proposers will be
rewarded with tokens accumulated in an independent pool (if
there are any tokens left in the pool) if the global aggregation
is approved and lose their stakes if the global aggregation
is rejected. The reward-and-slash design for the proposers is
illustrated in Algorithm 1. For the voters, the majority party
will not only take back their stakes but also be rewarded with
the staked tokens lost by the minority party. The reward-and-
slash design for the voters is illustrated in Algorithm 2. In
the following section, Sec. IV-E, we demonstrate that under
the proposed design and assumptions in Sec. III-C, malicious
voters have no incentive to make dishonest votes.
E. Theoretical Analysis on Malicious Votes
In this section, we theoretically show that malicious voters
in the proposed framework have no incentive to make dishon-
est votes.
Theorem 1 (Honest Voting Hypothesis): When all clients
are rational and there is no collusion among malicious clients,
a malicious client should not make a malicious vote.
6
JOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. 00, NO. 0, MONTH 2020
Algorithm 1 Reward-and-slash design for a set of randomly
selected proposers.
at: Majority voting decision at round t
K: Set of participating clients at round t
Kt
p: Set of proposers at round t
Mk: Asset of client k
γp: Staked tokens for proposing
poolp: Pool for proposers
1: if at == −1 then
2:
for k ∈ Kt
p do
3:
if Mk ≥ γp then
4:
Mk ← Mk − γp
5:
poolp ← poolp + γp
6:
else
7:
poolp ← poolp + Mk
8:
Mk ← 0
9:
Kt ← Kt \ {k}
10: else
11:
if poolp > 0 then
12:
for k ∈ Kt
p do
13:
Mk ← Mk +
poolp
|Ktp|
14:
poolp ← 0
Algorithm 2 Reward-and-slash design for a set of randomly
selected voters.
at: Majority voting decision at round t
K: Set of participating clients at round t
Kt
v: Set of voters at round t
Kt
m: Set of voters at round t with vt
k == at
Mk: Asset of client k
γv: Staked tokens for voting
poolv: Pool for voters
1: for k ∈ Kt
v \ Kt
m do
2:
if Mk ≥ γv then
3:
Mk ← Mk − γv
4:
poolv ← poolv + γp
5:
else
6:
poolv ← poolv + Mk
7:
Mk ← 0
8:
Kt ← Kt \ {k}
9: for k ∈ Kt
m do
10:
Mk ← Mk + poolv
|Kt
m|
11: poolv ← 0
Proof: Let Kv denote a randomly selected set of voters
and nv = |Kv|. For client k ∈ Kv, let γv > 0 denote the staked
tokens for voting, i.e. client k must stake γv to participate in
the voting, otherwise, it will be removed from the system.
Under A4, each client makes an independent decision on
voting. Let r be the ratio of malicious clients in Kv, there are
r · nv malicious clients in Kv and (1 − r) · nv honest clients.
If r · nv < (1 − r) · nv, i.e. r < 0.5, each malicious client will
lose γv; if r · nv > (1 − r) · nv, i.e. r > 0.5, each malicious
client will gain (1−r)·nv·γv
r·nv
= 1−r
r γv. The expected return R
of a malicious client will be
R =
Z 0.5
0
−γvdr +
Z 1
0.5
1 − r
r
γvdr
= −0.5γv + ((ln(1) − 1) − (ln(0.5) − 0.5))γv
= −(ln(0.5) + 1)γv < 0
(4)
Under A2, each client is rational. As R < 0, in the long
run, a malicious client will lose all tokens and be removed
from the system. So, a given client has no reason to make a
dishonest vote resulting in honest votes by all clients.
Additionally, there is a game among malicious clients. As
Eq. (4) is known by all clients in advance. A malicious
client can easily make an honest vote to gain tokens from
other malicious clients who make dishonest votes. However,
according to Nash Equilibrium [41], we are certain that, in the
long run, no malicious clients will make dishonest votes.
Theorem
1
will
further
be
empirically
validated
in
Sec. V-B1.
In practice, A4 can be relaxed, where multiple malicious
clients work together to attach the FL system. If A2 holds, we
are certain that the malicious voters will reach a consensus
internally before they act to win the majority vote. Intuitively,
all malicious voters can be considered as a group together.
In this case, this ”group” will behave exactly as the single
malicious client in Theorem 1 based on the same reasoning.
The proof is omitted.
F. Training
Each round consists of the following steps: proposer selec-
tion, local training, global aggregation, local validation, major-
ity voting, token redistribution, and block creation (recording
state3 information). The above steps are repeated in multi-
ple rounds until certain stopping criteria are fulfilled. The
complete training process is depicted in Fig. 3. The stopping
criteria could be a fixed amount of training epochs, which is
commonly adopted in ML.
V. EXPERIMENTS
A. Experimental Setup
We evaluate the proposed framework in a simulated envi-
ronment.
1) Data and Task: We consider a standard classification
task, namely loan default prediction. We use the Kaggle
Lending Club dataset4
to simulate a realistic financial
application scenario. We pre-process the raw dataset by
dropping all entries with missing values. For the labels, we
only keep “Fully Paid” and “Charged Off” to simplify the
task as a binary classification task. We randomly select 80%
of the data as the training set and use the rest of the data as
the test set. The training set is split into K subsets of equal
size and distributed across K clients. Within each client, 20%
of the local data are randomly selected as the validation set.
3For example, the state can record the global model and tokens of each
client.
4https://www.kaggle.com/datasets/wordsforthewise/lending-club
FIRST A. AUTHOR et al.: BARE DEMO OF IEEETAI.CLS FOR IEEE JOURNALS OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE
7
0
10
20
30
40
50
Epoch
0
20
40
60
80
Average Tokens
v = 2
v = 4
v = 8
v = 16
v = 32
(a) η = 0.1.
0
10
20
30
40
50
Epoch
0
20
40
60
80
Average Tokens
v = 2
v = 4
v = 8
v = 16
v = 32
(b) η = 0.2.
0
10
20
30
40
50
Epoch
0
20
40
60
80
Average Tokens
v = 2
v = 4
v = 8
v = 16
v = 32
(c) η = 0.3.
0
10
20
30
40
50
Epoch
0
20
40
60
80
Average Tokens
v = 2
v = 4
v = 8
v = 16
v = 32
(d) η = 0.4.
Fig. 4.
Token distribution results for malicious voters when all proposers are honest. The malicious voters’ tokens decrease quickly as the number of epochs
increases and a large γp leads to a high decreasing rate. This empirically validates our proof of Theorem 1. The solid line denotes the mean over 5 runs with
different random seeds and the shaded region denotes 1 standard deviation around the mean.
0
50
100
150
200
Epoch
0.5
0.6
0.7
0.8
0.9
1.0
AUROC
FedAVG w/o Mal
FedAVG w/ Mal
FedAVG w/ Block
(a) η = 0.1.
0
50
100
150
200
Epoch
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
AUROC
FedAVG w/o Mal
FedAVG w/ Mal
FedAVG w/ Block
(b) η = 0.2.
0
50
100
150
200
Epoch
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
AUROC
FedAVG w/o Mal
FedAVG w/ Mal
FedAVG w/ Block
(c) η = 0.3.
0
50
100
150
200
Epoch
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
AUROC
FedAVG w/o Mal
FedAVG w/ Mal
FedAVG w/ Block
(d) η = 0.4.
Fig. 5.
Federated training under different values of the ratio of malicious clients (η). The solid lines are the mean AUROCs and the shaded regions are
1 standard deviation around the means. FedAVG w/ Block significantly outperforms FedAVG w/ mal, while being comparable with FedAVG w/o mal, the
performance upper bound under this setup.
0
50
100
150
200
Epoch
0.7
0.8
0.9
1.0
Global Accuracy
p = 32
p = 16
p = 8
p = 4
p = 2
(a) η = 0.1.
0
50
100
150
200
Epoch
0.7
0.8
0.9
1.0
Global Accuracy
p = 32
p = 16
p = 8
p = 4
p = 2
(b) η = 0.2.
0
50
100
150
200
Epoch
0.7
0.8
0.9
1.0
Global Accuracy
p = 32
p = 16
p = 8
p = 4
p = 2
(c) η = 0.3.
0
50
100
150
200
Epoch
0.7
0.8
0.9
1.0
Global Accuracy
p = 32
p = 16
p = 8
p = 4
p = 2
(d) η = 0.4.
Fig. 6.
Global accuracy results when choosing γp = 2, 4, 8, 16, and 32. The global accuracy is not sensitive to the value of γp but the convergence tasks
more epochs for larger η.
2) Implementation: There are K = 50 clients in the system
and each client is initialized with 64 tokens. We use a 3-
layer multi-layer perceptron (MLP) as the network backbone.
Apart from the last layer, each layer of the MLP has 128
hidden nodes. We use a standard Adam [42] optimizer with
fixed learning rate 10−3 and batch size 128. No data aug-
mentation is applied. We use the binary accuracy as both the
local validation score and evaluation metric. We consider a
simple data poisoning attack [14], where malicious clients are
trained to confuse the model. All baselines are implemented
in PyTorch 1.12.1 [43] on one NVIDIA Tesla T4 GPU. We
leverage Ethereum smart contracts to deploy our reward-and-
slash design in a private blockchain and simulate the training
process using the Python library Web3.py5. We set ϵ = 0.05
5https://web3py.readthedocs.io/en/v5/
based on empirical experience.6
3) Baselines: We consider 4 baselines. The first one is
an Oracle approach, a centralized baseline without malicious
attacks. The Oracle should provide the upper-bound perfor-
mance of the experiment. The second one is FedAVG without
malicious attacks (denoted as FedAVG w/o mal), which is
equivalent to FedAVG under η = 0 and should provide the
upper-bound performance for a decentralized environment.
The third one is FedAVG under malicious attacks (denoted
as FedAVG w/ mal), where η of clients are malicious. The
fourth one is the proposed method, FedAVG with blockchain
under malicious attacks (denoted as FedAVG w/ block). For
FL baselines, 10% of clients are randomly selected to perform
local training at each epoch. For FedAVG w/ block, we simply
use the remaining 90% of the clients as voters.
6We notice that too small ϵ can cause large oscillation, which slows the
convergence, and too large ϵ can facilitate the convergence at the expense of
decreased detection performance, i.e. the system fails to remove the majority
of malicious clients.
8
JOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. 00, NO. 0, MONTH 2020
TABLE I
PERFORMANCE COMPARISON UNDER DIFFERENT VALUES OF THE RATIO OF MALICIOUS CLIENTS (η). THE REPORTED NUMBERS OF THE PERFORMANCE
ARE MEAN AND STANDARD DEVIATION UNDER 5 RANDOM SEEDS.
Model
η = 0.1
η = 0.2
η = 0.3
η = 0.4
FedAVG w/ mal
0.963 ± 0.017
0.946 ± 0.034
0.801 ± 0.222
0.709 ± 0.266
FedAVG w/ block (Ours)
0.965 ± 0.008
0.969 ± 0.003
0.952 ± 0.020
0.955 ± 0.021
FedAVG w/o mal
0.975 ± 0.004
0.975 ± 0.004
0.975 ± 0.004
0.975 ± 0.004
Oracle
0.971 ± 0.007
0.971 ± 0.007
0.971 ± 0.007
0.971 ± 0.007
0
50
100
150
200
Epoch
40
60
80
Average Tokens
Honest, 
p = 8
Malicious, 
p = 8
(a) η = 0.1.
0
50
100
150
200
Epoch
40
60
80
Average Tokens
Honest, 
p = 8
Malicious, 
p = 8
(b) η = 0.2.
0
50
100
150
200
Epoch
20
40
60
80
100
Average Tokens
Honest, 
p = 8
Malicious, 
p = 8
(c) η = 0.3.
0
50
100
150
200
Epoch
20
40
60
80
100
Average Tokens
Honest, 
p = 8
Malicious, 
p = 8
(d) η = 0.4.
Fig. 7.
Token distribution results for clients when setting the parameter for slashing proposers as γp = 8. The expected average token of malicious proposers
fluctuates down during the training process.
0
50
100
150
200
Epoch
20
40
60
80
Malicious Client Tokens
p = 32
p = 16
p = 8
p = 4
p = 2
(a) η = 0.1.
0
50
100
150
200
Epoch
20
40
60
80
100
Malicious Client Tokens
p = 32
p = 16
p = 8
p = 4
p = 2
(b) η = 0.2.
0
50
100
150
200
Epoch
0
20
40
60
80
100
Malicious Client Tokens
p = 32
p = 16
p = 8
p = 4
p = 2
(c) η = 0.3.
0
50
100
150
200
Epoch
0
20
40
60
80
100
120
Malicious Client Tokens
p = 32
p = 16
p = 8
p = 4
p = 2
(d) η = 0.4.
Fig. 8.
Token distribution results for malicious clients when choosing γp = 2, 4, 8, 16, and 32. The expected average token of malicious proposers exhibits
a higher rate of decrease when a large value of γp is selected.
0
50
100
150
200
Epoch
40
60
80
100
Honest Client Tokens
p = 32
p = 16
p = 8
p = 4
p = 2
(a) η = 0.1.
0
50
100
150
200
Epoch
40
60
80
100
120
Honest Client Tokens
p = 32
p = 16
p = 8
p = 4
p = 2
(b) η = 0.2.
0
50
100
150
200
Epoch
40
60
80
100
120
140
160
Honest Client Tokens
p = 32
p = 16
p = 8
p = 4
p = 2
(c) η = 0.3.
0
50
100
150
200
Epoch
40
60
80
100
120
140
160
180
200
Honest Client Tokens
p = 32
p = 16
p = 8
p = 4
p = 2
(d) η = 0.4.
Fig. 9.
Token distribution results for honest clients when choosing γp = 2, 4, 8, 16, and 32. The expected average token of honest proposers displays a
higher rate of growth when a large value of γp is selected.
B. Results
1) Empirical Analysis on Malicious Voters: To empirically
validate the theoretical result in Sec. IV-E, we first simulate a
hypothetical scenario where there are only honest proposers.
As there are more honest proposers than malicious proposers
at each round on average, the effect of malicious weights can
be seen as slowing the convergence and decreasing the global
performance, which will be validated in Sec. V-A3. Note, due
to A4, we further simplify the scenario to focus on the behavior
of malicious voters. As shown in Fig. 4, given the set of the
hyperparameter for slashing voters γr = {2, 4, 8, 16, 32}, the
malicious voters will be eliminated from the system shortly
(i.e. their average tokens decline to 0 within ≈ 40 epochs).
2) Comparison with Baselines: Following Theorem 1 and
Sec. V-B1, we now are certain that there will be no de facto
malicious voters. Thus, in the following experiments, we focus
on the scenarios where malicious clients only upload harmful
weights but make honest votes. We evaluate the proposed
framework against the baselines described in Sec. V-A3. We
provide the learning curves in Fig. 5 and the accuracy for all
four approaches after convergence (the mean accuracy of the
last 50 epochs) in Tab. I. The performance of FedAVG w/
block is competitive with FedAVG w/o mal (i.e. η = 0) and
FIRST A. AUTHOR et al.: BARE DEMO OF IEEETAI.CLS FOR IEEE JOURNALS OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE
9
5
10
15
20
25
30
p
0
100
200
Survival Time
(a) η = 0.1.
5
10
15
20
25
30
p
0
100
200
Survival Time
(b) η = 0.2.
5
10
15
20
25
30
p
0
100
200
Survival Time
(c) η = 0.3.
5
10
15
20
25
30
p
0
100
200
Survival Time
(d) η = 0.4.
Fig. 10.
Malicious proposers survival time with various γp. The expected survival time of malicious proposers declines as γp increases.
5
10
15
20
25
30
p
0
100
200
Survival Time
(a) η = 0.1.
5
10
15
20
25
30
p
0
100
200
Survival Time
(b) η = 0.2.
5
10
15
20
25
30
p
0
100
200
Survival Time
(c) η = 0.3.
5
10
15
20
25
30
p
0
100
200
Survival Time
(d) η = 0.4.
Fig. 11.
Honest proposers survival time with various γp. A large γp can also decrease the expected survival time of honest proposers when the malicious
rate η is large. This is because, in each epoch, the randomly selected proposers will be all slashed when the performance of the aggregated global model does
not increase.
consistently outperforms FedAVG w/ mal. As η increases, the
performance of FedAVG w/ mal decreases significantly, with a
larger standard deviation and increased instability. In contrast,
FedAVG w/ block maintains robust performance, with only
slightly lower results compared to FedAVG w/o mal.
3) Analysis of Token Distributions: Fig. 7, 8 and 9 de-
pict the average tokens remaining in honest and malicious
proposers during the FL training process. We observe that
honest proposers gradually accumulate more tokens while
malicious proposers have fewer tokens over sufficient training
epochs. Eventually, most malicious proposers lose the ability
to participate in staking and are removed from the FL system,
as their remaining tokens are insufficient. This meets the
expectations of our system design.
4) Survival Analysis of Clients: As shown in Fig. 10, the
anticipated survival time of malicious proposers experiences a
decrease as γp increases. This effect can be attributed to the
incentive mechanism in place, whereby a higher value of γp
results in a greater penalty for proposers who act maliciously.
Fig. 11 shows the survival time of honest proposers under
different values of γp and exhibits noteworthy behavior. In
cases where the malicious ratio η is high, the expected survival
time of honest proposers may decrease with a large γp. This
is due to the fact that, in each epoch, all randomly selected
proposers will be slashed if the performance of the aggregated
global model does not show improvement. Therefore, it is
worth noting that balancing the token slashing parameter γp
is crucial, because setting an excessively high value can harm
honest proposers, whereas a small value can lead to slow
convergence (see Fig. 6).
5) Sensitivity to Malicious Client Ratio: The results pre-
sented in Fig. 5 demonstrate the robustness of our proposed
method, FedAVG w/ block, against different malicious client
ratios, as its performance remains unaffected even under large
η values. However, it is important to note that the malicious
client ratio can impact the token distribution and survival time
of clients. Specifically, when there are more malicious clients
present in the system, honest clients tend to accumulate more
assets on average (c.f. Fig. 9(a) - 9(d)). Nevertheless, they also
face a higher risk of being slashed during an epoch, which can
ultimately shorten their survival time (c.f. Fig. 11(a) - 11(d)).
6) Limitations: In this work, as the experimental results aim
to evaluate the robustness of the proposed framework, several
practical challenges are simplified, e.g. staleness [44], storage,
and privacy [18]. Further, the proposed method requires more
computational power than traditional methods due to mining
(blockchain computing) and voting. Finally, large models have
gained in popularity in practical applications, e.g. ViT [45]
and GPT-3 [46]. This raises the question on how to efficiently
handle on-chain aggregation for large models. Future work
thus will aim to address these limitations to facilitate the
research and development of FL with blockchain.
VI. CONCLUSION
In this work, we explore an under-explored research di-
rection, namely using FL and blockchain to defend against
malicious behaviors. The defense mechanism is twofold. We
use on-chain smart contracts to replace the traditional central
server and propose a stake-based majority voting mechanism
to detect client-side malicious behaviors. We not only provide
a solution to the problem of interest, an emerging direction on
trustworthy ML, but also show the robustness of the proposed
method and provide the first empirical understanding of the
problem.
10
JOURNAL OF IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE, VOL. 00, NO. 0, MONTH 2020
ACKNOWLEDGMENT
The authors would like to thank Shuhao Zheng from the
School of Computer Science, McGill University for the dis-
cussion in the early stage.
REFERENCES
[1] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in CVPR, 2016, pp. 770–778.
[2] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” in NIPS, vol. 30,
2017, pp. 6000–6010.
[3] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G.
Bellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski
et al., “Human-level control through deep reinforcement learning,”
Nature, vol. 518, no. 7540, pp. 529–533, 2015.
[4] European
Commission,
“General
data
protection
regulation,”
2016.
[Online].
Available:
https://ec.europa.eu/info/law/law-topic/
data-protection/data-protection-eu en
[5] US Department of Health and Human Services, “Health insurance
portability and accountability act,” 2017. [Online]. Available: https:
//www.cdc.gov/phlp/publications/topic/hipaa.html
[6] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in AISTATS.
PMLR, 2017, pp. 1273–1282.
[7] M. Li, D. G. Andersen, A. J. Smola, and K. Yu, “Communication
efficient distributed machine learning with the parameter server,” in
NIPS, 2014, pp. 19–27.
[8] Y. Qu, M. P. Uddin, C. Gan, Y. Xiang, L. Gao, and J. Yearwood,
“Blockchain-enabled federated learning: A survey,” ACM Computing
Surveys, vol. 55, no. 4, pp. 1–35, 2022.
[9] G. Wood, “Ethereum: A secure decentralised generalised transaction
ledger,” Ethereum Project Yellow Paper, vol. 151, pp. 1–32, 2014.
[10] X. Chen, J. Ji, C. Luo, W. Liao, and P. Li, “When machine learning meets
blockchain: A decentralized, privacy-preserving and secure design,” in
IEEE International Conference on Big Data.
IEEE, 2018, pp. 1178–
1187.
[11] L. Soltanisehat, R. Alizadeh, H. Hao, and K.-K. R. Choo, “Tech-
nical, temporal, and spatial research challenges and opportunities in
blockchain-based healthcare: A systematic literature review,” IEEE
Transactions on Engineering Management, 2020.
[12] M. M. Queiroz, R. Telles, and S. H. Bonilla, “Blockchain and supply
chain management integration: a systematic review of the literature,”
Supply Chain Management: An International Journal, vol. 25, no. 2,
pp. 241–254, 2020.
[13] Y. Li, C. Chen, N. Liu, H. Huang, Z. Zheng, and Q. Yan, “A blockchain-
based decentralized federated learning framework with committee con-
sensus,” IEEE Network, vol. 35, no. 1, pp. 234–241, 2021.
[14] E. Bagdasaryan, A. Veit, Y. Hua, D. Estrin, and V. Shmatikov, “How to
backdoor federated learning,” in AISTATS, vol. 108.
PMLR, 2020, pp.
2938–2948.
[15] V. Tolpegin, S. Truex, M. E. Gursoy, and L. Liu, “Data poisoning attacks
against federated learning systems,” in ESORICS, 2020, pp. 480–501.
[16] S. Bano, A. Sonnino, M. Al-Bassam, S. Azouvi, P. McCorry, S. Meik-
lejohn, and G. Danezis, “Sok: Consensus in the age of blockchains,”
in ACM Conference on Advances in Financial Technologies, 2019, pp.
183–198.
[17] Wikipedia, “The resistance (game),” accessed: 2023-02-12. [Online].
Available: https://en.wikipedia.org/wiki/The Resistance (game)
[18] M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Tal-
war, and L. Zhang, “Deep learning with differential privacy,” in ACM
SIGSAC Conference on Computer and Communications Security, 2016,
pp. 308–318.
[19] W. Zhuang, X. Gan, Y. Wen, S. Zhang, and S. Yi, “Collaborative
unsupervised visual representation learning from decentralized data,” in
ICCV, 2021, pp. 4912–4921.
[20] S. Li, Y. Cheng, W. Wang, Y. Liu, and T. Chen, “Learning to de-
tect malicious clients for robust federated learning,” arXiv preprint
arXiv:2002.00211, 2020.
[21] Z. Zhang, X. Cao, J. Jia, and N. Z. Gong, “Fldetector: Defending fed-
erated learning against model poisoning attacks via detecting malicious
clients,” in ACM SIGKDD, 2022, pp. 2545–2555.
[22] S. Nakamoto, “Bitcoin: A peer-to-peer electronic cash system,” 2008.
[23] J. Garay and A. Kiayias, “Sok: A consensus taxonomy in the blockchain
era,” in Topics in Cryptology–CT-RSA 2020: The Cryptographers’ Track
at the RSA Conference 2020, San Francisco, CA, USA, February 24–28,
2020, Proceedings.
Springer, 2020, pp. 284–318.
[24] J. Bonneau, A. Miller, J. Clark, A. Narayanan, J. A. Kroll, and E. W.
Felten, “Sok: Research perspectives and challenges for bitcoin and
cryptocurrencies,” in 2015 IEEE Symposium on Security and Privacy.
IEEE, 2015, pp. 104–121.
[25] V. Gatteschi, F. Lamberti, C. Demartini, C. Pranteda, and V. Santamar´ıa,
“Blockchain and smart contracts for insurance: Is the technology mature
enough?” Future Internet, vol. 10, no. 2, p. 20, 2018.
[26] J. Bao, D. He, M. Luo, and K.-K. R. Choo, “A survey of blockchain
applications in the energy sector,” IEEE Systems Journal, vol. 15, no. 3,
pp. 3370–3381, 2020.
[27] A. Reyna, C. Mart´ın, J. Chen, E. Soler, and M. D´ıaz, “On blockchain and
its integration with iot. challenges and opportunities,” Future Generation
Computer Systems, vol. 88, pp. 173–190, 2018.
[28] S. M. Werner, D. Perez, L. Gudgeon, A. Klages-Mundt, D. Harz, and
W. J. Knottenbelt, “Sok: Decentralized finance (defi),” 2022.
[29] P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N.
Bhagoji, K. Bonawitz, Z. Charles, G. Cormode, R. Cummings et al.,
“Advances and open problems in federated learning,” Foundations and
Trends® in Machine Learning, vol. 14, no. 1–2, pp. 1–210, 2021.
[30] J. Zhu, J. Cao, D. Saxena, S. Jiang, and H. Ferradi, “Blockchain-
empowered federated learning: Challenges, solutions, and future direc-
tions,” ACM Computing Surveys, vol. 55, no. 11, pp. 1–31, 2023.
[31] H. Kim, J. Park, M. Bennis, and S.-L. Kim, “Blockchained on-device
federated learning,” IEEE Communications Letters, vol. 24, no. 6, pp.
1279–1283, 2019.
[32] J. Weng, J. Weng, J. Zhang, M. Li, Y. Zhang, and W. Luo, “Deepchain:
Auditable and privacy-preserving deep learning with blockchain-based
incentive,” IEEE Transactions on Dependable and Secure Computing,
vol. 18, no. 5, pp. 2438–2455, 2019.
[33] D. C. Nguyen, M. Ding, Q.-V. Pham, P. N. Pathirana, L. B. Le,
A. Seneviratne, J. Li, D. Niyato, and H. V. Poor, “Federated learning
meets blockchain in edge computing: Opportunities and challenges,”
IEEE Internet of Things Journal, vol. 8, no. 16, pp. 12 806–12 825,
2021.
[34] M. Ali, H. Karimipour, and M. Tariq, “Integration of blockchain and
federated learning for internet of things: Recent advances and future
challenges,” Computers & Security, vol. 108, p. 102355, 2021.
[35] D. Li, D. Han, T.-H. Weng, Z. Zheng, H. Li, H. Liu, A. Castiglione, and
K.-C. Li, “Blockchain for federated learning toward secure distributed
machine learning systems: a systemic survey,” Soft Computing, vol. 26,
no. 9, pp. 4423–4440, 2022.
[36] K. Toyoda and A. N. Zhang, “Mechanism design for an incentive-
aware blockchain-enabled federated learning platform,” in 2019 IEEE
International Conference on Big Data.
IEEE, 2019, pp. 395–403.
[37] J. Zhang, Y. Wu, and R. Pan, “Incentive mechanism for horizontal fed-
erated learning based on reputation and reverse auction,” in Proceedings
of the Web Conference 2021, 2021, pp. 947–956.
[38] N. Dong, M. Kampffmeyer, I. Voiculescu, and E. Xing, “Federated
partially supervised learning with limited decentralized medical images,”
IEEE TMI, 2022.
[39] N. Dong, M. Kampffmeyer, and I. Voiculescu, “Learning underrepre-
sented classes from decentralized partially labeled medical images,” in
MICCAI.
Springer, 2022, pp. 67–76.
[40] I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing
adversarial examples,” arXiv preprint arXiv:1412.6572, 2014.
[41] J. F. Nash, “Non-cooperative games,” Annals of Mathematics, vol. 54,
no. 2, pp. 286–295, 1951.
[42] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
in ICLR, 2015.
[43] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan,
T. Killeen, Z. Lin, N. Gimelshein, L. Antiga et al., “Pytorch: An
imperative style, high-performance deep learning library,” in NIPS,
vol. 32, 2019.
[44] W. Dai, Y. Zhou, N. Dong, H. Zhang, and E. Xing, “Toward understand-
ing the impact of staleness in distributed machine learning,” in ICLR,
2019.
[45] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai,
T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly et al.,
“An image is worth 16x16 words: Transformers for image recognition
at scale,” in ICLR, 2021.
[46] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal,
A. Neelakantan, P. Shyam, G. Sastry, A. Askell et al., “Language models
are few-shot learners,” in NIPS, vol. 33, 2020, pp. 1877–1901.

